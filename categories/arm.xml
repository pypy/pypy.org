<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>PyPy (Posts about arm)</title><link>https://www.pypy.org/</link><description></description><atom:link href="https://www.pypy.org/categories/arm.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Contents Â© 2025 &lt;a href="mailto:pypy-dev@pypy.org"&gt;The PyPy Team&lt;/a&gt; </copyright><lastBuildDate>Mon, 07 Jul 2025 11:01:31 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>PyPy 2.0 alpha for ARM</title><link>https://www.pypy.org/posts/2013/05/pypy-20-alpha-for-arm-2318299473927531503.html</link><dc:creator>Maciej Fijalkowski</dc:creator><description>&lt;div dir="ltr" style="text-align: left;"&gt;

&lt;p&gt;Hello.&lt;/p&gt;
&lt;p&gt;We're pleased to announce an alpha release of PyPy 2.0 for ARM. This is mostly
a technology preview, as we know the JIT is not yet stable enough for the
full release. However please try your stuff on ARM and report back.&lt;/p&gt;
&lt;p&gt;This is the first release that supports a range of ARM devices - anything with
ARMv6 (like the Raspberry Pi) or ARMv7 (like Beagleboard, Chromebook,
Cubieboard, etc.) that supports VFPv3 should work. We provide builds with
support for both ARM EABI variants: hard-float and some older operating
systems soft-float.&lt;/p&gt;
&lt;p&gt;This release comes with a list of limitations, consider it alpha quality,
not suitable for production:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;stackless support is missing.&lt;/li&gt;
&lt;li&gt;assembler produced is not always correct, but we successfully managed to
run large parts of our extensive benchmark suite, so most stuff should work.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You can download the PyPy 2.0 alpha ARM release here (including a deb for raspbian):&lt;/p&gt;
&lt;blockquote&gt;
&lt;a class="reference external" href="https://pypy.org/download.html"&gt;https://pypy.org/download.html&lt;/a&gt;&lt;/blockquote&gt;
&lt;p&gt;Part of the work was sponsored by the &lt;a class="reference external" href="https://www.raspberrypi.org/"&gt;Raspberry Pi foundation&lt;/a&gt;.&lt;/p&gt;
&lt;div class="section" id="what-is-pypy"&gt;
&lt;h3&gt;What is PyPy?&lt;/h3&gt;
&lt;p&gt;PyPy is a very compliant Python interpreter, almost a drop-in replacement for
CPython 2.7.3. It's fast due to its integrated tracing JIT compiler.&lt;/p&gt;
&lt;p&gt;This release supports ARM machines running Linux 32bit. Both hard-float
&lt;tt class="docutils literal"&gt;armhf&lt;/tt&gt; and soft-float &lt;tt class="docutils literal"&gt;armel&lt;/tt&gt; builds are provided.  &lt;tt class="docutils literal"&gt;armhf&lt;/tt&gt; builds are
created using the Raspberry Pi custom &lt;a class="reference external" href="https://github.com/raspberrypi"&gt;cross-compilation toolchain&lt;/a&gt; based on
gcc-arm-linux-gnueabihf and should work on ARMv6 and ARMv7 devices running at
least debian or ubuntu. &lt;tt class="docutils literal"&gt;armel&lt;/tt&gt; builds are built using gcc-arm-linux-gnuebi
toolchain provided by ubuntu and currently target ARMv7.  If there is interest
in other builds, such as gnueabi for ARMv6 or without requiring a VFP let us
know in the comments or in IRC.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="benchmarks"&gt;
&lt;h3&gt;Benchmarks&lt;/h3&gt;
&lt;p&gt;Everybody loves benchmarks. Here is a table of our benchmark suite
(for ARM we don't provide it yet on &lt;a class="reference external" href="https://speed.pypy.org"&gt;https://speed.pypy.org&lt;/a&gt;,
unfortunately).&lt;/p&gt;
&lt;p&gt;This is a comparison of Cortex A9 processor with 4M cache and Xeon W3580 with
8M of L3 cache. The set of benchmarks is a subset of what we run for
&lt;a class="reference external" href="https://speed.pypy.org"&gt;https://speed.pypy.org&lt;/a&gt; that finishes in reasonable time. The ARM machine
was provided by Calxeda.
Columns are respectively:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;benchmark name&lt;/li&gt;
&lt;li&gt;PyPy speedup over CPython on ARM (Cortex A9)&lt;/li&gt;
&lt;li&gt;PyPy speedup over CPython on x86 (Xeon)&lt;/li&gt;
&lt;li&gt;speedup on Xeon vs Cortex A9, as measured on CPython&lt;/li&gt;
&lt;li&gt;speedup on Xeon vs Cortex A9, as measured on PyPy&lt;/li&gt;
&lt;li&gt;relative speedup (how much bigger the x86 speedup is over ARM speedup)&lt;/li&gt;
&lt;/ul&gt;
&lt;table border="1" class="docutils"&gt;
&lt;colgroup&gt;
&lt;col width="16%"&gt;
&lt;col width="18%"&gt;
&lt;col width="18%"&gt;
&lt;col width="15%"&gt;
&lt;col width="18%"&gt;
&lt;col width="14%"&gt;
&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td&gt;Benchmark&lt;/td&gt;
&lt;td&gt;PyPy vs CPython (arm)&lt;/td&gt;
&lt;td&gt;PyPy vs CPython (x86)&lt;/td&gt;
&lt;td&gt;x86 vs arm (pypy)&lt;/td&gt;
&lt;td&gt;x86 vs arm (cpython)&lt;/td&gt;
&lt;td&gt;relative speedup&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;ai&lt;/td&gt;
&lt;td&gt;3.61&lt;/td&gt;
&lt;td&gt;3.16&lt;/td&gt;
&lt;td&gt;7.70&lt;/td&gt;
&lt;td&gt;8.82&lt;/td&gt;
&lt;td&gt;0.87&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;bm_mako&lt;/td&gt;
&lt;td&gt;3.41&lt;/td&gt;
&lt;td&gt;2.11&lt;/td&gt;
&lt;td&gt;8.56&lt;/td&gt;
&lt;td&gt;13.82&lt;/td&gt;
&lt;td&gt;0.62&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;chaos&lt;/td&gt;
&lt;td&gt;21.82&lt;/td&gt;
&lt;td&gt;17.80&lt;/td&gt;
&lt;td&gt;6.93&lt;/td&gt;
&lt;td&gt;8.50&lt;/td&gt;
&lt;td&gt;0.82&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;crypto_pyaes&lt;/td&gt;
&lt;td&gt;22.53&lt;/td&gt;
&lt;td&gt;19.48&lt;/td&gt;
&lt;td&gt;6.53&lt;/td&gt;
&lt;td&gt;7.56&lt;/td&gt;
&lt;td&gt;0.86&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;django&lt;/td&gt;
&lt;td&gt;13.43&lt;/td&gt;
&lt;td&gt;11.16&lt;/td&gt;
&lt;td&gt;7.90&lt;/td&gt;
&lt;td&gt;9.51&lt;/td&gt;
&lt;td&gt;0.83&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;eparse&lt;/td&gt;
&lt;td&gt;1.43&lt;/td&gt;
&lt;td&gt;1.17&lt;/td&gt;
&lt;td&gt;6.61&lt;/td&gt;
&lt;td&gt;8.12&lt;/td&gt;
&lt;td&gt;0.81&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;fannkuch&lt;/td&gt;
&lt;td&gt;6.22&lt;/td&gt;
&lt;td&gt;5.36&lt;/td&gt;
&lt;td&gt;6.18&lt;/td&gt;
&lt;td&gt;7.16&lt;/td&gt;
&lt;td&gt;0.86&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;float&lt;/td&gt;
&lt;td&gt;5.22&lt;/td&gt;
&lt;td&gt;6.00&lt;/td&gt;
&lt;td&gt;9.68&lt;/td&gt;
&lt;td&gt;8.43&lt;/td&gt;
&lt;td&gt;1.15&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;go&lt;/td&gt;
&lt;td&gt;4.72&lt;/td&gt;
&lt;td&gt;3.34&lt;/td&gt;
&lt;td&gt;5.91&lt;/td&gt;
&lt;td&gt;8.37&lt;/td&gt;
&lt;td&gt;0.71&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;hexiom2&lt;/td&gt;
&lt;td&gt;8.70&lt;/td&gt;
&lt;td&gt;7.00&lt;/td&gt;
&lt;td&gt;7.69&lt;/td&gt;
&lt;td&gt;9.56&lt;/td&gt;
&lt;td&gt;0.80&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;html5lib&lt;/td&gt;
&lt;td&gt;2.35&lt;/td&gt;
&lt;td&gt;2.13&lt;/td&gt;
&lt;td&gt;6.59&lt;/td&gt;
&lt;td&gt;7.26&lt;/td&gt;
&lt;td&gt;0.91&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;json_bench&lt;/td&gt;
&lt;td&gt;1.12&lt;/td&gt;
&lt;td&gt;0.93&lt;/td&gt;
&lt;td&gt;7.19&lt;/td&gt;
&lt;td&gt;8.68&lt;/td&gt;
&lt;td&gt;0.83&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;meteor-contest&lt;/td&gt;
&lt;td&gt;2.13&lt;/td&gt;
&lt;td&gt;1.68&lt;/td&gt;
&lt;td&gt;5.95&lt;/td&gt;
&lt;td&gt;7.54&lt;/td&gt;
&lt;td&gt;0.79&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;nbody_modified&lt;/td&gt;
&lt;td&gt;8.19&lt;/td&gt;
&lt;td&gt;7.78&lt;/td&gt;
&lt;td&gt;6.08&lt;/td&gt;
&lt;td&gt;6.40&lt;/td&gt;
&lt;td&gt;0.95&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;pidigits&lt;/td&gt;
&lt;td&gt;1.27&lt;/td&gt;
&lt;td&gt;0.95&lt;/td&gt;
&lt;td&gt;14.67&lt;/td&gt;
&lt;td&gt;19.66&lt;/td&gt;
&lt;td&gt;0.75&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;pyflate-fast&lt;/td&gt;
&lt;td&gt;3.30&lt;/td&gt;
&lt;td&gt;3.57&lt;/td&gt;
&lt;td&gt;10.64&lt;/td&gt;
&lt;td&gt;9.84&lt;/td&gt;
&lt;td&gt;1.08&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;raytrace-simple&lt;/td&gt;
&lt;td&gt;46.41&lt;/td&gt;
&lt;td&gt;29.00&lt;/td&gt;
&lt;td&gt;5.14&lt;/td&gt;
&lt;td&gt;8.23&lt;/td&gt;
&lt;td&gt;0.62&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;richards&lt;/td&gt;
&lt;td&gt;31.48&lt;/td&gt;
&lt;td&gt;28.51&lt;/td&gt;
&lt;td&gt;6.95&lt;/td&gt;
&lt;td&gt;7.68&lt;/td&gt;
&lt;td&gt;0.91&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;slowspitfire&lt;/td&gt;
&lt;td&gt;1.28&lt;/td&gt;
&lt;td&gt;1.14&lt;/td&gt;
&lt;td&gt;5.91&lt;/td&gt;
&lt;td&gt;6.61&lt;/td&gt;
&lt;td&gt;0.89&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;spambayes&lt;/td&gt;
&lt;td&gt;1.93&lt;/td&gt;
&lt;td&gt;1.27&lt;/td&gt;
&lt;td&gt;4.15&lt;/td&gt;
&lt;td&gt;6.30&lt;/td&gt;
&lt;td&gt;0.66&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;sphinx&lt;/td&gt;
&lt;td&gt;1.01&lt;/td&gt;
&lt;td&gt;1.05&lt;/td&gt;
&lt;td&gt;7.76&lt;/td&gt;
&lt;td&gt;7.45&lt;/td&gt;
&lt;td&gt;1.04&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;spitfire&lt;/td&gt;
&lt;td&gt;1.55&lt;/td&gt;
&lt;td&gt;1.58&lt;/td&gt;
&lt;td&gt;5.62&lt;/td&gt;
&lt;td&gt;5.49&lt;/td&gt;
&lt;td&gt;1.02&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;spitfire_cstringio&lt;/td&gt;
&lt;td&gt;9.61&lt;/td&gt;
&lt;td&gt;5.74&lt;/td&gt;
&lt;td&gt;5.43&lt;/td&gt;
&lt;td&gt;9.09&lt;/td&gt;
&lt;td&gt;0.60&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;sympy_expand&lt;/td&gt;
&lt;td&gt;1.42&lt;/td&gt;
&lt;td&gt;0.97&lt;/td&gt;
&lt;td&gt;3.86&lt;/td&gt;
&lt;td&gt;5.66&lt;/td&gt;
&lt;td&gt;0.68&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;sympy_integrate&lt;/td&gt;
&lt;td&gt;1.60&lt;/td&gt;
&lt;td&gt;0.95&lt;/td&gt;
&lt;td&gt;4.24&lt;/td&gt;
&lt;td&gt;7.12&lt;/td&gt;
&lt;td&gt;0.60&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;sympy_str&lt;/td&gt;
&lt;td&gt;0.72&lt;/td&gt;
&lt;td&gt;0.48&lt;/td&gt;
&lt;td&gt;3.68&lt;/td&gt;
&lt;td&gt;5.56&lt;/td&gt;
&lt;td&gt;0.66&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;sympy_sum&lt;/td&gt;
&lt;td&gt;1.99&lt;/td&gt;
&lt;td&gt;1.19&lt;/td&gt;
&lt;td&gt;3.83&lt;/td&gt;
&lt;td&gt;6.38&lt;/td&gt;
&lt;td&gt;0.60&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;telco&lt;/td&gt;
&lt;td&gt;14.28&lt;/td&gt;
&lt;td&gt;9.36&lt;/td&gt;
&lt;td&gt;3.94&lt;/td&gt;
&lt;td&gt;6.02&lt;/td&gt;
&lt;td&gt;0.66&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;twisted_iteration&lt;/td&gt;
&lt;td&gt;11.60&lt;/td&gt;
&lt;td&gt;7.33&lt;/td&gt;
&lt;td&gt;6.04&lt;/td&gt;
&lt;td&gt;9.55&lt;/td&gt;
&lt;td&gt;0.63&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;twisted_names&lt;/td&gt;
&lt;td&gt;3.68&lt;/td&gt;
&lt;td&gt;2.83&lt;/td&gt;
&lt;td&gt;5.01&lt;/td&gt;
&lt;td&gt;6.50&lt;/td&gt;
&lt;td&gt;0.77&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;twisted_pb&lt;/td&gt;
&lt;td&gt;4.94&lt;/td&gt;
&lt;td&gt;3.02&lt;/td&gt;
&lt;td&gt;5.10&lt;/td&gt;
&lt;td&gt;8.34&lt;/td&gt;
&lt;td&gt;0.61&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;It seems that Cortex A9, while significantly slower than Xeon, has higher
slowdowns with a large interpreter (CPython) than a JIT compiler (PyPy). This
comes as a surprise to me, especially that our ARM assembler is not nearly
as polished as our x86 assembler. As for the causes, various people mentioned
branch predictor, but I would not like to speculate without actually knowing.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="how-to-use-pypy"&gt;
&lt;h3&gt;How to use PyPy?&lt;/h3&gt;
&lt;p&gt;We suggest using PyPy from a &lt;a class="reference external" href="https://www.virtualenv.org/en/latest/"&gt;virtualenv&lt;/a&gt;. Once you have a virtualenv
installed, you can follow instructions from &lt;a class="reference external" href="https://doc.pypy.org/en/latest/getting-started.html#installing-using-virtualenv"&gt;pypy documentation&lt;/a&gt; on how
to proceed. This document also covers other &lt;a class="reference external" href="https://doc.pypy.org/en/latest/getting-started.html#installing-pypy"&gt;installation schemes&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;We would not recommend using in production PyPy on ARM just quite yet,
however the day of a stable PyPy ARM release is not far off.&lt;/p&gt;
&lt;p&gt;Cheers,&lt;br&gt;
fijal, bivab, arigo and the whole PyPy team&lt;/p&gt;
&lt;/div&gt;
&lt;br&gt;&lt;/div&gt;</description><category>arm</category><category>sponsors</category><guid>https://www.pypy.org/posts/2013/05/pypy-20-alpha-for-arm-2318299473927531503.html</guid><pubDate>Tue, 07 May 2013 13:35:00 GMT</pubDate></item><item><title>Almost There - PyPy's ARM Backend</title><link>https://www.pypy.org/posts/2012/02/almost-there-pypys-arm-backend_01-3216759488618774525.html</link><dc:creator>David Schneider</dc:creator><description>&lt;div style="text-align: left;"&gt;
In this post I want to give an update on the status of the ARM backend for PyPy's JIT and describe some of the issues and details of the backend.&lt;/div&gt;
&lt;div class="section" id="current-status"&gt;
&lt;br&gt;
&lt;h2&gt;




Current Status&lt;/h2&gt;
It has been a more than a year that I have been working on the ARM backend. Now it is in a shape, that we can measure meaningful numbers and also ask for some feedback.Â Since the &lt;a class="reference external" href="https://www.pypy.org/posts/2011/01/jit-backend-for-arm-processors-5994810755839586463.html"&gt;last post about the backend&lt;/a&gt; we have added support floating point operations as well as for PyPy's framework GC's. Another area of work was to keep up with the constant improvements done in the main development branch, such as out-of-line guards, labels, etc.Â It has been possible for about a year to cross-translate the PyPy Python interpreter and other interpreters such as &lt;a class="reference external" href="https://bitbucket.org/cfbolz/pyrolog/"&gt;Pyrolog&lt;/a&gt;, with a JIT, to run benchmarks on ARM. Up until now there remained some hard to track bugs that would cause the interpreter to crash with a segmentation fault in certain cases when running with the JIT on ARM. Lately it was possible to run all benchmarks without problems, but when running the translation toolchain itself it would crash.Â During the last PyPy sprint in &lt;a class="reference external" href="https://www.pypy.org/posts/2011/12/leysin-winter-sprint-6862532189897876336.html"&gt;Leysin&lt;/a&gt; Armin and I managed to fix several of these hard to track bugs in the ARM backend with the result that, it is now possible to run the PyPy translator on ARM itself (at least unless until it runs out of memory), which is a kind of litmus test for the backend itself and used to crash before. Just to point it out, we are not able to complete a PyPy translation on ARM, because on the hardware we have currently available there is not enough memory. But up to the point we run out of memory the JIT does not hit any issues.&lt;br&gt;
&lt;br&gt;&lt;/div&gt;
&lt;div class="section" id="implementation-details"&gt;
&lt;h2&gt;




Implementation Details&lt;/h2&gt;
The hardware requirements to run the JIT on ARM follow those for Ubuntu on ARM which targets ARMv7 with a VFP unit running in little endian mode. The JIT can be translated without floating point support, but there might be a few places that need to be fixed to fully work in this setting.Â We are targeting the ARM instruction set, because at least at the time we decided to use it seemed to be the best choice in terms of speed while having some size overhead compared to the Thumb2 instruction set. It appears that the Thumb2 instruction set should give comparable speed with better code density but has a few restriction on the number of registers available and the use of conditional execution. Also the implementation is a bit easier using a fixed width instruction set and we can use the full set of registers in the generated code when using the ARM instruction set.&lt;br&gt;
&lt;br&gt;&lt;/div&gt;
&lt;div class="section" id="the-calling-convention-on-arm"&gt;
&lt;h2&gt;




The calling convention on ARM&lt;/h2&gt;
The calling convention on ARM uses 4 of the general purpose registers to pass arguments to functions, further arguments are passed on the stack. The presence of a floating point unit is not required for ARM cores, for this reason there are different ways of handling floats with relation to the calling convention. There is a so called soft-float calling convention that is independent of the presence of a floating point unit. For this calling convention floating point arguments to functions are stored in the general purpose registers and on the stack. Passing floats around this way works with software and hardware floating point implementations. But in presence of a floating point unit it produces some overhead, because floating point numbers need to be moved from the floating point unit to the core registers to do a call and moved back to the floating point registers by the callee. The alternative calling convention is the so-called hard-float calling convention which requires the presence of a floating point unit but has the advantage of getting rid of the overhead of moving floating point values around when performing a call. Although it would be better in the long term to support the hard-float calling convention, we need to be able to interoperate with external code compiled for the operating system we are running on. For this reason at the moment we only support the soft-float to interoperate with external code.Â We implemented and tested the backend on a &lt;a class="reference external" href="https://beagleboard.org/hardware-xM/"&gt;BeagleBoard-xM&lt;/a&gt; with a &lt;a class="reference external" href="https://www.arm.com/products/processors/cortex-a/cortex-a8.php"&gt;Cortex-A8&lt;/a&gt; processor running &lt;a class="reference external" href="https://wiki.ubuntu.com/ARM"&gt;Ubuntu 11.04 for ARM&lt;/a&gt;.&lt;br&gt;
&lt;br&gt;&lt;/div&gt;
&lt;div class="section" id="translating-for-arm"&gt;
&lt;h2&gt;




Translating for ARM&lt;/h2&gt;
The toolchain used to translate PyPy currently is based on a &lt;a class="reference external" href="https://maemo.gitorious.org/scratchbox2/pages/Home"&gt;Scratchbox2&lt;/a&gt;. Scratchbox2 is a cross-compiling environment. Development had stopped for a while, but it seems to have revived again. We run a 32-bit Python interpreter on the host system and perform all calls to the compiler using a Scratchbox2 based environment. A description on how to setup the cross translation toolchain can be found &lt;a class="reference external" href="https://bitbucket.org/pypy/pypy/src/1f07ea8076c9/pypy/doc/arm.rst"&gt;here&lt;/a&gt;.&lt;br&gt;
&lt;br&gt;&lt;/div&gt;
&lt;div class="section" id="results"&gt;
&lt;h2&gt;




Results&lt;/h2&gt;
The current results on ARM, as shown in the graph below, show that the JIT currently gives a speedup of about 3.5 times compared to CPython on ARM. The benchmarks were run on the before mentioned BeagleBoard-xM with a 1GHz ARM Cortex-A8 processor and 512MB of memory. The operating system on the board is Ubuntu 11.04 for ARM. We measured the PyPy interpreter with the JIT enabled and disabled comparing each to CPython Python 2.7.1+ (r271:86832) for ARM. The graph shows the speedup or slowdown of both PyPy versions for the different benchmarks from our benchmark suite normalized to the runtime of CPython. The data used for the graph can be seen below.&lt;br&gt;
&lt;div class="separator" style="clear: both; text-align: center;"&gt;
&lt;a href="https://2.bp.blogspot.com/-uckc9tOWgnM/TykHMuuGT9I/AAAAAAAAAKg/J8_fC6RS-QA/s1600/graph.png" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" height="258" src="https://2.bp.blogspot.com/-uckc9tOWgnM/TykHMuuGT9I/AAAAAAAAAKg/J8_fC6RS-QA/s400/graph.png" width="400"&gt;&lt;/a&gt;&lt;/div&gt;
&lt;br&gt;
The speedup is less than the speedup of 5.2 times we currently  get on x86 on our own benchmark suite (see &lt;a class="reference external" href="https://speed.pypy.org/"&gt;https://speed.pypy.org&lt;/a&gt; for details). There are several possible reasons for this. Comparing the results for the interpreter without the JIT on ARM and x86 suggests that the interpreter generated by PyPy, without the JIT, has a worse performance when compared to CPython that it does on x86. Also it is quite possible that the code we are generating with the JIT is not yet optimal. Also there are some architectural constraints produce some overhead. One of these differences is the handling of constants, most ARM instructions only support 8 bit (that can be shifted) immediate values, larger constants need to be loaded into a register, something that is not necessary on x86.&lt;br&gt;
&lt;br&gt;
&lt;table border="1" class="docutils"&gt;&lt;colgroup&gt;&lt;/colgroup&gt;&lt;colgroup&gt;&lt;col width="40%"&gt;&lt;/colgroup&gt;&lt;colgroup&gt;&lt;col width="32%"&gt;&lt;/colgroup&gt;&lt;colgroup&gt;&lt;col width="28%"&gt;&lt;/colgroup&gt;&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td&gt;Benchmark&lt;/td&gt;&lt;td&gt;PyPy JIT&lt;/td&gt;&lt;td&gt;PyPy no JIT&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;ai&lt;/td&gt;&lt;td&gt;0.484439780047&lt;/td&gt;&lt;td&gt;3.72756749625&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;chaos&lt;/td&gt;&lt;td&gt;0.0807291691934&lt;/td&gt;&lt;td&gt;2.2908692212&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;crypto_pyaes&lt;/td&gt;&lt;td&gt;0.0711114832245&lt;/td&gt;&lt;td&gt;3.30112318509&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;django&lt;/td&gt;&lt;td&gt;0.0977743245519&lt;/td&gt;&lt;td&gt;2.56779947601&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;fannkuch&lt;/td&gt;&lt;td&gt;0.210423735698&lt;/td&gt;&lt;td&gt;2.49163632938&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;float&lt;/td&gt;&lt;td&gt;0.154275334675&lt;/td&gt;&lt;td&gt;2.12053281495&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;go&lt;/td&gt;&lt;td&gt;0.330483034202&lt;/td&gt;&lt;td&gt;5.84628320479&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;html5lib&lt;/td&gt;&lt;td&gt;0.629264389862&lt;/td&gt;&lt;td&gt;3.60333138526&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;meteor-contest&lt;/td&gt;&lt;td&gt;0.984747426912&lt;/td&gt;&lt;td&gt;2.93838610037&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;nbody_modified&lt;/td&gt;&lt;td&gt;0.236969593082&lt;/td&gt;&lt;td&gt;1.40027234936&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;pyflate-fast&lt;/td&gt;&lt;td&gt;0.367447191807&lt;/td&gt;&lt;td&gt;2.72472422146&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;raytrace-simple&lt;/td&gt;&lt;td&gt;0.0290527461437&lt;/td&gt;&lt;td&gt;1.97270054339&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;richards&lt;/td&gt;&lt;td&gt;0.034575573553&lt;/td&gt;&lt;td&gt;3.29767342015&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;slowspitfire&lt;/td&gt;&lt;td&gt;0.786642551908&lt;/td&gt;&lt;td&gt;3.7397367403&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;spambayes&lt;/td&gt;&lt;td&gt;0.660324379456&lt;/td&gt;&lt;td&gt;3.29059863111&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;spectral-norm&lt;/td&gt;&lt;td&gt;0.063610783731&lt;/td&gt;&lt;td&gt;4.01788986233&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;spitfire&lt;/td&gt;&lt;td&gt;0.43617131165&lt;/td&gt;&lt;td&gt;2.72050579076&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;spitfire_cstringio&lt;/td&gt;&lt;td&gt;0.255538702134&lt;/td&gt;&lt;td&gt;1.7418593111&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;telco&lt;/td&gt;&lt;td&gt;0.102918930413&lt;/td&gt;&lt;td&gt;3.86388866047&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;twisted_iteration&lt;/td&gt;&lt;td&gt;0.122723986805&lt;/td&gt;&lt;td&gt;4.33632475491&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;twisted_names&lt;/td&gt;&lt;td&gt;2.42367797135&lt;/td&gt;&lt;td&gt;2.99878698076&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;twisted_pb&lt;/td&gt;&lt;td&gt;1.30991837431&lt;/td&gt;&lt;td&gt;4.48877805486&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;twisted_tcp&lt;/td&gt;&lt;td&gt;0.927033354055&lt;/td&gt;&lt;td&gt;2.8161624665&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;waf&lt;/td&gt;&lt;td&gt;1.02059811932&lt;/td&gt;&lt;td&gt;1.03793427321&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;br&gt;
&lt;br&gt;
&lt;div class="section" id="the-next-steps-and-call-for-help"&gt;
&lt;h2&gt;




The next steps and call for help&lt;/h2&gt;
Although there probably still are some remaining issues which have not surfaced yet, the JIT backend for ARM is working. Before we can merge the backend into the main development line there are some things that we would like to do first, in particular it we are looking for a way to run the all PyPy tests to verify that things work on ARM before we can merge.Â AdditionallyÂ there are some other longterm ideas. To do this we are looking for people willing to help, either by contributing to implement the open features or that can help us with hardware to test.&lt;br&gt;
&lt;br&gt;
The incomplete list of open topics:&lt;br&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;We are looking for a better way to translate PyPy for ARM, than the one describe above. I am not sure if there currently is hardware with enough memory to directly translate PyPy on an ARM based system, this would require between 1.5 or 2 Gig of memory. A fully &lt;a class="reference external" href="https://wiki.qemu.org/Main_Page"&gt;QEMU&lt;/a&gt; based approach could also work, instead of Scratchbox2 that uses QEMU under the hood.&lt;/li&gt;
&lt;li&gt;Test the JIT on different hardware.&lt;/li&gt;
&lt;li&gt;Experiment with the JIT settings to find the optimal thresholds for ARM.&lt;/li&gt;
&lt;li&gt;Continuous integration: We are looking for a way to run the PyPy test suite to make sure everything works as expected on ARM, here QEMU also might provide an alternative.&lt;/li&gt;
&lt;li&gt;A long term plan would be to port the backend to ARMv5 ISA and improve the support for systems without a floating point unit. This would require to implement the ISA and create different code paths and improve the instruction selection depending on the target architecture.&lt;/li&gt;
&lt;li&gt;Review of the generated machine code the JIT generates on ARM to see if the instruction selection makes sense for ARM.&lt;/li&gt;
&lt;li&gt;Build a version that runs on Android.&lt;/li&gt;
&lt;li&gt;Improve the tools, i.e. integrate with &lt;a class="reference external" href="https://bitbucket.org/pypy/jitviewer"&gt;jitviewer&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
So if you are interested or willing to help in any way contact us.&lt;/div&gt;</description><category>arm</category><category>jit</category><category>pypy</category><guid>https://www.pypy.org/posts/2012/02/almost-there-pypys-arm-backend_01-3216759488618774525.html</guid><pubDate>Wed, 01 Feb 2012 09:43:00 GMT</pubDate></item></channel></rss>