<!DOCTYPE html>
<html \ prefix="
        og: http://ogp.me/ns# article: http://ogp.me/ns/article#
    " vocab="http://ogp.me/ns" lang="en">
<head>
<meta charset="utf-8">
<meta name="description" content="A Faster Python">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>PyPy (old posts, page 34) | PyPy</title>
<link href="../assets/css/rst_base.css" rel="stylesheet" type="text/css">
<link href="../assets/css/nikola_rst.css" rel="stylesheet" type="text/css">
<link href="../assets/css/code.css" rel="stylesheet" type="text/css">
<link href="../assets/css/theme.css" rel="stylesheet" type="text/css">
<link href="../assets/css/styles.css" rel="stylesheet" type="text/css">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="alternate" type="application/rss+xml" title="RSS" hreflang="en" href="../rss.xml">
<link rel="canonical" href="https://www.pypy.org/blog/index-34.html">
<link rel="icon" href="../favicon2.ico" sizes="16x16">
<link rel="icon" href="../favicon32x32.ico" sizes="32x32">
<link rel="prev" href="index-35.html" type="text/html">
<link rel="next" href="index-33.html" type="text/html">
<!--[if lt IE 9]><script src="../assets/js/html5shiv-printshiv.min.js"></script><![endif]--><link href="https://fonts.googleapis.com/css?family=Roboto" rel="stylesheet">
<link rel="stylesheet" type="text/css" href="../assets/css/tipuesearch.css">
</head>
<body>
    <a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>
    <div id="container">
             <header id="header"><!-- Adapted from https://www.taniarascia.com/responsive-dropdown-navigation-bar --><section class="navigation"><div class="nav-container">
            <div class="brand">
                <a href="../index.html">
                    <image id="toplogo" src="../images/pypy-logo.svg" width="75px;" alt="PyPy/"></image></a>
            </div>
            <nav><ul class="nav-list">
<li> 
                <a href="#!">Features</a>
                <ul class="nav-dropdown">
<li> <a href="../features.html">What is PyPy?</a> </li>  
                    <li> <a href="../compat.html">Compatibility</a> </li>  
                    <li> <a href="../performance.html">Performance</a> </li>  
                </ul>
</li>
          <li> <a href="../download.html">Download</a> </li>  
          <li> <a href="http://doc.pypy.org">Dev Docs</a> </li>  
            <li> 
                <a href="#!">Blog</a>
                <ul class="nav-dropdown">
<li> <a href=".">Index</a> </li>  
                    <li> <a href="../categories/">Tags</a> </li>  
                    <li> <a href="../archive.html">Archive by year</a> </li>  
                    <li> <a href="../rss.xml">RSS feed</a> </li>  
                    <li> <a href="https://morepypy.blogspot.com/">Old site</a> </li>  
                </ul>
</li>
            <li> 
                <a href="#!">About</a>
                <ul class="nav-dropdown">
<li> <a href="https://bsky.app/profile/pypyproject.bsky.social">Bluesky</a> </li>  
                    <li> <a href="https://libera.irclog.whitequark.org/pypy">IRC logs</a> </li>  
                    <li> <a href="https://www.youtube.com/playlist?list=PLADqad94yVqDRQXuqxKrPS5QnVqbDLlRt">YouTube</a> </li>  
                    <li> <a href="https://www.twitch.tv/pypyproject">Twitch</a> </li>  
                    <li> <a href="../pypy-sponsors.html">Sponsors</a> </li>  
                    <li> <a href="../howtohelp.html">How To Help?</a> </li>  
                    <li> <a href="../contact.html">Contact</a> </li>  
                </ul>
</li>

                </ul></nav><div class="nav-mobile">
                <a id="nav-toggle" href="#!"> <span></span></a>
            </div>
        </div>
    </section><div class="searchform" role="search">
                
<form class="navbar-form navbar-left" action="../search.html" role="search">
    <div class="form-group">
        <input type="text" class="form-control" id="tipue_search_input" name="q" placeholder="Search…" autocomplete="off">
</div>
    <input type="submit" value="Local Search" style="visibility: hidden;">
</form>

            </div>
    </header><main id="content"><div class="post">
<div class="postindex">
    <article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="../posts/2016/01/using-cffi-for-embedding-8493496761738752124.html" class="u-url">Using CFFI for embedding</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                <a href="../authors/armin-rigo.html">Armin Rigo</a>
            </span></p>
            <p class="dateline">
            <a href="../posts/2016/01/using-cffi-for-embedding-8493496761738752124.html" rel="bookmark">
            <time class="published dt-published" datetime="2016-01-06T11:17:00Z" itemprop="datePublished" title="2016-01-06 11:17">2016-01-06 11:17</time></a>
            </p>
                <p class="commentline">7 comments</p>

        </div>
    </header><div class="p-summary entry-summary">
    <h3>Introduction</h3>

<p><a href="https://cffi.readthedocs.org/">CFFI</a> has been a great success so far to call C libraries in your
Python programs, in a way that is both simple and that works across
CPython 2.x and 3.x and PyPy.</p>

<p>This post assumes that you know what CFFI is and how to use it in
API mode (<tt class="docutils literal">ffi.cdef()</tt>, <tt class="docutils literal">ffi.set_source()</tt>, <tt class="docutils literal">ffi.compile()</tt>).
A quick overview can be found <a href="https://cffi.readthedocs.org/en/latest/overview.html#real-example-api-level-out-of-line">in this paragraph.</a></p>

<p>The major news of CFFI 1.4, released last december, was that you can
now declare C functions with <tt class="docutils literal">extern "Python"</tt> in the <tt class="docutils literal">cdef()</tt>.
These magic keywords make the function callable from C (where it is
defined automatically), but calling it will call some Python code
(which you attach with the <tt class="docutils literal">@ffi.def_extern()</tt> decorator).  This is
useful because it gives a more straightforward, faster and
libffi-independent way to write callbacks.  For more details, see <a href="https://cffi.readthedocs.org/en/latest/using.html#extern-python-new-style-callbacks">the
documentation.</a></p>

<p>You are, in effect, declaring a static family of C functions which
call Python code.  The idea is to take pointers to them, and pass them
around to other C functions, as callbacks.  However, the idea of a set
of C functions which call Python code opens another path: <em>embedding</em>
Python code inside non-Python programs.</p>

<h3>Embedding</h3>

<p>Embedding is traditionally done using the CPython C API: from C code,
you call <tt class="docutils literal">Py_Initialize()</tt> and then some other functions like
<tt class="docutils literal">PyRun_SimpleString()</tt>.  In the simple cases it is, indeed, simple
enough; but it can become a complicated story if you throw in
supporting application-dependent object types; and a messy story if
you add correctly running on multiple threads, for example.</p>
<p>Moreover, this approach is specific to CPython (2.x or 3.x).  It does
not work at all on PyPy, which has its own very different, minimal
<a href="https://pypy.readthedocs.org/en/latest/embedding.html">embedding API.</a></p>

<p>The new-and-coming thing about CFFI 1.5, meant as replacement of the
above solutions, is direct embedding support---with no fixed API at
all.  The idea is to write some Python script with a <tt class="docutils literal">cdef()</tt> which
declares a number of <tt class="docutils literal">extern "Python"</tt> functions.  When running the
script, it creates the C source code and compiles it to a
dynamically-linked library (<tt class="docutils literal">.so</tt> on Linux).  This is the same as in
the regular API-mode usage.  What is new is that these <tt class="docutils literal">extern
"Python"</tt> can now also be <em>exported</em> from the <tt class="docutils literal">.so</tt>, in the C
sense.  You also give a bit of initialization-time Python code
directly in the script, which will be compiled into the <tt class="docutils literal">.so</tt> too.</p>
<p>This library can now be used directly from any C program (and it is
still importable in Python).  It exposes the C API of your choice,
which you specified with the <tt class="docutils literal">extern "Python"</tt> declarations.  You
can use it to make whatever custom API makes sense in your particular
case.  You can even directly make a "plug-in" for any program that
supports them, just by exporting the API expected for such plugins.</p>

<h3>Trying it out on CPython</h3>

<p>This is still being finalized, but please try it out.  You can
see <a href="https://foss.heptapod.net/cffi/cffi/src/static-callback-embedding/demo/embedding.py">embedding.py</a> directly online for a quick glance.  Or
see below the instructions on Linux with CPython 2.7 (CPython 3.x and
non-Linux platforms are still a work in progress right now, but this
should be quickly fixed):</p>
<ul>
<li>
<p class="first">get the branch <tt class="docutils literal"><span class="pre">static-callback-embedding</span></tt> of CFFI:</p>
<pre class="literal-block">
hg clone https://foss.heptapod.net/cffi/cffi
hg up static-callback-embedding
</pre>
</li>
<li>
<p class="first">make the <tt class="docutils literal">_cffi_backend.so</tt>:</p>
<pre class="literal-block">
python setup_base.py build_ext -f -i
</pre>
</li>
<li>
<p class="first">run <tt class="docutils literal">embedding.py</tt> in the <tt class="docutils literal">demo</tt> directory:</p>
<pre class="literal-block">
cd demo
PYTHONPATH=.. python embedding.py
</pre>
</li>
<li>
<p class="first">this produces <tt class="docutils literal">_embedding_cffi.c</tt>.  Run <tt class="docutils literal">gcc</tt> to build it.  On Linux:</p>
<pre class="literal-block">
gcc -shared -fPIC _embedding_cffi.c -o _embedding_cffi.so  \
    -lpython2.7 -I/usr/include/python2.7
</pre>
</li>
<li>
<p class="first">try out the demo C program in <tt class="docutils literal">embedding_test.c</tt>:</p>
<pre class="literal-block">
gcc embedding_test.c _embedding_cffi.so
PYTHONPATH=.. LD_LIBRARY_PATH=. ./a.out
</pre>
</li>
</ul>
<p>Note that if you get <tt class="docutils literal">ImportError: cffi extension module
'_embedding_cffi' has unknown version 0x2701</tt>, it means that the
<tt class="docutils literal">_cffi_backend</tt> module loaded is a pre-installed one instead of the
more recent one in "<tt class="docutils literal">..</tt>".  Be sure to use <tt class="docutils literal"><span class="pre">PYTHONPATH=..</span></tt> for now.  (Some installations manage to be confused enough to load the system-wide cffi even if another version is in the PYTHONPATH.  I think a virtualenv can be used to work around this issue.)</p>

<h3>Try it out on PyPy</h3>

<p>Very similar steps can be followed on PyPy, but it requires the
<tt class="docutils literal"><span class="pre">cffi-static-callback-embedding</span></tt> branch of PyPy, which you must
first translate from sources.  The difference is then that you need to
adapt the first <tt class="docutils literal">gcc</tt> command line: replace <tt class="docutils literal"><span class="pre">-lpython2.7</span></tt> with
<tt class="docutils literal"><span class="pre">-lpypy-c</span></tt> and to fix the <tt class="docutils literal"><span class="pre">-I</span></tt> path (and possibly add a <tt class="docutils literal"><span class="pre">-L</span></tt>
path).</p>

<h3>More details</h3>

<p>How it works, more precisely, is by automatically initializing CPython/PyPy
the first time any of the <tt class="docutils literal">extern "Python"</tt>
functions is called from the C program.  This is done using locks in case of multi-threading,
so several threads can concurrently do this "first call".  This should work even if two
different threads call the first time a function from two <em>different</em>
embedded CFFI extensions that happen to be linked with the same program.  Explicit initialization is
never needed.</p>

<p>The custom initialization-time Python code you put in
<tt class="docutils literal">ffi.embedding_init_code()</tt> is executed at that time.  If this code
starts to be big, you can move it to independent modules or packages.
Then the initialization-time Python code only needs to import them.  In
that case, you have to carefully set up <tt class="docutils literal">sys.path</tt> if the modules are
not installed in the usual Python way.</p>
<p>If the Python code is big and full of dependencies, a better alternative
would be to use virtualenv.  How to do that is not fully fleshed out so
far.  You can certainly run the whole program with the environment
variables set up by the virtualenv's <tt class="docutils literal">activate</tt> script first.  There
are probably other solutions that involve using gcc's
<tt class="docutils literal"><span class="pre">-Wl,-rpath=\$ORIGIN/</span></tt> or <tt class="docutils literal"><span class="pre">-Wl,-rpath=/fixed/path/</span></tt> options to load
a specific libpython or libypypy-c library.  If you try it out and it
doesn't work the way you would like, please complain <tt class="docutils literal"><span class="pre">:-)</span></tt></p>
<p>Another point: right now this does not support CPython's notion of
multiple subinterpreters.  The logic creates a single global Python
interpreter, and runs everything in that context.  Maybe a future
version would have an explicit API to do that — or maybe it should be
the job of a 3rd-party extension module to provide a Python interface
over the notion of subinterpreters...</p>
<p>More generally, any feedback is appreciated.</p>
<p>Have fun,</p>
<p>Armin</p>
    </div>
    </article><div class="comment-level comment-level-1">
      <div class="comment comment-5103785936625763314">
        <div class="comment-header">
          <a name="comment-5103785936625763314"></a>
            <span class="author">Armin Rigo</span> wrote on <span class="date">2016-01-07 13:29</span>:
        </div>
        <div class="comment-content">
          <p>Thanks to apollo13 on irc for early feedback.  Main change: the code put in embedded_init_code() should now start with "from xx import ffi", where "xx" is the name of the module (first argument to set_source()).  The goal is to clearly say that you need the same line in other modules imported from there.</p>
        </div>
      </div>
      <div class="comment comment-380956674313874528">
        <div class="comment-header">
          <a name="comment-380956674313874528"></a>
            <span class="author">Unknown</span> wrote on <span class="date">2016-01-11 14:42</span>:
        </div>
        <div class="comment-content">
          <p>This is very exciting! Just waiting for Python 3.x support now. :)</p>
        </div>
      </div>
      <div class="comment comment-425643661807624631">
        <div class="comment-header">
          <a name="comment-425643661807624631"></a>
            <span class="author">Armin Rigo</span> wrote on <span class="date">2016-01-12 07:54</span>:
        </div>
        <div class="comment-content">
          <p>Python 3 is implemented and tested now.</p>
        </div>
      </div>
      <div class="comment comment-5603874434597101470">
        <div class="comment-header">
          <a name="comment-5603874434597101470"></a>
            <span class="author">Armin Rigo</span> wrote on <span class="date">2016-01-12 18:48</span>:
        </div>
        <div class="comment-content">
          <p>Windows support is now done (tested on Python 2.7).  Expect a release soon :-)</p>
        </div>
      </div>
      <div class="comment comment-1526418882178615002">
        <div class="comment-header">
          <a name="comment-1526418882178615002"></a>
            <span class="author">Armin Rigo</span> wrote on <span class="date">2016-01-16 18:02</span>:
        </div>
        <div class="comment-content">
          <a href="https://pypi.python.org/pypi/cffi" rel="nofollow">CFFI 1.5 is released.</a>
        </div>
      </div>
      <div class="comment comment-7006588583534092283">
        <div class="comment-header">
          <a name="comment-7006588583534092283"></a>
            <span class="author">Anonymous</span> wrote on <span class="date">2016-02-08 00:10</span>:
        </div>
        <div class="comment-content">
          <p>Excelent feature!!<br><br>CFFI rocks, and the documentation keeps improving :)<br></p>
        </div>
      </div>
      <div class="comment comment-582089255001051786">
        <div class="comment-header">
          <a name="comment-582089255001051786"></a>
            <span class="author">d.q.</span> wrote on <span class="date">2016-03-10 10:51</span>:
        </div>
        <div class="comment-content">
          <p>Awesome, pypyInstaller in cross-hairs!</p>
        </div>
      </div>
         </div>

    <article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="../posts/2016/01/leysin-winter-sprint-20-27th-february-1737200016169608469.html" class="u-url">Leysin Winter Sprint (20-27th February 2016)</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                <a href="../authors/armin-rigo.html">Armin Rigo</a>
            </span></p>
            <p class="dateline">
            <a href="../posts/2016/01/leysin-winter-sprint-20-27th-february-1737200016169608469.html" rel="bookmark">
            <time class="published dt-published" datetime="2016-01-04T12:24:00Z" itemprop="datePublished" title="2016-01-04 12:24">2016-01-04 12:24</time></a>
            </p>
            
        </div>
    </header><div class="p-summary entry-summary">
    <p>The next PyPy sprint will be in Leysin, Switzerland, for the eleventh time.
This is a fully public sprint: newcomers and topics other than those
proposed below are welcome.</p>
<div class="section" id="goals-and-topics-of-the-sprint">
<h3>Goals and topics of the sprint</h3>
<p>The details depend on who is here and ready to work.  The list of
topics is mostly the same as last year (did PyPy became a mature
project with only long-term goals?):</p>
<ul class="simple">
<li>cpyext (CPython C API emulation layer): various speed and
completeness topics</li>
<li>cleaning up the optimization step in the JIT, change the register
allocation done by the JIT's backend, or more improvements to the
warm-up time</li>
<li>finish vmprof - a statistical profiler for CPython and PyPy</li>
<li>Py3k (Python 3.x support), NumPyPy (the numpy module)</li>
<li>STM (Software Transaction Memory), notably: try to come up with
benchmarks, and measure them carefully in order to test and improve
the conflict reporting tools, and more generally to figure out how
practical it is in large projects to avoid conflicts</li>
<li>And as usual, the main side goal is to have fun in winter sports :-)
We can take a day off for ski.</li>
</ul>
</div>
<div class="section" id="exact-times">
<h3>Exact times</h3>
<p>I have booked the week from Saturday 20 to Saturday 27.  It is fine to
leave either the 27 or the 28, or even stay a few
more days on either side.  The plan is to work full days between the 21
and the 27.  You are of course allowed to show up for a part of that
time only, too.</p>
</div>
<div class="section" id="location-accomodation">
<h3>Location &amp; Accomodation</h3>
<p>Leysin, Switzerland, "same place as before".  Let me refresh your
memory: both the sprint venue and the lodging will be in a
pair of chalets built specifically for bed &amp; breakfast:
<a class="reference external" href="https://www.ermina.ch/">https://www.ermina.ch/</a>.  The place has a good ADSL Internet connection
with wireless installed.  You can also arrange your own lodging
elsewhere (as long as you are in Leysin, you cannot be more than a 15
minutes walk away from the sprint venue).</p>
<p>Please <em>confirm</em> that you are coming so that we can adjust the
reservations as appropriate.</p>
<p>The options of rooms are a bit more limited than on previous years
because the place for bed-and-breakfast is shrinking: what is
guaranteed is only one double-bed room and a bigger room with 5-6
individual beds (the latter at 50-60 CHF per night, breakfast
included).  If there are more people that would prefer a single room,
please contact me and we'll see what choices you have.  There are a
choice of hotels, many of them reasonably priced for Switzerland.</p>
<p>Please register by Mercurial:</p>
<blockquote>
<a href="https://bitbucket.org/pypy/extradoc/">https://bitbucket.org/pypy/extradoc/</a><br><a href="https://foss.heptapod.net/pypy/extradoc/-/blob/branch/default/extradoc/sprintinfo/leysin-winter-2016">https://foss.heptapod.net/pypy/extradoc/-/blob/branch/default/extradoc/sprintinfo/leysin-winter-2016</a>
</blockquote>
<p>or on the pypy-dev mailing list if you do not yet have check-in rights:</p>
<blockquote>
<a class="reference external" href="https://mail.python.org/mailman/listinfo/pypy-dev">https://mail.python.org/mailman/listinfo/pypy-dev</a>
</blockquote>
<p>You need a Swiss-to-(insert country here) power adapter.  There will be
some Swiss-to-EU adapters around, and at least one EU-format power strip.</p>
</div>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="../posts/2015/11/pypy-401-released-please-update-2652340737298251005.html" class="u-url">PyPy 4.0.1 released please update</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                <a href="../authors/mattip.html">mattip</a>
            </span></p>
            <p class="dateline">
            <a href="../posts/2015/11/pypy-401-released-please-update-2652340737298251005.html" rel="bookmark">
            <time class="published dt-published" datetime="2015-11-19T21:01:00Z" itemprop="datePublished" title="2015-11-19 21:01">2015-11-19 21:01</time></a>
            </p>
                <p class="commentline">8 comments</p>

        </div>
    </header><div class="p-summary entry-summary">
    <div dir="ltr" style="text-align: left;">
<div class="document">
<div>
<div class="section" id="pypy-4-0-1" style="text-align: left;">
<h1>
PyPy 4.0.1</h1>
<br>
We have released PyPy 4.0.1, three weeks after PyPy 4.0.0. We have fixed a few critical bugs in the JIT compiled code, reported by users. We therefore encourage all users of PyPy to update to this version. There are a few minor enhancements in this version as well.<br><br>
You can download the PyPy 4.0.1 release here:<br><blockquote>
<div>
<a class="reference external" href="https://pypy.org/download.html">https://pypy.org/download.html</a>
</div>
</blockquote>
We would like to thank our donors for the continued support of the PyPy project.<br>
We would also like to thank our contributors and encourage new people to join the project. PyPy has many layers and we need help with all of them: <a class="reference external" href="https://doc.pypy.org/">PyPy</a> and <a class="reference external" href="https://rpython.readthedocs.org/">RPython</a> documentation improvements, tweaking popular <a class="reference external" href="https://doc.pypy.org/en/latest/project-ideas.html#make-more-python-modules-pypy-friendly">modules</a> to run on pypy, or general <a class="reference external" href="https://doc.pypy.org/en/latest/project-ideas.html">help</a> with making RPython’s JIT even better.<br><h3>
 </h3>
<div class="section" id="cffi">
<h3>
 </h3>
<h3>
CFFI update</h3>
<br>
While not applicable only to PyPy, <a class="reference external" href="https://cffi.readthedocs.org/">cffi</a> is arguably our most significant contribution to the python ecosystem. PyPy 4.0.1 ships with <a class="reference external" href="https://cffi.readthedocs.org/en/latest/whatsnew.html#v1-3-1">cffi-1.3.1</a> with the improvements it brings.</div>
<div class="section" id="what-is-pypy">
<h3 style="text-align: left;">
 </h3>
<h3 style="text-align: left;">
What is PyPy?</h3>
<br>
PyPy is a very compliant Python interpreter, almost a drop-in replacement for CPython 2.7. It’s fast (<a class="reference external" href="https://speed.pypy.org/">pypy and cpython 2.7.x</a> performance comparison) due to its integrated tracing JIT compiler.<br>
We also welcome developers of other <a class="reference external" href="https://pypyjs.org/">dynamic languages</a> to see what RPython can do for them.<br>
This release supports <b>x86</b> machines on most common operating systems (Linux 32/64, Mac OS X 64, Windows 32, OpenBSD, freebsd), newer <b>ARM</b> hardware (ARMv6 or ARMv7, with VFPv3) running Linux, and the big- and little-endian variants of <b>ppc64</b> running Linux.</div>
<div class="section" id="other-highlights-since-4-0-0-released-three-weeks-ago" style="text-align: left;">
<h3>
 </h3>
<h3>
Other Highlights (since 4.0.0 released three weeks ago)</h3>
<h3>
</h3>
<ul class="simple">
<li>
<b>Bug Fixes</b><ul>
<li>Fix a bug when unrolling double loops in JITted code</li>
<li>Fix multiple memory leaks in the ssl module, one of which affected CPython as well (thanks to Alex Gaynor for pointing those out)</li>
<li>Use pkg-config to find ssl headers on OS-X</li>
<li>Issues reported with our previous release were <a class="reference external" href="https://doc.pypy.org/en/latest/whatsnew-4.0.1.html">resolved</a> after reports from users on our issue tracker at <a class="reference external" href="https://foss.heptapod.net/pypy/pypy/-/issues">https://foss.heptapod.net/pypy/pypy/-/issues</a> or on IRC at #pypy</li>
</ul>
</li>
<li>
<b>New features</b><ul>
<li>Internal cleanup of RPython class handling</li>
<li>Support stackless and greenlets on PPC machines</li>
<li>Improve debug logging in subprocesses: use PYPYLOG=jit:log.%d for example to have all subprocesses write the JIT log to a file called ‘log.%d’, with ‘%d’ replaced with the subprocess’ PID.</li>
<li>Support PyOS_double_to_string in our cpyext capi compatibility layer</li>
</ul>
</li>
<li>
<b>Numpy</b><ul>
<li>Improve support for __array_interface__</li>
<li>Propagate most NAN mantissas through float16-float32-float64 conversions</li>
</ul>
</li>
<li>
<b>Performance improvements and refactorings</b><ul>
<li>Improvements in slicing byte arrays</li>
<li>Improvements in enumerate()</li>
<li>Silence some warnings while translating</li>
</ul>
</li>
</ul>
Please update, and continue to help us make PyPy better.<br><br>
Cheers <br>
The PyPy Team</div>
</div>
</div>
</div>
</div>
    </div>
    </article><div class="comment-level comment-level-1">
      <div class="comment comment-6275437514005732775">
        <div class="comment-header">
          <a name="comment-6275437514005732775"></a>
            <span class="author">Marius Gedminas</span> wrote on <span class="date">2015-11-20 11:20</span>:
        </div>
        <div class="comment-content">
          <p>I'd love to upgrade and see if that makes my segfault go away, but the builds at https://launchpad.net/~pypy/+archive/ubuntu/ppa?field.series_filter=precise are two weeks old?</p>
        </div>
      </div>
      <div class="comment comment-8458193481974979587">
        <div class="comment-header">
          <a name="comment-8458193481974979587"></a>
            <span class="author">Armin Rigo</span> wrote on <span class="date">2015-11-20 12:06</span>:
        </div>
        <div class="comment-content">
          <p>Hi Marius!  How about directing such complains to the maintainer of the PPA instead of us? :-)</p>
        </div>
      </div>
      <div class="comment comment-2178292701411672094">
        <div class="comment-header">
          <a name="comment-2178292701411672094"></a>
            <span class="author">Gerd Puin</span> wrote on <span class="date">2015-11-27 05:46</span>:
        </div>
        <div class="comment-content">
          <p>Where are the benchmark instructions for the official set?</p>
        </div>
      </div>
      <div class="comment comment-1822703389172824810">
        <div class="comment-header">
          <a name="comment-1822703389172824810"></a>
            <span class="author">Armin Rigo</span> wrote on <span class="date">2015-11-27 09:57</span>:
        </div>
        <div class="comment-content">
          <p>https://bitbucket.org/pypy/benchmarks , file runner.py.  This file has various options; try this: ``python runner.py --changed /path/to/pypy``.  This example would compare the speed on top of your system's python and on top of /path/to/pypy.  Try also ``--fast`` if you're not patient enough.</p>
        </div>
      </div>
      <div class="comment comment-1363566087001661644">
        <div class="comment-header">
          <a name="comment-1363566087001661644"></a>
            <span class="author">Unknown</span> wrote on <span class="date">2015-11-28 02:54</span>:
        </div>
        <div class="comment-content">
          <p>can I run pandas in PyPy. I am using Python for Data Science</p>
        </div>
      </div>
      <div class="comment comment-4414136288120778883">
        <div class="comment-header">
          <a name="comment-4414136288120778883"></a>
            <span class="author">Gerd Puin</span> wrote on <span class="date">2015-11-28 04:20</span>:
        </div>
        <div class="comment-content">
          <p>Thanks Armin, that got me a result.json file - is there a tool to present the data in a more human-readable way?</p>
        </div>
      </div>
      <div class="comment comment-8448734406565519838">
        <div class="comment-header">
          <a name="comment-8448734406565519838"></a>
            <span class="author">Armin Rigo</span> wrote on <span class="date">2015-11-29 08:03</span>:
        </div>
        <div class="comment-content">
          <p>The command itself prints a human-readable result at the end; you can ignore result.json.</p>
        </div>
      </div>
      <div class="comment comment-3087505738153662042">
        <div class="comment-header">
          <a name="comment-3087505738153662042"></a>
            <span class="author">Gerd Puin</span> wrote on <span class="date">2015-11-29 18:48</span>:
        </div>
        <div class="comment-content">
          <p>I see. Just an idea - maybe the results could be reviewed on speed.pypy.org via a web interface?<br><br>Cheers!</p>
        </div>
      </div>
         </div>

    <article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="../posts/2015/10/pypy-400-released-jit-with-simd-8282134928733384063.html" class="u-url">PyPy 4.0.0 Released - A Jit with SIMD Vectorization and More</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                <a href="../authors/mattip.html">mattip</a>
            </span></p>
            <p class="dateline">
            <a href="../posts/2015/10/pypy-400-released-jit-with-simd-8282134928733384063.html" rel="bookmark">
            <time class="published dt-published" datetime="2015-10-29T12:17:00Z" itemprop="datePublished" title="2015-10-29 12:17">2015-10-29 12:17</time></a>
            </p>
                <p class="commentline">19 comments</p>

        </div>
    </header><div class="p-summary entry-summary">
    <div dir="ltr" style="text-align: left;">
<h1>
PyPy 4.0.0</h1>
We’re pleased and proud to unleash PyPy 4.0.0, a major update of the PyPy python 2.7.10 compatible interpreter with a Just In Time compiler. We have improved <a class="reference external" href="../posts/2015/10/pypy-memory-and-warmup-improvements-2-4598780879518640015.html">warmup time and memory overhead used for tracing</a>, added <a class="reference external" href="https://pypyvecopt.blogspot.co.at/">vectorization</a> for numpy and general loops where possible on x86 hardware (disabled by default), refactored rough edges in rpython, and increased functionality of numpy.<br>
You can download the PyPy 4.0.0 release here:<br><blockquote>
<div>
<a class="reference external" href="https://pypy.org/download.html">https://pypy.org/download.html</a>
</div>
</blockquote>
We would like to thank our donors for the continued support of the PyPy project.<br>
We would also like to thank our contributors (7 new ones since PyPy 2.6.0) and encourage new people to join the project. PyPy has many layers and we need help with all of them: <a class="reference external" href="https://doc.pypy.org/">PyPy</a> and <a class="reference external" href="https://rpython.readthedocs.org/">RPython</a> documentation improvements, tweaking popular <a class="reference external" href="https://doc.pypy.org/en/latest/project-ideas.html#make-more-python-modules-pypy-friendly">modules</a> to run on PyPy, or general <a class="reference external" href="https://doc.pypy.org/en/latest/project-ideas.html">help</a> with making RPython’s JIT even better.<br><br><h3 style="text-align: center;">
New Version Numbering</h3>
<br><div class="section" id="new-version-numbering">
Since the past release, PyPy 2.6.1, we decided to update the PyPy 2.x.x versioning directly to PyPy 4.x.x, to avoid confusion with CPython 2.7 and 3.5. Note that this version of PyPy uses the stdlib and implements the syntax of CPython 2.7.10.</div>
<br><h3 style="text-align: center;">
Vectorization</h3>
<br><div class="section" id="vectorization">
Richard Plangger began work in March and continued over a Google Summer of Code to add a<a href="https://pypyvecopt.blogspot.co.at/"> <cite>vectorization</cite></a> step to the trace optimizer. The step recognizes common constructs and emits SIMD code where possible, much as any modern compiler does. This vectorization happens while tracing running code,  so it is actually easier at run-time to determine the availability of possible vectorization than it is for ahead-of-time compilers.<br>
Availability of SIMD hardware is detected at run time, without needing to precompile various code paths into the executable.<br>
The first version of the vectorization has been merged in this release, since it is so new it is off by default. To enable the vectorization in built-in JIT drivers (like numpy ufuncs), add <cite>–jit vec=1</cite>, to enable all implemented vectorization add <cite>–jit vec_all=1</cite><br>
Benchmarks and a summary of this work appear <a class="reference external" href="../posts/2015/10/automatic-simd-vectorization-support-in-639063580401330508.html">here</a>
</div>
<br><h3 style="text-align: center;">
Internal Refactoring: Warmup Time Improvement and Reduced Memory Usage</h3>
<br><div class="section" id="internal-refactoring-and-warmup-time-improvement">
Maciej Fijalkowski and Armin Rigo refactored internals of <cite></cite>Rpython that now allow PyPy to more efficiently use <a class="reference external" href="https://rpython.readthedocs.org/en/latest/glossary.html">guards</a> in jitted code. They also rewrote unrolling, leading to a warmup time improvement of 20% or so. The reduction in guards also means a reduction in the use of memory, also a savings of around 20%.</div>
<div class="section" id="numpy">
<br><h3 style="text-align: center;">
Numpy</h3>
<br>
Our implementation of <a class="reference external" href="https://bitbucket.org/pypy/numpy">numpy</a> continues to improve. ndarray and the numeric dtypes are very close to feature-complete; record, string and unicode dtypes are mostly supported.  We have reimplemented numpy linalg, random and fft as cffi-1.0 modules that call out to the same underlying libraries that upstream numpy uses. Please try it out, especially using the new vectorization (via <cite>–jit vec=1</cite> on the command line) and let us know what is missing for your code.</div>
<div class="section" id="cffi">
<br><h3 style="text-align: center;">
CFFI</h3>
<br>
While not applicable only to PyPy, <a class="reference external" href="https://cffi.readthedocs.org/">cffi</a> is arguably our most significant contribution to the python ecosystem. Armin Rigo continued improving it, and PyPy reaps the benefits of <a class="reference external" href="https://cffi.readthedocs.org/en/latest/whatsnew.html#v1-3-0">cffi-1.3</a>: improved manangement of object lifetimes, __stdcall on Win32, ffi.memmove(), and percolate <code class="docutils literal"><span class="pre">const</span></code>, <code class="docutils literal"><span class="pre">restrict</span></code> keywords from cdef to C code.</div>
<div class="section" id="what-is-pypy">
<br><h3 style="text-align: center;">
What is PyPy?</h3>
<br>
PyPy is a very compliant Python interpreter, almost a drop-in replacement for CPython 2.7. It’s fast (<a class="reference external" href="https://speed.pypy.org/">pypy and cpython 2.7.x</a> performance comparison) due to its integrated tracing JIT compiler.<br>
We also welcome developers of other <a class="reference external" href="https://pypyjs.org/">dynamic languages</a> to see what RPython can do for them.<br>
This release supports <b>x86</b> machines on most common operating systems (Linux 32/64, Mac OS X 64, Windows 32, <a class="reference external" href="https://cvsweb.openbsd.org/cgi-bin/cvsweb/ports/lang/pypy">OpenBSD</a>, <a class="reference external" href="https://svnweb.freebsd.org/ports/head/lang/pypy/">freebsd</a>), as well as newer <b>ARM</b> hardware (ARMv6 or ARMv7, with VFPv3) running Linux.<br>
We also introduce <a class="reference external" href="../posts/2015/10/powerpc-backend-for-jit-3014100267884692148.html">support for the 64 bit PowerPC</a> hardware, specifically Linux running the big- and little-endian variants of ppc64.</div>
<div class="section" id="other-highlights-since-2-6-1-release-two-months-ago">
<h3 style="text-align: center;">
Other Highlights (since 2.6.1 release two months ago)</h3>
<ul class="simple" style="text-align: left;">
<li>
<b>Bug Fixes</b><ul>
<li>Applied OPENBSD downstream fixes</li>
<li>Fix a crash on non-linux when running more than 20 threads</li>
<li>In cffi, ffi.new_handle() is more cpython compliant</li>
<li>Accept unicode in functions inside the _curses cffi backend exactly like cpython</li>
<li>Fix a segfault in itertools.islice()</li>
<li>Use gcrootfinder=shadowstack by default, asmgcc on linux only</li>
<li>Fix ndarray.copy() for upstream compatability when copying non-contiguous arrays</li>
<li>Fix assumption that lltype.UniChar is unsigned</li>
<li>Fix a subtle bug with stacklets on shadowstack</li>
<li>Improve support for the cpython capi in cpyext (our capi compatibility layer). Fixing these issues inspired some thought about cpyext in general, stay tuned for more improvements</li>
<li>When loading dynamic libraries, in case of a certain loading error, retry loading the library assuming it is actually a linker script, like on Arch and Gentoo</li>
<li>Issues reported with our previous release were <a class="reference external" href="https://doc.pypy.org/en/latest/whatsnew-15.11.0.html">resolved</a> after reports from users on our issue tracker at <a class="reference external" href="https://foss.heptapod.net/pypy/pypy/-/issues">https://foss.heptapod.net/pypy/pypy/-/issues</a> or on IRC at #pypy</li>
</ul>
</li>
<li>
<b>New features</b>:<ul>
<li>Add an optimization pass to vectorize loops using x86 SIMD intrinsics.</li>
<li>Support __stdcall on Windows in CFFI</li>
<li>Improve debug logging when using PYPYLOG=???</li>
<li>Deal with platforms with no RAND_egd() in OpenSSL</li>
</ul>
</li>
<li>
<b>Numpy</b>:<ul>
<li>Add support for ndarray.ctypes</li>
<li>Fast path for mixing numpy scalars and floats</li>
<li>Add support for creating Fortran-ordered ndarrays</li>
<li>Fix casting failures in linalg (by extending ufunc casting)</li>
<li>Recognize and disallow (for now) pickling of ndarrays with objects embedded in them</li>
</ul>
</li>
<li>
<b>Performance improvements and refactorings</b>:<ul class="simple">
<li>Reuse hashed keys across dictionaries and sets</li>
<li>Refactor JIT interals to improve warmup time by 20% or so at the cost of a minor regression in JIT speed</li>
<li>Recognize patterns of common sequences in the JIT backends and optimize them</li>
<li>Make the garbage collecter more incremental over external_malloc() calls</li>
<li>Share guard resume data where possible which reduces memory usage</li>
<li>Fast path for zip(list, list)</li>
<li>Reduce the number of checks in the JIT for lst[a:]</li>
<li>Move the non-optimizable part of callbacks outside the JIT</li>
<li>Factor in field immutability when invalidating heap information</li>
<li>Unroll itertools.izip_longest() with two sequences</li>
<li>Minor optimizations after analyzing output from <a class="reference external" href="https://vmprof.readthedocs.org/">vmprof</a> and trace logs</li>
<li>Remove many class attributes in rpython classes</li>
<li>Handle getfield_gc_pure* and getfield_gc_* uniformly in heap.py</li>
<li>Improve simple trace function performance by lazily calling fast2locals and locals2fast only if truly necessary </li>
</ul>
</li>
</ul>
</div>
<div class="document">
<div>
<div class="section" id="pypy-4-0-0">
<div class="section" id="other-highlights-since-2-6-1-release-two-months-ago">
Please try it out and let us know what you think. We welcome feedback, we know you are using PyPy, please tell us about it!<br>
Cheers<br>
The PyPy Team</div>
</div>
</div>
</div>
<br><br><br><br><footer><div class="rst-footer-buttons">
</div>
</footer>
</div>
    </div>
    </article><div class="comment-level comment-level-1">
      <div class="comment comment-8457809226939588640">
        <div class="comment-header">
          <a name="comment-8457809226939588640"></a>
            <span class="author">Gerrit Slonzer</span> wrote on <span class="date">2015-10-29 14:17</span>:
        </div>
        <div class="comment-content">
          <p>With the SIMD run-time detection implemented, has the --jit-backend option become redundant?</p>
        </div>
      </div>
      <div class="comment comment-1850616440123392262">
        <div class="comment-header">
          <a name="comment-1850616440123392262"></a>
            <span class="author">stryker</span> wrote on <span class="date">2015-10-29 18:07</span>:
        </div>
        <div class="comment-content">
          <p>Will a similar release be coming for Python 3.5?</p>
        </div>
      </div>
      <div class="comment comment-7206855077251711344">
        <div class="comment-header">
          <a name="comment-7206855077251711344"></a>
            <span class="author">John M. Camara</span> wrote on <span class="date">2015-10-29 21:44</span>:
        </div>
        <div class="comment-content">
          <p>@Gerrit, they are 2 different things.  One is the option to say you are interested in the SIMD support and the other is a check if SIMD support is available in the HW if you are interested in using it.  I'm sure once SIMD support has been used for some time it will eventually be enabled by default but since it is new and potential could have some unknown issues at this time you have to explicitly enable it at this time.</p>
        </div>
      </div>
      <div class="comment comment-1382153833394463986">
        <div class="comment-header">
          <a name="comment-1382153833394463986"></a>
            <span class="author">Niklas B</span> wrote on <span class="date">2015-10-30 10:07</span>:
        </div>
        <div class="comment-content">
          <p>Awesome, can't wait to try it</p>
        </div>
      </div>
      <div class="comment comment-4667104664338873092">
        <div class="comment-header">
          <a name="comment-4667104664338873092"></a>
            <span class="author">Unknown</span> wrote on <span class="date">2015-10-30 19:31</span>:
        </div>
        <div class="comment-content">
          <p>Well done, thx!</p>
        </div>
      </div>
      <div class="comment comment-5362967467563886400">
        <div class="comment-header">
          <a name="comment-5362967467563886400"></a>
            <span class="author">Travis Griggs</span> wrote on <span class="date">2015-10-31 00:31</span>:
        </div>
        <div class="comment-content">
          <p>I keep watching the progress of PyPy with excitement. Cool things happening here. But I continue to be disappointed that it doesn't tip towards Python3. It's dead to me until that becomes the majority effort. :(</p>
        </div>
      </div>
      <div class="comment comment-6901617115002952051">
        <div class="comment-header">
          <a name="comment-6901617115002952051"></a>
            <span class="author">Carl Friedrich Bolz-Tereick</span> wrote on <span class="date">2015-10-31 00:35</span>:
        </div>
        <div class="comment-content">
          <p>The PyPy project contains a large plurality of interests. A lot of the people working on it are volunteers. So PyPy3 will happen if people within the project become interested in that part, or if new people with that interest join the project. At the moment, this seems not happening, which we can all be sad about. However, blaming anybody with differing interest for that situation feels a bit annoying to me.</p>
        </div>
      </div>
      <div class="comment comment-939996346740470106">
        <div class="comment-header">
          <a name="comment-939996346740470106"></a>
            <span class="author">Travis Griggs</span> wrote on <span class="date">2015-10-31 07:15</span>:
        </div>
        <div class="comment-content">
          <p>Well said, I apologize for any whining tone. It was not my intent to blame or complain. It really was just meant as a lamentation. Thanks for all you do.</p>
        </div>
      </div>
      <div class="comment comment-9038920002488730405">
        <div class="comment-header">
          <a name="comment-9038920002488730405"></a>
            <span class="author">PeteVine</span> wrote on <span class="date">2015-10-31 17:47</span>:
        </div>
        <div class="comment-content">
          <p>What happened to my comment? Surely the benchmark I was proposing is not censorable...</p>
        </div>
      </div>
      <div class="comment comment-1800674213620872159">
        <div class="comment-header">
          <a name="comment-1800674213620872159"></a>
            <span class="author">Maciej Fijalkowski</span> wrote on <span class="date">2015-10-31 18:14</span>:
        </div>
        <div class="comment-content">
          <p>@PeteVine you posted a random executable from dropbox claiming to have pypy with x87 backend. PyPy does not have an x87 backend and this raises suspitions this was just some malware. Now if you want someone to compare one thing against some other thing, please link to sources and not random binaries so the person comparing can look themselves. Additionally you did not post a benchmark, just a link to the binary</p>
        </div>
      </div>
      <div class="comment comment-6359499501352485918">
        <div class="comment-header">
          <a name="comment-6359499501352485918"></a>
            <span class="author">PeteVine</span> wrote on <span class="date">2015-10-31 19:29</span>:
        </div>
        <div class="comment-content">
          <p>Well, I was suggesting benchmarking the 32-bit backends to see how much difference SIMD makes - x87 means the standard fpu whereas the default uses SSE2. I know it's processor archaeology so you may have forgotten pypy even had it ;)<br><br>The ready-to-use pypy distro (built by me) was meant for anyone in possesion of a real set of benchmarks (not synthetic vector stuff) to be able to try it quickly.<br><br>And btw, you could have simply edited the dropbox link out. I'd already tested py3k using this backend and mentioned it in one of the issues on bitbucket so it's far from random.<br><br>@ all the people asking about pypy3 - you have the python 3.2 compatible pypy (py3k) at your disposal even now.</p>
        </div>
      </div>
      <div class="comment comment-7096114148867671580">
        <div class="comment-header">
          <a name="comment-7096114148867671580"></a>
            <span class="author">Armin Rigo</span> wrote on <span class="date">2015-10-31 20:54</span>:
        </div>
        <div class="comment-content">
          <p>@PeteVine: to clarify, PyPy has no JIT backend emitting the old-style x87 fpu instructions.  What you are posting is very likely a PyPy whose JIT doesn't support floats at all.  It emits calls to already-compiled functions, like the one doing addition of float objects, instead of writing a SSE2 float addition on unboxed objects.<br><br>Instead, use the official PyPy and run it with vectorization turned on and off (as documented) on the same modern machine.  This allows an apple-to-apple comparison.</p>
        </div>
      </div>
      <div class="comment comment-7643027642224710306">
        <div class="comment-header">
          <a name="comment-7643027642224710306"></a>
            <span class="author">PeteVine</span> wrote on <span class="date">2015-10-31 22:18</span>:
        </div>
        <div class="comment-content">
          <p>Thanks for clarifying, I must have confused myself after seeing it was i486 compatible.<br><br>Are you saying the only difference between the backends I wanted to benchmark would boil down to jit-emitting performance and not actual pypy performance? (I must admit I tried this a while ago with fibonacci and there was no difference at all).<br><br>In other words, even before vectorization functionality was added, shouldn't it be possible to detect that the non-SSE2 backend is running on newer hardware and use the available SIMD? (e.g. for max. compatibility)</p>
        </div>
      </div>
      <div class="comment comment-3383333846652169537">
        <div class="comment-header">
          <a name="comment-3383333846652169537"></a>
            <span class="author">Armin Rigo</span> wrote on <span class="date">2015-11-03 11:33</span>:
        </div>
        <div class="comment-content">
          <p>@PeteVine Sorry, I don't understand your questions.  Why do you bring the JIT-emitting performance to the table?  And why fibonacci (it's not a benchmark with floats at all)?  And I don't get the last question either ("SIMD" = "vectorization").<br><br>To some people, merely dropping the word "SIMD" into a performance discussion makes them go "ooh nice" even if they don't have a clue what it is.  I hope you're more knowledgeable than that and that I'm merely missing your point :-)</p>
        </div>
      </div>
      <div class="comment comment-7717427434714233871">
        <div class="comment-header">
          <a name="comment-7717427434714233871"></a>
            <span class="author">PeteVine</span> wrote on <span class="date">2015-11-03 13:49</span>:
        </div>
        <div class="comment-content">
          <p>The last part should have been pretty clear as it was referring to the newly added –jit vec=1 so it's not me who's dropping SIMD here (shorthand for different instructions sets) as can be seen in the title of this blog post. <br><br>All this time I was merely interested in comparing the two 32-bit backends, that's all. One's using the i486/x87 instruction set regardless of any jit codes, the other is able take advantage of anything up to SSE2. The quick fibonacci test was all I did so you could have pointed me to a real set of benchmarks instead of throwing these little jabs :)</p>
        </div>
      </div>
      <div class="comment comment-6540283040388637470">
        <div class="comment-header">
          <a name="comment-6540283040388637470"></a>
            <span class="author">Carl Friedrich Bolz-Tereick</span> wrote on <span class="date">2015-11-03 15:12</span>:
        </div>
        <div class="comment-content">
          <p>@PeteVine: ok, there is a misunderstanding somewhere, I think. Let me try to clarify: PyPy's JIT has <i>always</i> used non-SIMD SSE2 instructions to implement floating point operations. We have a slow mode where only x87 instructions are used, but usually don't fall back to that, and it does not make sense to compare against that mode.<br><br>What the new release experimentally added is support for SIMD SSE instructions using autoparallelization when --jit vec=1 is given. This only works if your program uses numpy arrays or other simple list processing code. For details on that (and for benchmarks) it's probably best to read Richard Plangger's <a href="https://pypyvecopt.blogspot.de/" rel="nofollow">blog</a>.<br><br>Does that make sense?</p>
        </div>
      </div>
      <div class="comment comment-2428231896309119812">
        <div class="comment-header">
          <a name="comment-2428231896309119812"></a>
            <span class="author">PeteVine</span> wrote on <span class="date">2015-11-03 15:46</span>:
        </div>
        <div class="comment-content">
          <p>Great, love that explanation! :)<br><br>But please, I'd really like to see how much of a handicap the much-maligned non-SSE2 backend incurs. Could you recommend a set of python (not purely computational) benchmarks so I can put this peevee of mine to rest/test?<br><br>Anyways, @Armin Rigo is a great educator himself judging from his patient replies in the bugtracker! So yeah, kudos to you guys!</p>
        </div>
      </div>
      <div class="comment comment-4846369733586970502">
        <div class="comment-header">
          <a name="comment-4846369733586970502"></a>
            <span class="author">Carl Friedrich Bolz-Tereick</span> wrote on <span class="date">2015-11-03 15:59</span>:
        </div>
        <div class="comment-content">
          <p>If you want to try a proper performance evaluation, the official benchmark set is probably the right one: https://bitbucket.org/pypy/benchmarks/<br><br>However, none of these benchmarks are exercising the new autovectorization. If you're particularly interested in that part, use the benchmarks from Richard's blog.</p>
        </div>
      </div>
      <div class="comment comment-4512951014493326581">
        <div class="comment-header">
          <a name="comment-4512951014493326581"></a>
            <span class="author">NortonCommander4ever</span> wrote on <span class="date">2015-11-09 14:33</span>:
        </div>
        <div class="comment-content">
          <p>Is there a readme on how to use these benchmarks somewhere? (preferably written with windows users in mind, if you know what I mean:))</p>
        </div>
      </div>
         </div>

    <article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="../posts/2015/10/automatic-simd-vectorization-support-in-639063580401330508.html" class="u-url">Automatic SIMD vectorization support in PyPy</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                <a href="../authors/richard-plangger.html">Richard Plangger</a>
            </span></p>
            <p class="dateline">
            <a href="../posts/2015/10/automatic-simd-vectorization-support-in-639063580401330508.html" rel="bookmark">
            <time class="published dt-published" datetime="2015-10-20T14:38:00Z" itemprop="datePublished" title="2015-10-20 14:38">2015-10-20 14:38</time></a>
            </p>
                <p class="commentline">5 comments</p>

        </div>
    </header><div class="p-summary entry-summary">
    <div dir="ltr" style="text-align: left;">
Hi everyone,<br><br>
it took some time to catch up with the JIT refacrtorings merged in this summer. <span style="font-size: small;">But, (drums) we are happy to announce that:</span><br><br><h2 style="text-align: center;">
<span style="font-size: large;">The next release of PyPy,  "PyPy 4.0.0", will ship the new auto vectorizer</span>
</h2>
<span style="font-size: small;">The goal of this project was to increase the speed of numerical applications in both the NumPyPy library and for arbitrary Python programs. In PyPy we have focused a lot on improvements in the 'typical python workload',  which usually involves object and string manipulations, mostly for web development. We're hoping with this work that we'll continue improving the other very important Python use case - numerics.</span><br><br><h2>
<span style="font-size: small;"><span style="font-size: large;">What it can do!</span> </span>
</h2>
<span style="font-size: small;">It targets numerics only. It 
will not execute object manipulations faster, but it is capable of 
enhancing common vector and matrix operations.</span><br>
Good news is that it is not specifically targeted for the NumPy library and the PyPy 
virtual machine. Any interpreter (written in RPython) is able make use 
of the vectorization. For more information about that take a look <a href="https://pypyvecopt.blogspot.co.at/">here</a>, or consult the documentation. For the time being it is not turn on by default, so be sure to enable it by specifying <span>--jit vec=1<span style="font-family: inherit;"> </span></span>before running your program.<br><br>
If your language (written in RPython) contains many array/matrix operations, you can easily integrate the optimization by adding the parameter 'vec=1' to the JitDriver.<br><br><h2>
<span style="font-size: large;">NumPyPy Improvements</span>
</h2>
<span style="font-size: small;"></span>
<span style="font-size: small;">Let's take a look at the core functions of the NumPyPy library (*). </span><br><span style="font-size: small;">The following tests tests show the speedup of the core functions commonly used in Python code interfacing with NumPy, on CPython with NumPy, on the PyPy 2.6.1 relased several weeks ago, and on PyPy 15.11 to be released soon. Timeit was used to test the time needed to run the operation in the plot title on various vector (lower case) and square matrix (upper case) sizes displayed on the X axis. The Y axis shows the speedup compared to CPython 2.7.10. <b>This means that higher is better</b>. </span><br><br><div class="separator" style="clear: both; text-align: center;">
<a href="https://3.bp.blogspot.com/-aqC2wMdVRaU/ViUZJYlUNoI/AAAAAAAAAXQ/FGa9DfdDZ-4/s1600/matrix-vector.png" style="clear: left; float: left; margin-bottom: 1em; margin-right: 1em;"><img border="0" height="353" src="https://3.bp.blogspot.com/-aqC2wMdVRaU/ViUZJYlUNoI/AAAAAAAAAXQ/FGa9DfdDZ-4/s640/matrix-vector.png" width="640"></a>
</div>
<br><div class="separator" style="clear: both; text-align: center;">
</div>
<div class="separator" style="clear: both; text-align: center;">
</div>
<span style="font-size: small;">In comparison to PyPy 2.6.1, the speedup </span><span style="font-size: small;"><span style="font-size: small;">greatly</span> improved. The hardware support really strips down the runtime of the vector and matrix operations. There is another operation we would like to highlight: the dot product.</span><br><span style="font-size: small;">It is a very common operation in numerics and PyPy now (given a moderate sized matrix and vector) decreases the time spent in that operation. See for yourself:</span><br><br><div class="separator" style="clear: both; text-align: center;">
<a href="https://3.bp.blogspot.com/-TMuz6OUEOXU/ViUZWEng4AI/AAAAAAAAAXY/dZOYp1LO1G0/s1600/dotproduct.png" style="clear: left; float: left; margin-bottom: 1em; margin-right: 1em;"><img border="0" height="353" src="https://3.bp.blogspot.com/-TMuz6OUEOXU/ViUZWEng4AI/AAAAAAAAAXY/dZOYp1LO1G0/s640/dotproduct.png" width="640"></a>
</div>
<div class="separator" style="clear: both; text-align: center;">
</div>
These are nice improvements in the NumPyPy library and we got to a competitive level only making use of SSE4.1.<br><br><h2>
<span style="font-size: large;">Future work   </span>
</h2>
<br><span style="font-size: small;">This is not the end of the road. The GSoC project showed that it is possible to implement this optimization in PyPy. There might be other improvements we can make to carry this further:</span><br><ul>
<li><span style="font-size: small;">Check alignment at runtime to increase the memory throughput of the CPU</span></li>
<li><span style="font-size: small;">Support the AVX vector extension which (at least) doubles the size of the vector register</span></li>
<li><span style="font-size: small;">Handle each and every corner case in Python traces to enable it  globally</span></li>
<li><span style="font-size: small;">Do not rely only on loading operations to trigger the analysis, there might be cases where combination of floating point values could be done in parallel </span></li>
</ul>
Cheers,<br>
The PyPy Team<br><h4>
<span style="font-size: x-small;">(*) The benchmark code can be found <a href="https://bitbucket.org/plan_rich/numpy-benchmark">here</a> it was run using this configuration: i7-2600 CPU @ 3.40GHz (4 cores). </span>
</h4>
</div>
    </div>
    </article><div class="comment-level comment-level-1">
      <div class="comment comment-6415622804704063612">
        <div class="comment-header">
          <a name="comment-6415622804704063612"></a>
            <span class="author">Nax</span> wrote on <span class="date">2015-10-20 20:27</span>:
        </div>
        <div class="comment-content">
          <p>Which BLAS are u using for CPython Numpy? OpenBlas?</p>
        </div>
      </div>
      <div class="comment comment-1762281512266856308">
        <div class="comment-header">
          <a name="comment-1762281512266856308"></a>
            <span class="author">crusaderky</span> wrote on <span class="date">2015-10-20 22:20</span>:
        </div>
        <div class="comment-content">
          <p>How does it compare to numexpr on those benchmarks?<br><br>Also, any plan of addressing one of the killer features of numexpr, that is the fact that an operation like y += a1*x1 + a2*x2 + a3*x3 will create 5 temporary vectors and make a horrible usage of the CPU cache?</p>
        </div>
      </div>
      <div class="comment comment-5396005631073603997">
        <div class="comment-header">
          <a name="comment-5396005631073603997"></a>
            <span class="author">Anonymous</span> wrote on <span class="date">2015-10-21 05:03</span>:
        </div>
        <div class="comment-content">
          <p>I don't know anyone who uses NumPy for arrays with less than 128 elements.<br><br>Your own benchmark shows NumPypy is much slower than NumPy for large arrays...</p>
        </div>
      </div>
      <div class="comment comment-1760897275212905250">
        <div class="comment-header">
          <a name="comment-1760897275212905250"></a>
            <span class="author">Unknown</span> wrote on <span class="date">2015-10-21 08:44</span>:
        </div>
        <div class="comment-content">
          <p>NumPyPy is currently not complete. Trying to evaluate any numexpr gives a strange error. I guess the problem is a missing field not exported by NumPyPy.<br>However we will see how far we can get with this approach. I have made some thoughts on how we could make good use of graphics cards, but this is future work.</p>
        </div>
      </div>
      <div class="comment comment-3165332329721579242">
        <div class="comment-header">
          <a name="comment-3165332329721579242"></a>
            <span class="author">René Dudfield</span> wrote on <span class="date">2015-10-21 11:14</span>:
        </div>
        <div class="comment-content">
          <p>Nice work!</p>
        </div>
      </div>
         </div>

    <article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="../posts/2015/10/powerpc-backend-for-jit-3014100267884692148.html" class="u-url">PowerPC backend for the JIT</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                <a href="../authors/armin-rigo.html">Armin Rigo</a>
            </span></p>
            <p class="dateline">
            <a href="../posts/2015/10/powerpc-backend-for-jit-3014100267884692148.html" rel="bookmark">
            <time class="published dt-published" datetime="2015-10-16T17:08:00Z" itemprop="datePublished" title="2015-10-16 17:08">2015-10-16 17:08</time></a>
            </p>
            
        </div>
    </header><div class="p-summary entry-summary">
    <p>Hi all,</p>

<p>PyPy's JIT now supports the 64-bit PowerPC architecture!  This is the
third architecture supported, in addition to x86 (32 and 64) and ARM
(32-bit only).  More precisely, we support Linux running the big- and the
little-endian variants of ppc64.  Thanks to IBM for funding this work!</p>

<p>The new JIT backend has been merged into "default".  You should be able
to translate PPC versions
<a href="https://pypy.org/download.html#building-from-source">as usual</a>
directly on the machines.  For
the foreseeable future, I will compile and distribute binary versions
corresponding to the official releases (for Fedora), but of course I'd
welcome it if someone else could step in and do it.  Also, it is unclear
yet if we will run a buildbot.</p>

<p>To check that the result performs well, I logged in a ppc64le machine
and ran the usual benchmark suite of PyPy (minus sqlitesynth: sqlite
was not installed on that machine).  I ran it twice at a difference of
12 hours, as an attempt to reduce risks caused by other users suddenly
using the machine.  The machine was overall relatively quiet.  Of
course, this is scientifically not good enough; it is what I could come
up with given the limited resources.</p>

<p>Here are the results, where the numbers are speed-up factors between the
non-jit and the jit version of PyPy.  The first column is x86-64, for
reference.  The second and third columns are the two ppc64le runs.  All
are Linux.  A few benchmarks are not reported here because the runner
doesn't execute them on non-jit (however, apart from sqlitesynth, they
all worked).</p>

<pre>
    ai                        13.7342        16.1659     14.9091
    bm_chameleon               8.5944         8.5858        8.66
    bm_dulwich_log             5.1256         5.4368      5.5928
    bm_krakatau                5.5201         2.3915      2.3452
    bm_mako                    8.4802         6.8937      6.9335
    bm_mdp                     2.0315         1.7162      1.9131
    chaos                     56.9705        57.2608     56.2374
    sphinx
    crypto_pyaes               62.505         80.149     79.7801
    deltablue                  3.3403         5.1199      4.7872
    django                    28.9829         23.206       23.47
    eparse                     2.3164         2.6281       2.589
    fannkuch                   9.1242        15.1768     11.3906
    float                     13.8145        17.2582     17.2451
    genshi_text               16.4608        13.9398     13.7998
    genshi_xml                 8.2782         8.0879      9.2315
    go                         6.7458        11.8226     15.4183
    hexiom2                   24.3612        34.7991     33.4734
    html5lib                   5.4515         5.5186       5.365
    json_bench                28.8774        29.5022     28.8897
    meteor-contest             5.1518         5.6567      5.7514
    nbody_modified            20.6138        22.5466     21.3992
    pidigits                   1.0118          1.022      1.0829
    pyflate-fast               9.0684        10.0168     10.3119
    pypy_interp                3.3977         3.9307      3.8798
    raytrace-simple           69.0114       108.8875    127.1518
    richards                  94.1863       118.1257    102.1906
    rietveld                   3.2421         3.0126      3.1592
    scimark_fft
    scimark_lu
    scimark_montecarlo
    scimark_sor
    scimark_sparsematmul
    slowspitfire               2.8539         3.3924      3.5541
    spambayes                  5.0646         6.3446       6.237
    spectral-norm             41.9148        42.1831     43.2913
    spitfire                   3.8788         4.8214       4.701
    spitfire_cstringio          7.606         9.1809      9.1691
    sqlitesynth
    sympy_expand               2.9537         2.0705      1.9299
    sympy_integrate            4.3805         4.3467      4.7052
    sympy_str                  1.5431         1.6248      1.5825
    sympy_sum                  6.2519          6.096      5.6643
    telco                     61.2416        54.7187     55.1705
    trans2_annotate
    trans2_rtype
    trans2_backendopt
    trans2_database
    trans2_source
    twisted_iteration         55.5019        51.5127     63.0592
    twisted_names              8.2262         9.0062      10.306
    twisted_pb                12.1134         13.644     12.1177
    twisted_tcp                4.9778          1.934      5.4931

    GEOMETRIC MEAN               9.31           9.70       10.01
</pre>

<p>The last line reports the geometric mean of each column.  We see that
the goal was reached: PyPy's JIT actually improves performance by a
factor of around 9.7 to 10 times on ppc64le.  By comparison, it "only"
improves performance by a factor 9.3 on Intel x86-64.  I don't know why,
but I'd guess it mostly means that a non-jitted PyPy performs slightly
better on Intel than it does on PowerPC.</p>

<p>Why is that?  Actually, if we do the same comparison with an ARM
column too, we also get higher numbers there than on Intel.
When we discovered that a few years ago, we guessed that
on ARM running the whole interpreter in
PyPy takes up a lot of resources, e.g. of instruction cache, which the
JIT's assembler doesn't need any more after the process is warmed up.
And caches are much bigger on Intel.  However, PowerPC is much closer
to Intel, so this argument doesn't work for PowerPC.
But there are other more subtle
variants of it.  Notably, Intel is doing crazy things about branch
prediction, which likely helps a big interpreter---both the non-JITted
PyPy and CPython, and both for the interpreter's main loop itself and
for the numerous indirect branches that depend on the types of the
objects.  Maybe the PowerPC is as good as Intel, and so this argument
doesn't work either.  Another one would be:
on PowerPC I did notice that gcc itself is not
perfect at optimization.  During development of this backend, I often
looked at assembler produced by gcc, and there are a number of small
inefficiencies there.  All these are factors that slow down the
non-JITted version of PyPy, but don't influence the speed of the
assembler produced just-in-time.</p>

<p>Anyway, this is just guessing.  The fact remains that PyPy can now
be used on PowerPC machines.  Have fun!</p>

<p>A bientôt,</p>

<p>Armin.</p>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="../posts/2015/10/pypy-memory-and-warmup-improvements-2-4598780879518640015.html" class="u-url">PyPy memory and warmup improvements (2) - Sharing of Guards</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                <a href="../authors/maciej-fijalkowski.html">Maciej Fijalkowski</a>
            </span></p>
            <p class="dateline">
            <a href="../posts/2015/10/pypy-memory-and-warmup-improvements-2-4598780879518640015.html" rel="bookmark">
            <time class="published dt-published" datetime="2015-10-05T10:31:00Z" itemprop="datePublished" title="2015-10-05 10:31">2015-10-05 10:31</time></a>
            </p>
                <p class="commentline">2 comments</p>

        </div>
    </header><div class="p-summary entry-summary">
    <div dir="ltr" style="text-align: left;">
<p>Hello everyone!</p>
<p>This is the second part of the series of improvements in warmup time and
memory consumption in the PyPy JIT. This post covers recent work on sharing guard
resume data that was recently merged to trunk. It will be a part
of the next official PyPy release. To understand what it does, let's
start with a loop for a simple example:</p>
<pre class="literal-block">
class A(object):
    def __init__(self, x, y):
        self.x = x
        self.y = y

    def call_method(self, z):
        return self.x + self.y + z

def f():
    s = 0
    for i in range(100000):
        a = A(i, 1 + i)
        s += a.call_method(i)
</pre>
<p>At the entrance of the loop, we have the following set of operations:</p>
<pre class="literal-block">
<div style="color: red;">guard(i5 == 4)</div>
<div style="color: red;">guard(p3 is null)</div>
p27 = p2.co_cellvars
p28 = p2.co_freevars
<div style="color: red;">guard_class(p17, 4316866008, descr=&lt;Guard0x104295e08&gt;)</div>
p30 = p17.w_seq
<div style="color: red;">guard_nonnull(p30, descr=&lt;Guard0x104295db0&gt;)</div>
i31 = p17.index
p32 = p30.strategy
<div style="color: red;">guard_class(p32, 4317041344, descr=&lt;Guard0x104295d58&gt;)</div>
p34 = p30.lstorage
i35 = p34..item0
</pre>
<p>The above operations gets executed at the entrance, so each time we call <tt class="docutils literal">f()</tt>. They ensure
all the optimizations done below stay valid. Now, as long as nothing
out of the ordinary happens, they only ensure that the world around us never changed. However, if e.g. someone puts new
methods on class <tt class="docutils literal">A</tt>, any of the above guards might fail. Despite the fact that it's a very unlikely
case, PyPy needs to track how to recover from such a situation. Each of those points needs to keep the full
state of the optimizations performed, so we can safely deoptimize them and reenter the interpreter.
This is vastly wasteful since most of those guards never fail, hence some <a href="https://www.stups.uni-duesseldorf.de/mediawiki/images/c/c4/Pub-schneider_efficient_2012.pdf">sharing between guards</a>
has been performed.</p>
<p>We went a step further - when two guards are next to each other or the
operations in between them don't have side effects, we can safely redo the operations or to simply
put, resume in the previous guard. That means every now and again we execute a few
operations extra, but not storing extra info saves quite a bit of time and memory. This is similar to the approach that LuaJIT takes, which is called <a href="https://lua-users.org/lists/lua-l/2009-11/msg00089.html">sparse snapshots</a>.</p>

<p>
I've done some measurements on annotating &amp; rtyping translation of pypy, which
is a pretty memory hungry program that compiles a fair bit. I measured, respectively:</p>
<ul class="simple">
<li>total time the translation step took (annotating or rtyping)</li>
<li>time it took for tracing (that excludes backend time for the total JIT time) at
the end of rtyping.</li>
<li>memory the GC feels responsible for after the step. The real amount of memory
consumed will always be larger and the coefficient of savings is in 1.5-2x mark</li>
</ul>
<p>Here is the table:</p>
<table border="1" class="docutils">
<colgroup>
<col width="10%">
<col width="19%">
<col width="16%">
<col width="21%">
<col width="18%">
<col width="16%">
</colgroup>
<thead valign="bottom"><tr>
<th class="head">branch</th>
<th class="head">time annotation</th>
<th class="head">time rtyping</th>
<th class="head">memory annotation</th>
<th class="head">memory rtyping</th>
<th class="head">tracing time</th>
</tr></thead>
<tbody valign="top">
<tr>
<td>default</td>
<td>317s</td>
<td>454s</td>
<td>707M</td>
<td>1349M</td>
<td>60s</td>
</tr>
<tr>
<td>sharing</td>
<td>302s</td>
<td>430s</td>
<td>595M</td>
<td>1070M</td>
<td>51s</td>
</tr>
<tr>
<td>win</td>
<td>4.8%</td>
<td>5.5%</td>
<td>19%</td>
<td>26%</td>
<td>17%</td>
</tr>
</tbody>
</table>
<p>Obviously pypy translation is an extreme example - the vast majority of the code out there
does not have that many lines of code to be jitted. However, it's at the very least
a good win for us :-)</p>
<p>We will continue to improve the warmup performance and keep you posted!</p>
<p>Cheers,<br>
fijal</p>
</div>
<br>
</div>
    </article><div class="comment-level comment-level-1">
      <div class="comment comment-1531358888873254249">
        <div class="comment-header">
          <a name="comment-1531358888873254249"></a>
            <span class="author">Ernst Sjöstrand</span> wrote on <span class="date">2015-10-05 20:14</span>:
        </div>
        <div class="comment-content">
          <p>"when two guards are next to each other or the operations in between them don't have side effects, we can safely redo the operations or to simply put, resume in the previous guard"<br>Wait... "side effects", "redo"... Does this have synergies with STM?</p>
        </div>
      </div>
      <div class="comment comment-3889738160354780660">
        <div class="comment-header">
          <a name="comment-3889738160354780660"></a>
            <span class="author">Maciej Fijalkowski</span> wrote on <span class="date">2015-10-06 05:45</span>:
        </div>
        <div class="comment-content">
          <p>Side effect operation is one that does not have any side effects. This means that you can execute the operation again (e.g. reading a field or adding two numbers) and will affect nothing but it's result. As for redo - well, it has nothing to do with STM, but doing pure operations again can be sometimes useful (in short - if you have i = a + b, you don't remember the i, just a, b and that i = a + b)</p>
        </div>
      </div>
         </div>

    <article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="../posts/2015/09/pypy-warmup-improvements-8349465374608676233.html" class="u-url">PyPy warmup improvements</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                <a href="../authors/maciej-fijalkowski.html">Maciej Fijalkowski</a>
            </span></p>
            <p class="dateline">
            <a href="../posts/2015/09/pypy-warmup-improvements-8349465374608676233.html" rel="bookmark">
            <time class="published dt-published" datetime="2015-09-09T15:52:00Z" itemprop="datePublished" title="2015-09-09 15:52">2015-09-09 15:52</time></a>
            </p>
            
        </div>
    </header><div class="p-summary entry-summary">
    <div dir="ltr" style="text-align: left;">

<p>Hello everyone!</p>
<p>I'm very pleased to announce that we've just managed to merge
the optresult branch.
Under this cryptic name is the biggest JIT refactoring we've done in a couple
years, mostly focused on the warmup time and memory impact of PyPy.</p>
<p>To understand why we did that, let's look back in time - back when we
got the first working JIT prototype in 2009 we were focused exclusively
on achieving peak performance with some consideration towards memory usage, but
without serious consideration towards warmup time. This means we accumulated
quite a bit of technical debt over time that we're trying, with difficulty,
to address right now. This branch mostly does not affect the peak performance
- it should however help you with short-living scripts, like test runs.</p>
<p>We identified warmup time to be one of the major pain points for pypy users,
along with memory impact and compatibility issues with CPython C extension
world. While we can't address all the issues at once, we're trying to address
the first two in the work contributing to this blog post. I will write
a separate article on the last item separately.</p>
<p>To see how much of a problem warmup is for your program, you can run your
program with <tt class="docutils literal"><span class="pre">PYPYLOG=jit-summary:-</span></tt> environment variable set.
This should show you something like this:</p>
<pre class="literal-block">
(pypy-optresult)fijal@hermann:~/src/botbot-web$ PYPYLOG=jit-summary:- python orm.py 1500
[d195a2fcecc] {jit-summary
Tracing:            781     2.924965
Backend:            737     0.722710
TOTAL:                      35.912011
ops:                1860596
recorded ops:       493138
  calls:            81022
guards:             131238
opt ops:            137263
opt guards:         35166
forcings:           4196
abort: trace too long:      22
abort: compiling:   0
abort: vable escape:        22
abort: bad loop:    0
abort: force quasi-immut:   0
nvirtuals:          183672
nvholes:            25797
nvreused:           116131
Total # of loops:   193
Total # of bridges: 575
Freed # of loops:   6
Freed # of bridges: 75
[d195a48de18] jit-summary}
</pre>
<p>This means that the total (wall clock) time was 35.9s, out of which we spent
2.9s tracing 781 loops and 0.72s compiling them. The remaining couple were
aborted (trace too long is normal, vable escape means someone called
<tt class="docutils literal">sys._getframe()</tt> or equivalent). You can do the following things:</p>
<ul class="simple">
<li>compare the numbers with <tt class="docutils literal">pypy <span class="pre">--jit</span> off</tt> and see at which number of
iterations <tt class="docutils literal">pypy</tt> jit kicks in</li>
<li>play with the thresholds:
<tt class="docutils literal">pypy <span class="pre">--jit</span> threshold=500,function_threshold=400,trace_eagerness=50</tt> was
much better in this example. What this does is to lower the threshold
for tracing loops from default of 1039 to 400, threshold for tracing
functions from the start from 1619 to 500 and threshold for tracing bridges
from 200 to 50. Bridges are "alternative paths" that JIT did not take that
are being additionally traced. We believe in sane defaults, so we'll try
to improve upon those numbers, but generally speaking there is no one-size
fits all here.</li>
<li>if the tracing/backend time stays high, come and complain to us with
benchmarks, we'll try to look at them</li>
</ul>
<p>Warmup, as a number, is notoriously hard to measure. It's a combination of:</p>
<ul class="simple">
<li>pypy running interpreter before jitting</li>
<li>pypy needing time to JIT the traces</li>
<li>additional memory allocations needed during tracing to accomodate bookkeeping
data</li>
<li>exiting and entering assembler until there is enough coverage of assembler</li>
</ul>
<p>We're working hard on making a better assesment at this number, stay tuned :-)</p>
<div class="section" id="speedups">
<h1>Speedups</h1>
<p>Overall we measured about 50% speed improvement in the optimizer, which reduces
the overall warmup time between 10% and 30%. The very
<a class="reference external" href="https://bitbucket.org/pypy/benchmarks/src/fe2e89c0ae6846e3a8d4142106a4857e95f17da7/warmup/function_call2.py?at=default">obvious warmup benchmark</a> got a speedup from 4.5s to 3.5s, almost
30% improvement. Obviously the speedups on benchmarks would vastly
depend on how much warmup time is there in those benchmarks. We observed
annotation of pypy to decreasing by about 30% and the overall translation
time by about 7%, so your mileage may vary.</p>
<p>Of course, as usual with the large refactoring of a crucial piece of PyPy,
there are expected to be bugs. We are going to wait for the default branch
to stabilize so you should see warmup improvements in the next release.
If you're not afraid to try, <a class="reference external" href="https://buildbot.pypy.org/nightly/trunk">nightlies</a> will already have them.</p>
<p>We're hoping to continue improving upon warmup time and memory impact in the
future, stay tuned for improvements.</p>
</div>
<div class="section" id="technical-details">
<h1>Technical details</h1>
<p>The branch does "one" thing - it changes the underlying model of how operations
are represented during tracing and optimizations. Let's consider a simple
loop like:</p>
<pre class="literal-block">
[i0, i1]
i2 = int_add(i0, i1)
i3 = int_add(i2, 1)
i4 = int_is_true(i3)
guard_true(i4)
jump(i3, i2)
</pre>
<p>The original representation would allocate a <tt class="docutils literal">Box</tt> for each of <tt class="docutils literal">i0</tt> - <tt class="docutils literal">i4</tt>
and then store those boxes in instances of <tt class="docutils literal">ResOperation</tt>. The list of such
operations would then go to the optimizer. Those lists are big - we usually
remove <tt class="docutils literal">90%</tt> of them during optimizations, but they can be a couple thousand
elements. Overall, allocating those big lists takes a toll on warmup time,
especially due to the GC pressure. The branch removes the existance of <tt class="docutils literal">Box</tt>
completely, instead using a link to <tt class="docutils literal">ResOperation</tt> itself. So say in the above
example, <tt class="docutils literal">i2</tt> would refer to its producer - <tt class="docutils literal">i2 = int_add(i0, i1)</tt> with
arguments getting special treatment.</p>
<p>That alone reduces the GC pressure slightly, but a reduced number
of instances also lets us store references on them directly instead
of going through expensive dictionaries, which were used to store optimizing
information about the boxes.</p>
<p>Cheers!<br>
fijal &amp; arigo</p>
</div>

<br>
</div>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="../posts/2015/08/pypy-261-released-3638960649983103796.html" class="u-url">PyPy 2.6.1 released</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                <a href="../authors/mattip.html">mattip</a>
            </span></p>
            <p class="dateline">
            <a href="../posts/2015/08/pypy-261-released-3638960649983103796.html" rel="bookmark">
            <time class="published dt-published" datetime="2015-08-31T16:52:00Z" itemprop="datePublished" title="2015-08-31 16:52">2015-08-31 16:52</time></a>
            </p>
                <p class="commentline">5 comments</p>

        </div>
    </header><div class="p-summary entry-summary">
    <div dir="ltr" style="text-align: left;">
<div class="document">
<div>
<div class="section" id="pypy-2-6-1">
<h1>
PyPy 2.6.1</h1>
We’re pleased to announce PyPy 2.6.1, an update to PyPy 2.6.0 released June 1.
We have fixed many issues, updated stdlib to 2.7.10, <a class="reference external" href="https://cffi.readthedocs.org/">cffi</a> to version 1.3, extended support for
the new <a class="reference external" href="https://vmprof.readthedocs.org/">vmprof</a> statistical profiler for multiple threads, and increased
functionality of numpy.<br>
You can download the PyPy 2.6.1 release here:<br><blockquote>
<div>
<a class="reference external" href="https://pypy.org/download.html">https://pypy.org/download.html</a>
</div>
</blockquote>
We would like to thank our donors for the continued support of the PyPy
project, and our volunteers and contributors.<br><br>
We would also like to encourage new people to join the project. PyPy has many
layers and we need help with all of them: <a class="reference external" href="https://doc.pypy.org/">PyPy</a> and <a class="reference external" href="https://rpython.readthedocs.org/">RPython</a> documentation
improvements, tweaking popular <a class="reference external" href="https://doc.pypy.org/en/latest/project-ideas.html#make-more-python-modules-pypy-friendly">modules</a> to run on pypy, or general <a class="reference external" href="https://doc.pypy.org/en/latest/project-ideas.html">help</a> with making
RPython’s JIT even better.<br><br><div class="section" id="what-is-pypy">
<h2>
What is PyPy?</h2>
PyPy is a very compliant Python interpreter, almost a drop-in replacement for
CPython 2.7. It’s fast (<a class="reference external" href="https://speed.pypy.org/">pypy and cpython 2.7.x</a> performance comparison)
due to its integrated tracing JIT compiler.<br><br>
This release supports <b>x86</b> machines on most common operating systems
(Linux 32/64, Mac OS X 64, Windows 32, <a class="reference external" href="https://cvsweb.openbsd.org/cgi-bin/cvsweb/ports/lang/pypy">OpenBSD</a>, <a class="reference external" href="https://svnweb.freebsd.org/ports/head/lang/pypy/">freebsd</a>),
as well as newer <b>ARM</b> hardware (ARMv6 or ARMv7, with VFPv3) running Linux.<br><br>
We also welcome developers of other
<a class="reference external" href="https://pypyjs.org/">dynamic languages</a> to see what RPython can do for them.</div>
<br><div class="section" id="highlights">
<h2>
Highlights</h2>
<ul class="simple">
<li>Bug Fixes<ul>
<li>Revive non-SSE2 support</li>
<li>Fixes for detaching _io.Buffer*</li>
<li>On Windows, close (and flush) all open sockets on exiting</li>
<li>Drop support for ancient macOS v10.4 and before</li>
<li>Clear up contention in the garbage collector between trace-me-later and pinning</li>
<li>Issues reported with our previous release were <a class="reference external" href="https://doc.pypy.org/en/latest/whatsnew-2.6.1.html">resolved</a> after reports from users on
our issue tracker at <a class="reference external" href="https://foss.heptapod.net/pypy/pypy/-/issues">https://foss.heptapod.net/pypy/pypy/-/issues</a> or on IRC at
#pypy.</li>
</ul>
</li>
<li>New features:<ul>
<li>cffi was updated to version 1.3</li>
<li>The python stdlib was updated to 2.7.10 from 2.7.9</li>
<li>vmprof now supports multiple threads and OS X</li>
<li>The translation process builds cffi import libraries for some stdlib
packages, which should prevent confusion when package.py is not used</li>
<li>better support for gdb debugging</li>
<li>freebsd should be able to translate PyPy “out of the box” with no patches</li>
</ul>
</li>
<li>Numpy:<ul>
<li>Better support for record dtypes, including the <code class="docutils literal"><span class="pre">align</span></code> keyword</li>
<li>Implement casting and create output arrays accordingly (still missing some corner cases)</li>
<li>Support creation of unicode ndarrays</li>
<li>Better support ndarray.flags</li>
<li>Support <code class="docutils literal"><span class="pre">axis</span></code> argument in more functions</li>
<li>Refactor array indexing to support ellipses</li>
<li>Allow the docstrings of built-in numpy objects to be set at run-time</li>
<li>Support the <code class="docutils literal"><span class="pre">buffered</span></code> nditer creation keyword</li>
</ul>
</li>
<li>Performance improvements:<ul>
<li>Delay recursive calls to make them non-recursive</li>
<li>Skip loop unrolling if it compiles too much code</li>
<li>Tweak the heapcache</li>
<li>Add a list strategy for lists that store both floats and 32-bit integers.
The latter are encoded as nonstandard NaNs.  Benchmarks show that the speed
of such lists is now very close to the speed of purely-int or purely-float
lists.</li>
<li>Simplify implementation of ffi.gc() to avoid most weakrefs</li>
<li>Massively improve the performance of map() with more than
one sequence argument</li>
</ul>
</li>
</ul>
Please try it out and let us know what you think. We welcome
success stories, <a class="reference external" href="../posts/2015/02/experiments-in-pyrlang-with-rpython-8103387814587972227.html">experiments</a>,  or <a class="reference external" href="https://mithrandi.net/blog/2015/03/axiom-benchmark-results-on-pypy-2-5-0">benchmarks</a>, we know you are using PyPy, please tell us about it!<br>
Cheers<br>
The PyPy Team</div>
</div>
</div>
</div>
</div>
    </div>
    </article><div class="comment-level comment-level-1">
      <div class="comment comment-9008066287414414328">
        <div class="comment-header">
          <a name="comment-9008066287414414328"></a>
            <span class="author">Anonymous</span> wrote on <span class="date">2015-09-02 13:28</span>:
        </div>
        <div class="comment-content">
          <p>Cool! Really nice, thank you. Any ETA for Python 3.3 compatibility in pypy?</p>
        </div>
      </div>
      <div class="comment comment-7797966067492280542">
        <div class="comment-header">
          <a name="comment-7797966067492280542"></a>
            <span class="author">xndxn</span> wrote on <span class="date">2015-09-03 17:37</span>:
        </div>
        <div class="comment-content">
          <p>Thanks!</p>
        </div>
      </div>
      <div class="comment comment-4379175129083615487">
        <div class="comment-header">
          <a name="comment-4379175129083615487"></a>
            <span class="author">Anonymous</span> wrote on <span class="date">2015-09-03 18:56</span>:
        </div>
        <div class="comment-content">
          <p>Thanks!</p>
        </div>
      </div>
      <div class="comment comment-142023445064379828">
        <div class="comment-header">
          <a name="comment-142023445064379828"></a>
            <span class="author">Anonymous</span> wrote on <span class="date">2015-09-04 05:01</span>:
        </div>
        <div class="comment-content">
          <p>Still waiting for PyPy3's update. The latest version of PyPy is much faster than the latest version of PyPy3. Please update soon. :)</p>
        </div>
      </div>
      <div class="comment comment-3203204722587062798">
        <div class="comment-header">
          <a name="comment-3203204722587062798"></a>
            <span class="author">PeteVine</span> wrote on <span class="date">2015-09-14 00:03</span>:
        </div>
        <div class="comment-content">
          <p>Contrary to what the front page is still saying, the non-SSE2 backend for older x86 processors is fully working and can be built from source, which takes almost 7h on a 2.2GHz Athlon XP.<br><br>You can download a 2.6.1 build from here:<br><br>https://www.dropbox.com/sh/6i7ktwv9551asfc/AADOd55Br0lDJRH8HsKpbIwTa?dl=0<br><br>It should work on any P2 class processor.</p>
        </div>
      </div>
         </div>

    <article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="../posts/2015/06/pypy-and-ijson-guest-blog-post-8143007374752482637.html" class="u-url">PyPy and ijson - a guest blog post</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                <a href="../authors/mattip.html">mattip</a>
            </span></p>
            <p class="dateline">
            <a href="../posts/2015/06/pypy-and-ijson-guest-blog-post-8143007374752482637.html" rel="bookmark">
            <time class="published dt-published" datetime="2015-06-17T19:45:00Z" itemprop="datePublished" title="2015-06-17 19:45">2015-06-17 19:45</time></a>
            </p>
                <p class="commentline">4 comments</p>

        </div>
    </header><div class="p-summary entry-summary">
    <div dir="ltr" style="text-align: left;">
This gem was posted in the <a href="https://github.com/isagalaev/ijson/issues/35" target="_blank">ijson issue tracker</a> after some discussion on #pypy, and Dav1dde kindly allowed us to repost it here:<br><br><span style="font-family: Arial,Helvetica,sans-serif;">"</span>So, I was playing around with parsing huge JSON files (19GiB, testfile is ~520MiB) and wanted to try a sample code with PyPy, turns out, PyPy needed ~1:30-2:00 whereas CPython 2.7 needed ~13 seconds (the pure python implementation on both pythons was equivalent at ~8 minutes). <br><br>"Apparantly ctypes is really bad performance-wise, especially on PyPy. So I made a quick <a href="https://pypi.python.org/pypi/cffi">CFFI</a> mockup: <a href="https://gist.github.com/Dav1dde/c509d472085f9374fc1d">https://gist.github.com/Dav1dde/c509d472085f9374fc1d</a><br><br>
Before:<br><br>CPython 2.7: <br><span>    python -m emfas.server size dumps/echoprint-dump-1.json <br>    11.89s user 0.36s system 98% cpu 12.390 total </span><br>
PYPY: <br><span>    python -m emfas.server size dumps/echoprint-dump-1.json <br>    117.19s user 2.36s system 99% cpu 1:59.95 total </span><br><br>
After (CFFI):<br><br> CPython 2.7: <br><span>     python jsonsize.py ../dumps/echoprint-dump-1.json<br>      8.63s user 0.28s system 99% cpu 8.945 total </span><br>
PyPy: <br><span>     python jsonsize.py ../dumps/echoprint-dump-1.json <br>     4.04s user 0.34s system 99% cpu 4.392 total
</span><br>"<br><div style="text-align: left;">
<br>
</div>
<br><br>Dav1dd goes into more detail in the issue itself, but we just want to emphasize a few significant points from this brief interchange:<br><ul style="text-align: left;">
<li>His CFFI implementation is faster than the ctypes one even on CPython 2.7.</li>
<li>PyPy + CFFI is faster than CPython even when using C code to do the heavy parsing.</li>
</ul>
 The PyPy Team <br><div>
<div>
 <br>
</div>
</div>
</div>
    </div>
    </article><div class="comment-level comment-level-1">
      <div class="comment comment-1452195078903157311">
        <div class="comment-header">
          <a name="comment-1452195078903157311"></a>
            <span class="author">Alendit</span> wrote on <span class="date">2015-06-18 08:38</span>:
        </div>
        <div class="comment-content">
          <p>Maybe it's time to discuss inclusion of CFFI into stdandard library again?</p>
        </div>
      </div>
      <div class="comment comment-7954834601107824074">
        <div class="comment-header">
          <a name="comment-7954834601107824074"></a>
            <span class="author">Armin Rigo</span> wrote on <span class="date">2015-06-18 09:52</span>:
        </div>
        <div class="comment-content">
          <p>If CPython decides to include it in its stdlib, I can make sure it is updated as needed.  I don't have the energy to discuss its inclusion myself, so if it happens it will be "championed" by someone else.  Nowadays, I personally think inclusion has as many drawbacks as advantages, even if CFFI 1.x shouldn't evolve a lot in the foreseeable future after the 1.0 step.</p>
        </div>
      </div>
      <div class="comment comment-3115910897496513174">
        <div class="comment-header">
          <a name="comment-3115910897496513174"></a>
            <span class="author">v3ss</span> wrote on <span class="date">2015-07-18 22:14</span>:
        </div>
        <div class="comment-content">
          <p>The problem is converting existing libs to use cffi. Only very few percent of Libs are ready for python3.x and with this trend , not even 1% of libs will be converted to work with CFFI. <br>That makes PyPy adoption a lot slower.<br><br>Is there really no chance of improving ctypes?<br></p>
        </div>
      </div>
      <div class="comment comment-4299963034922593615">
        <div class="comment-header">
          <a name="comment-4299963034922593615"></a>
            <span class="author">Maciej Fijalkowski</span> wrote on <span class="date">2015-07-19 05:39</span>:
        </div>
        <div class="comment-content">
          <p>you would think, but these days vast majority of popular C bindings come with cffi equivalents. In fact cffi is vastly more popular than ctypes ever was.</p>
        </div>
      </div>
         </div>

</div>
</div>
<div class="sidebar">
<div>
  <h2>
    The PyPy blogposts
  </h2>
  <div>
    Create a guest post via a PR to the <a href="https://github.com/pypy/pypy.org">source repo</a>
  </div>
</div>
    <div id="global-recent-posts">
    <h2>
      Recent Posts
    </h2>
    <ul class="post-list">
      <li>
        <a href="/posts/2025/07/pypy-v7320-release.html" class="listtitle">PyPy v7.3.20 release</a>
      </li>
      <li>
        <a href="/posts/2025/06/rpython-gc-allocation-speed.html" class="listtitle">How fast can the RPython GC allocate?</a>
      </li>
      <li>
        <a href="/posts/2025/04/prospero-in-rpython.html" class="listtitle">Doing the Prospero-Challenge in RPython</a>
      </li>
      <li>
        <a href="/posts/2025/02/pypy-v7319-release.html" class="listtitle">PyPy v7.3.19 release</a>
      </li>
      <li>
        <a href="/posts/2025/02/pypy-gc-sampling.html" class="listtitle">Low Overhead Allocation Sampling with VMProf in PyPy's GC</a>
      </li>
      <li>
        <a href="/posts/2025/02/pypy-v7318-release.html" class="listtitle">PyPy v7.3.18 release</a>
      </li>
      <li>
        <a href="/posts/2025/01/musings-tracing.html" class="listtitle">Musings on Tracing in PyPy</a>
      </li>
      <li>
        <a href="/posts/2025/01/towards-pypy311-an-update.html" class="listtitle">Towards PyPy3.11 - an update</a>
      </li>
      <li>
        <a href="/posts/2024/11/guest-post-final-encoding-in-rpython.html" class="listtitle">Guest Post: Final Encoding in RPython Interpreters</a>
      </li>
      <li>
        <a href="/posts/2024/10/jit-peephole-dsl.html" class="listtitle">A DSL for Peephole Transformation Rules of Integer Operations in the PyPy JIT</a>
      </li>
    </ul>
  </div>

          <div id="global-archive-list">
          <h2>
            Archives
          </h2>
          <ul class="archive-level archive-level-1">
            <li><a class="reference" href="/2007/">2007</a> (19)
            </li>
            <li><a class="reference" href="/2008/">2008</a> (62)
            </li>
            <li><a class="reference" href="/2009/">2009</a> (38)
            </li>
            <li><a class="reference" href="/2010/">2010</a> (44)
            </li>
            <li><a class="reference" href="/2011/">2011</a> (43)
            </li>
            <li><a class="reference" href="/2012/">2012</a> (44)
            </li>
            <li><a class="reference" href="/2013/">2013</a> (46)
            </li>
            <li><a class="reference" href="/2014/">2014</a> (22)
            </li>
            <li><a class="reference" href="/2015/">2015</a> (20)
            </li>
            <li><a class="reference" href="/2016/">2016</a> (20)
            </li>
            <li><a class="reference" href="/2017/">2017</a> (13)
            </li>
            <li><a class="reference" href="/2018/">2018</a> (12)
            </li>
            <li><a class="reference" href="/2019/">2019</a> (12)
            </li>
            <li><a class="reference" href="/2020/">2020</a> (9)
            </li>
            <li><a class="reference" href="/2021/">2021</a> (10)
            </li>
            <li><a class="reference" href="/2022/">2022</a> (13)
            </li>
            <li><a class="reference" href="/2023/">2023</a> (6)
            </li>
            <li><a class="reference" href="/2024/">2024</a> (13)
            </li>
            <li><a class="reference" href="/2025/">2025</a> (8)
            </li>
          </ul>
        </div>


          <div id="global-tag-list">
          <h2>
            Tags
          </h2>
          <ul>
            <li><a class="reference" href="/categories/arm.html">arm</a> (2)</li>
            <li><a class="reference" href="/categories/benchmarking.html">benchmarking</a> (1)</li>
            <li><a class="reference" href="/categories/casestudy.html">casestudy</a> (3)</li>
            <li><a class="reference" href="/categories/cli.html">cli</a> (1)</li>
            <li><a class="reference" href="/categories/compiler.html">compiler</a> (1)</li>
            <li><a class="reference" href="/categories/conda-forge.html">conda-forge</a> (1)</li>
            <li><a class="reference" href="/categories/cpyext.html">cpyext</a> (4)</li>
            <li><a class="reference" href="/categories/cpython.html">CPython</a> (3)</li>
            <li><a class="reference" href="/categories/ep2008.html">ep2008</a> (1)</li>
            <li><a class="reference" href="/categories/extension-modules.html">extension modules</a> (3)</li>
            <li><a class="reference" href="/categories/gc.html">gc</a> (3)</li>
            <li><a class="reference" href="/categories/guestpost.html">guestpost</a> (3)</li>
            <li><a class="reference" href="/categories/graalpython.html">GraalPython</a> (1)</li>
            <li><a class="reference" href="/categories/hpy.html">hpy</a> (1)</li>
            <li><a class="reference" href="/categories/heptapod.html">Heptapod</a> (1)</li>
            <li><a class="reference" href="/categories/jit.html">jit</a> (23)</li>
            <li><a class="reference" href="/categories/jython.html">jython</a> (1)</li>
            <li><a class="reference" href="/categories/kcachegrind.html">kcachegrind</a> (1)</li>
            <li><a class="reference" href="/categories/meta.html">meta</a> (1)</li>
            <li><a class="reference" href="/categories/numpy.html">numpy</a> (24)</li>
            <li><a class="reference" href="/categories/parser.html">parser</a> (1)</li>
            <li><a class="reference" href="/categories/performance.html">performance</a> (2)</li>
            <li><a class="reference" href="/categories/profiling.html">profiling</a> (7)</li>
            <li><a class="reference" href="/categories/pypy.html">pypy</a> (6)</li>
            <li><a class="reference" href="/categories/pypy3.html">pypy3</a> (16)</li>
            <li><a class="reference" href="/categories/pyqt4.html">PyQt4</a> (1)</li>
            <li><a class="reference" href="/categories/release.html">release</a> (66)</li>
            <li><a class="reference" href="/categories/releasecffi.html">releasecffi</a> (3)</li>
            <li><a class="reference" href="/categories/releaserevdb.html">releaserevdb</a> (1)</li>
            <li><a class="reference" href="/categories/releasestm.html">releasestm</a> (1)</li>
            <li><a class="reference" href="/categories/revdb.html">revdb</a> (1)</li>
            <li><a class="reference" href="/categories/roadmap.html">roadmap</a> (2)</li>
            <li><a class="reference" href="/categories/rpython.html">rpython</a> (1)</li>
            <li><a class="reference" href="/categories/rpyc.html">RPyC</a> (1)</li>
            <li><a class="reference" href="/categories/speed.html">speed</a> (6)</li>
            <li><a class="reference" href="/categories/sponsors.html">sponsors</a> (7)</li>
            <li><a class="reference" href="/categories/sprint.html">sprint</a> (3)</li>
            <li><a class="reference" href="/categories/sprints.html">sprints</a> (1)</li>
            <li><a class="reference" href="/categories/stm.html">stm</a> (14)</li>
            <li><a class="reference" href="/categories/sun.html">sun</a> (1)</li>
            <li><a class="reference" href="/categories/smalltalk.html">Smalltalk</a> (1)</li>
            <li><a class="reference" href="/categories/squeak.html">Squeak</a> (1)</li>
            <li><a class="reference" href="/categories/testing.html">testing</a> (1)</li>
            <li><a class="reference" href="/categories/toy-optimizer.html">toy-optimizer</a> (5)</li>
            <li><a class="reference" href="/categories/unicode.html">unicode</a> (1)</li>
            <li><a class="reference" href="/categories/valgrind.html">valgrind</a> (1)</li>
            <li><a class="reference" href="/categories/vmprof.html">vmprof</a> (3)</li>
            <li><a class="reference" href="/categories/z3.html">z3</a> (5)</li>
          </ul>
        </div></div>
</main>
</div>
<div style="clear: both; width: 75%; margin: 1em auto;">
        <nav class="postindexpager"><ul class="pager">
<li class="previous">
                <a href="index-35.html" rel="prev">Newer posts</a>
            </li>
            <li class="next">
                <a href="index-33.html" rel="next">Older posts</a>
            </li>
        </ul></nav>
</div>
         
                 <footer id="footer"><p>
</p>
<div class="myfooter">
  <div class="logotext">
    © 2025 <a href="mailto:pypy-dev@pypy.org">The PyPy Team</a>
     
    Built with <a href="https://getnikola.com" rel="nofollow">Nikola</a>
     
    Last built 2025-07-07T11:01
  </div>
  <div style="margin-left: auto">
  <a href="../rss.xml">RSS feed</a>
</div>

            
        

    </div>
            <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.1.3/jquery.min.js" crossorigin="anonymous"></script><script src="../assets/js/styles.js"></script></footer>
</body>
</html>