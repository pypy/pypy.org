<!DOCTYPE html>
<html \ prefix="
        og: http://ogp.me/ns# article: http://ogp.me/ns/article#
    " vocab="http://ogp.me/ns" lang="en">
<head>
<meta charset="utf-8">
<meta name="description" content="A Faster Python">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>PyPy (old posts, page 23) | PyPy</title>
<link href="../assets/css/rst_base.css" rel="stylesheet" type="text/css">
<link href="../assets/css/nikola_rst.css" rel="stylesheet" type="text/css">
<link href="../assets/css/code.css" rel="stylesheet" type="text/css">
<link href="../assets/css/theme.css" rel="stylesheet" type="text/css">
<link href="../assets/css/styles.css" rel="stylesheet" type="text/css">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="alternate" type="application/rss+xml" title="RSS" hreflang="en" href="../rss.xml">
<link rel="canonical" href="https://www.pypy.org/blog/index-23.html">
<link rel="icon" href="../favicon2.ico" sizes="16x16">
<link rel="icon" href="../favicon32x32.ico" sizes="32x32">
<link rel="prev" href="index-24.html" type="text/html">
<link rel="next" href="index-22.html" type="text/html">
<!--[if lt IE 9]><script src="../assets/js/html5shiv-printshiv.min.js"></script><![endif]--><link href="https://fonts.googleapis.com/css?family=Roboto" rel="stylesheet">
<link rel="stylesheet" type="text/css" href="../assets/css/tipuesearch.css">
</head>
<body>
    <a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>
    <div id="container">
             <header id="header"><!-- Adapted from https://www.taniarascia.com/responsive-dropdown-navigation-bar --><section class="navigation"><div class="nav-container">
            <div class="brand">
                <a href="../index.html">
                    <image id="toplogo" src="../images/pypy-logo.svg" width="75px;" alt="PyPy/"></image></a>
            </div>
            <nav><ul class="nav-list">
<li> 
                <a href="#!">Features</a>
                <ul class="nav-dropdown">
<li> <a href="../features.html">What is PyPy?</a> </li>  
                    <li> <a href="../compat.html">Compatibility</a> </li>  
                    <li> <a href="../performance.html">Performance</a> </li>  
                </ul>
</li>
          <li> <a href="../download.html">Download</a> </li>  
          <li> <a href="http://doc.pypy.org">Dev Docs</a> </li>  
            <li> 
                <a href="#!">Blog</a>
                <ul class="nav-dropdown">
<li> <a href=".">Index</a> </li>  
                    <li> <a href="../categories/">Tags</a> </li>  
                    <li> <a href="../archive.html">Archive by year</a> </li>  
                    <li> <a href="../rss.xml">RSS feed</a> </li>  
                    <li> <a href="https://morepypy.blogspot.com/">Old site</a> </li>  
                </ul>
</li>
            <li> 
                <a href="#!">About</a>
                <ul class="nav-dropdown">
<li> <a href="https://bsky.app/profile/pypyproject.bsky.social">Bluesky</a> </li>  
                    <li> <a href="https://libera.irclog.whitequark.org/pypy">IRC logs</a> </li>  
                    <li> <a href="https://www.youtube.com/playlist?list=PLADqad94yVqDRQXuqxKrPS5QnVqbDLlRt">YouTube</a> </li>  
                    <li> <a href="https://www.twitch.tv/pypyproject">Twitch</a> </li>  
                    <li> <a href="../pypy-sponsors.html">Sponsors</a> </li>  
                    <li> <a href="../howtohelp.html">How To Help?</a> </li>  
                    <li> <a href="../contact.html">Contact</a> </li>  
                </ul>
</li>

                </ul></nav><div class="nav-mobile">
                <a id="nav-toggle" href="#!"> <span></span></a>
            </div>
        </div>
    </section><div class="searchform" role="search">
                
<form class="navbar-form navbar-left" action="../search.html" role="search">
    <div class="form-group">
        <input type="text" class="form-control" id="tipue_search_input" name="q" placeholder="Search…" autocomplete="off">
</div>
    <input type="submit" value="Local Search" style="visibility: hidden;">
</form>

            </div>
    </header><main id="content"><div class="post">
<div class="postindex">
    <article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="../posts/2012/06/stm-with-threads-7818875111634541910.html" class="u-url">STM with threads</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                <a href="../authors/armin-rigo.html">Armin Rigo</a>
            </span></p>
            <p class="dateline">
            <a href="../posts/2012/06/stm-with-threads-7818875111634541910.html" rel="bookmark">
            <time class="published dt-published" datetime="2012-06-10T19:02:00Z" itemprop="datePublished" title="2012-06-10 19:02">2012-06-10 19:02</time></a>
            </p>
                <p class="commentline">6 comments</p>

        </div>
    </header><div class="p-summary entry-summary">
    <p>Hi all,</p>
<p>A quick update.  The first version of pypy-stm <a class="reference" href="../posts/2012/05/stm-update-back-to-threads-6622746581767639355.html">based on regular<br>
threads</a> is ready.  Still having no JIT and a 4-or-5-times performance<br>
hit, it is not particularly fast, but I am happy that it turns out not<br>
to be much slower than the previous thread-less attempts.  It is at<br>
least fast enough to run faster (in real time) than an equivalent no-STM<br>
PyPy, if fed with an eight-threaded program on an eight-core machine<br>
(provided, of course, you don't mind it eating all 8 cores' CPU power<br>
instead of just one :-).</p>
<p>You can download and play around with <a class="reference" href="https://cobra.cs.uni-duesseldorf.de/~buildmaster/misc/pypy-stm-38eb1fbc3c8d.bz2">this binary</a> for Linux 64.  It<br>
was made from the <a class="reference" href="https://foss.heptapod.net/pypy/pypy/-/tree/branch/stm-thread">stm-thread</a> branch of the PyPy repository (<tt class="docutils literal"><span class="pre">translate.py --stm -O2 targetpypystandalone.py</span></tt>).  (Be sure<br>
to put it where it can find its stdlib, e.g. by putting it inside the<br>
directory from the official <a class="reference" href="https://bitbucket.org/pypy/pypy/downloads/pypy-1.9-linux64.tar.bz2">1.9 release</a>.)</p>
<p>This binary supports the <tt class="docutils literal"><span class="pre">thread</span></tt> module and runs without the GIL.<br>
So, despite the factor-of-4 slow-down issue, it should be the <em>fourth</em><br>
complete Python interpreter in which we can reasonably claim to have<br>
resolved the problem of the GIL.  (The first one was Greg Stein's Python<br>
1.4, re-explored <a class="reference" href="https://dabeaz.blogspot.ch/2011/08/inside-look-at-gil-removal-patch-of.html">here</a>; the second one is <a class="reference" href="https://jython.org/">Jython</a>; the third one is<br><a class="reference" href="https://ironpython.net/">IronPython</a>.)  Unlike the previous three, it is also the first one to<br>
offer full GIL semantics to the programmer, and additionally<br><tt class="docutils literal"><span class="pre">thread.atomic</span></tt> (see below).  I should also add that we're likely to<br>
see in the next year a 5th such interpreter, too, based on Hardware<br>
Transactional Memory (same approach as with STM, but using e.g.<br><a class="reference" href="https://software.intel.com/en-us/blogs/2012/02/07/transactional-synchronization-in-haswell/">Intel's HTM</a>).</p>
<p>The binary I linked to above supports all built-in modules from PyPy,<br>
apart from <tt class="docutils literal"><span class="pre">signal</span></tt>, still being worked on (which can be a bit<br>
annoying because standard library modules like <tt class="docutils literal"><span class="pre">subprocess</span></tt> depend on<br>
it).  The <tt class="docutils literal"><span class="pre">sys.get/setcheckinterval()</span></tt> functions can be used to tweak<br>
the frequency of the automatic commits.  Additionally, it offers<br><tt class="docutils literal"><span class="pre">thread.atomic</span></tt>, described in the <a class="reference" href="../posts/2012/05/stm-update-back-to-threads-6622746581767639355.html">previous blog post</a> as a way to<br>
create longer atomic sections (with the observable effect of preventing<br>
the "GIL" to be released during that time).  A complete<br><tt class="docutils literal"><span class="pre">transaction.py</span></tt> module based on it is available <a class="reference" href="https://foss.heptapod.net/pypy/pypy/-/tree/branch/stm-thread/lib_pypy/transaction.py">from the sources</a>.</p>
<p>The main missing features are:</p>
<ul class="simple">
<li>the <tt class="docutils literal"><span class="pre">signal</span></tt> module;</li>
<li>the Garbage Collector, which does not do major collections so far, only<br>
minor ones;</li>
<li>and finally, the JIT, which needs some amount of integration to generate<br>
the correctly-tweaked assembler.</li>
</ul>
<p>Have fun!</p>
<p>Armin.</p>
    </div>
    </article><div class="comment-level comment-level-1">
      <div class="comment comment-4977392340600987581">
        <div class="comment-header">
          <a name="comment-4977392340600987581"></a>
            <span class="author">Anonymous</span> wrote on <span class="date">2012-06-12 08:11</span>:
        </div>
        <div class="comment-content">
          <p>STM has such much potential. I wonder if it gets the attention of the hacker community it deserves. And if not, why not? I hope this is getting more recognition in the future.</p>
        </div>
      </div>
      <div class="comment comment-4886558464371261056">
        <div class="comment-header">
          <a name="comment-4886558464371261056"></a>
            <span class="author">Paul Jaros</span> wrote on <span class="date">2012-06-12 08:12</span>:
        </div>
        <div class="comment-content">
          <p>Ah... didn't mean to post it anonymously.</p>
        </div>
      </div>
      <div class="comment comment-3025625666753392431">
        <div class="comment-header">
          <a name="comment-3025625666753392431"></a>
            <span class="author">Unknown</span> wrote on <span class="date">2012-06-13 11:21</span>:
        </div>
        <div class="comment-content">
          <p>Nice!</p>
        </div>
      </div>
      <div class="comment comment-2832540780959550111">
        <div class="comment-header">
          <a name="comment-2832540780959550111"></a>
            <span class="author">Armin Rigo</span> wrote on <span class="date">2012-06-13 15:19</span>:
        </div>
        <div class="comment-content">
          <p>@Paul: my guess would be that the majority of people that know STM are still looking at it from the point of view of short or very short transactions, as a replacement of locking.  Even gcc 4.7 got an STM extension, but it cannot be used with long-running transactions: the performance is not at all tuned for this case, and you cannot express things you need in real long-running transactions, like interrupting them for I/O.<br><br>Moreover the single-core 4x performance hit is usually far more that what people are willing to accept --- not realizing that in many cases it will soon be outdated, as a way of measuring performance: the future is toward many-cores machines.</p>
        </div>
      </div>
      <div class="comment comment-2421885597456481683">
        <div class="comment-header">
          <a name="comment-2421885597456481683"></a>
            <span class="author">Anonymous</span> wrote on <span class="date">2012-06-14 16:11</span>:
        </div>
        <div class="comment-content">
          <p>For a casual Python programmer like me, how does STM affect the way I write my programs? I know about suggested benefits of STM on multi-core machines. However, what I'm asking is what is it that I have to do differently to get that benefit ?<br><br>Thanks</p>
        </div>
      </div>
      <div class="comment comment-8886034033672487139">
        <div class="comment-header">
          <a name="comment-8886034033672487139"></a>
            <span class="author">Armin Rigo</span> wrote on <span class="date">2012-06-15 07:42</span>:
        </div>
        <div class="comment-content">
          <p>@Anonymous: https://foss.heptapod.net/pypy/pypy/-/tree/branch//stm-thread/pypy/doc/stm.rst</p>
        </div>
      </div>
         </div>

    <article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="../posts/2012/06/pypy-19-yard-wolf-7006180436602667005.html" class="u-url">PyPy 1.9 - Yard Wolf</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                <a href="../authors/maciej-fijalkowski.html">Maciej Fijalkowski</a>
            </span></p>
            <p class="dateline">
            <a href="../posts/2012/06/pypy-19-yard-wolf-7006180436602667005.html" rel="bookmark">
            <time class="published dt-published" datetime="2012-06-08T10:48:00Z" itemprop="datePublished" title="2012-06-08 10:48">2012-06-08 10:48</time></a>
            </p>
                <p class="commentline">4 comments</p>

        </div>
    </header><div class="p-summary entry-summary">
    <p>We're pleased to announce the 1.9 release of PyPy. This release brings mostly<br>
bugfixes, performance improvements, other small improvements and overall<br>
progress on the <a class="reference external" href="https://pypy.org/numpydonate.html">numpypy</a> effort.<br>
It also brings an improved situation on Windows and OS X.</p>
<p>You can download the PyPy 1.9 release here:</p>
<blockquote><a class="reference external" href="https://pypy.org/download.html">https://pypy.org/download.html</a></blockquote>
<div class="section" id="what-is-pypy">
<h3>What is PyPy?</h3>
<p>PyPy is a very compliant Python interpreter, almost a drop-in replacement for<br>
CPython 2.7. It's fast (<a class="reference external" href="https://speed.pypy.org">pypy 1.9 and cpython 2.7.2</a> performance comparison)<br>
due to its integrated tracing JIT compiler.</p>
<p>This release supports x86 machines running Linux 32/64, Mac OS X 64 or<br>
Windows 32.  Windows 64 work is still stalling, we would welcome a volunteer<br>
to handle that.</p>
</div>
<div class="section" id="thanks-to-our-donors">
<h3>Thanks to our donors</h3>
<p>But first of all, we would like to say thank you to all people who<br>
donated some money to one of our four calls:</p>
<blockquote><ul class="simple">
<li>
<a class="reference external" href="https://pypy.org/numpydonate.html">NumPy in PyPy</a> (got so far $44502 out of $60000, 74%)</li>
<li>
<a class="reference external" href="https://pypy.org/py3donate.html">Py3k (Python 3)</a> (got so far $43563 out of $105000, 41%)</li>
<li>
<a class="reference external" href="https://pypy.org/tmdonate.html">Software Transactional Memory</a> (got so far $21791 of $50400, 43%)</li>
<li>as well as our general PyPy pot.</li>
</ul></blockquote>
<p>Thank you all for proving that it is indeed possible for a small team of<br>
programmers to get funded like that, at least for some<br>
time.  We want to include this thank you in the present release<br>
announcement even though most of the work is not finished yet.  More<br>
precisely, neither Py3k nor STM are ready to make it in an official release<br>
yet: people interested in them need to grab and (attempt to) translate<br>
PyPy from the corresponding branches (respectively <tt class="docutils literal">py3k</tt> and<br><tt class="docutils literal"><span class="pre">stm-thread</span></tt>).</p>
</div>
<div class="section" id="highlights">
<h3>Highlights</h3>
<ul class="simple">
<li>This release still implements Python 2.7.2.</li>
<li>Many bugs were corrected for Windows 32 bit.  This includes new<br>
functionality to test the validity of file descriptors; and<br>
correct handling of the calling convensions for ctypes.  (Still not<br>
much progress on Win64.) A lot of work on this has been done by Matti Picus<br>
and Amaury Forgeot d'Arc.</li>
<li>Improvements in <tt class="docutils literal">cpyext</tt>, our emulator for CPython C extension modules.<br>
For example PyOpenSSL should now work.  We thank various people for help.</li>
<li>Sets now have strategies just like dictionaries. This means for example<br>
that a set containing only ints will be more compact (and faster).</li>
<li>A lot of progress on various aspects of <tt class="docutils literal">numpypy</tt>. See the <a class="reference external" href="https://buildbot.pypy.org/numpy-status/latest.html">numpy-status</a><br>
page for the automatic report.</li>
<li>It is now possible to create and manipulate C-like structures using the<br>
PyPy-only <tt class="docutils literal">_ffi</tt> module.  The advantage over using e.g. <tt class="docutils literal">ctypes</tt> is that<br><tt class="docutils literal">_ffi</tt> is very JIT-friendly, and getting/setting of fields is translated<br>
to few assembler instructions by the JIT. However, this is mostly intended<br>
as a low-level backend to be used by more user-friendly FFI packages, and<br>
the API might change in the future. Use it at your own risk.</li>
<li>The non-x86 backends for the JIT are progressing but are still not<br>
merged (ARMv7 and PPC64).</li>
<li>JIT hooks for inspecting the created assembler code have been improved.<br>
See <a class="reference external" href="https://doc.pypy.org/en/latest/jit-hooks.html">JIT hooks documentation</a> for details.</li>
<li>
<tt class="docutils literal">select.kqueue</tt> has been added (BSD).</li>
<li>Handling of keyword arguments has been drastically improved in the best-case<br>
scenario: proxy functions which simply forwards <tt class="docutils literal">*args</tt> and <tt class="docutils literal">**kwargs</tt><br>
to another function now performs much better with the JIT.</li>
<li>List comprehension has been improved.</li>
</ul>
</div>
<div class="section" id="jitviewer">
<h3>JitViewer</h3>
<p>There will be a corresponding 1.9 release of JitViewer which is guaranteed to work<br>
with PyPy 1.9. See the <a class="reference external" href="https://bitbucket.org/pypy/jitviewer">JitViewer docs</a> for details.</p>
<p>Cheers,<br>
The PyPy Team</p>
</div>
    </div>
    </article><div class="comment-level comment-level-1">
      <div class="comment comment-2633614464180694641">
        <div class="comment-header">
          <a name="comment-2633614464180694641"></a>
            <span class="author">Dmitrey</span> wrote on <span class="date">2012-06-08 11:11</span>:
        </div>
        <div class="comment-content">
          <p>I have took a look at the mentioned numpypy table (https://buildbot.pypy.org/numpy-status/latest.html), and it lies in many ways. At first, some methods marked as "done" and undone yet, e.g. consider searchsorted: <br>&gt;&gt;&gt;&gt; from numpypy import searchsorted<br>&gt;&gt;&gt;&gt; searchsorted([1,2,3],[2,3])<br>Traceback (most recent call last):<br>  File "", line 1, in <br>  File "/home/dmitrey/Install/pypy-c-jit-55492-ac392fb76904-linux/lib_pypy/numpypy/core/fromnumeric.py", line 763, in searchsorted<br>    raise NotImplementedError('Waiting on interp level method')<br>NotImplementedError: Waiting on interp level method<br><br>(and AFAIK there are many other similar numpypy funcs that are present in dir(numpypy), but only raise NotImplementedError).<br><br>At 2nd, some funcs like all and any, also mentioned there as "done", don't work with "axis" parameter and thus also should be unmarked.<br><br>FYI as a temporary replacement for some missing in PyPy yet numpy funcs (atleast_1d, atleast_2d, hstack, vstack, cumsum, isscalar, asscalar, asfarray, flatnonzero, tile, zeros_like, ones_like, empty_like, where, searchsorted;<br>    with "axis" parameter: nan(arg)min, nan(arg)max, all, any ) <br><br>I have implemented them in AppLevel (thus PyPy developers refuce to commit them, but some users could be interested right now), see https://openopt.org/PyPy for more details and my sincere opinion on the situation.<br><br>Best wishes for PyPy developers and users, D.</p>
        </div>
      </div>
      <div class="comment comment-8549835603946576341">
        <div class="comment-header">
          <a name="comment-8549835603946576341"></a>
            <span class="author">Maciej Fijalkowski</span> wrote on <span class="date">2012-06-08 12:52</span>:
        </div>
        <div class="comment-content">
          <p>Hi Dmitrey, nice to hear from you.<br><br>The page is automatically generated - we should probably just disable those functions, I can't remember the exact reason why they're there in the first place.<br><br>When it comes to missing arguments - you just can't help it. It's an automatically generated page that should give only an overview.<br><br>As far as your patches go - yes, we need tests and we also need tests that cover corner cases. This is very important for us, we can live without the rest (like implementations on the interp-level). We do care about quality a lot.<br><br>Cheers,<br>fijal</p>
        </div>
      </div>
      <div class="comment comment-6681551036372601521">
        <div class="comment-header">
          <a name="comment-6681551036372601521"></a>
            <span class="author">Dmitrey</span> wrote on <span class="date">2012-06-08 15:24</span>:
        </div>
        <div class="comment-content">
          <p>hi fijal,<br>as far as I remember, main reasons of PyPy developers (I don't remember namely) to reject my funcs propositions were AppLevel vs InterpLevel, not corner testcases (they even said "don't start the func, it must be InterpLevel"). Thus to speedup OpenOpt port on PyPy I went other way and as you probably have seen that some OpenOpt Suite functionality is already available in PyPy and works some times faster.<br><br>If apperplevel is ok for some of those funcs mentioned above, you or any other PyPy programmer can take anything from the code; as for me, I have lots of other things to do with my projects, especially now, before regular release, and thus cannot allocate time to create testcases for the numpy funcs.<br><br>BTW, what about fancy indexing with int arrays (https://bugs.pypy.org/issue1130) - when it will be implemented? It's very important for many Python projects and hangs for a long time already.</p>
        </div>
      </div>
      <div class="comment comment-172310154247019625">
        <div class="comment-header">
          <a name="comment-172310154247019625"></a>
            <span class="author">Peter Thomson</span> wrote on <span class="date">2012-06-10 16:56</span>:
        </div>
        <div class="comment-content">
          <p>Congratulations to the new release to the best and most awesome team there is. We work daily with Python and PyPy and always look forward to the latest release :-)</p>
        </div>
      </div>
         </div>

    <article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="../posts/2012/06/py3k-status-update-4-4834053219477515637.html" class="u-url">Py3k status update #4</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                <a href="../authors/antonio-cuni.html">Antonio Cuni</a>
            </span></p>
            <p class="dateline">
            <a href="../posts/2012/06/py3k-status-update-4-4834053219477515637.html" rel="bookmark">
            <time class="published dt-published" datetime="2012-06-05T13:39:00Z" itemprop="datePublished" title="2012-06-05 13:39">2012-06-05 13:39</time></a>
            </p>
                <p class="commentline">3 comments</p>

        </div>
    </header><div class="p-summary entry-summary">
    <p>This is the fourth status update about our work on the <a class="reference external" href="https://foss.heptapod.net/pypy/pypy/-/tree/branch/py3k">py3k branch</a>, which we<br>
can work on thanks to all of the people who <a class="reference external" href="../posts/2012/01/py3k-and-numpy-first-stage-thanks-to-3008917396290059758.html">donated</a> to the <a class="reference external" href="https://pypy.org/py3donate.html">py3k proposal</a>.</p>
<p>For various reasons, less work than usual has been done since the last status<br>
update. However, some interesting things happened anyway.</p>
<p>As readers know, so far we spent most of the effort in fixing all PyPy's own<br>
tests which started to fail for various py2/py3 differences.  Most of them<br>
failed for shallow reasons, e.g. syntactic changes or the int/long<br>
unifications. Others failed for subtle differences and needed a bit more care,<br>
for example the fact that unbound methods are gone in Py3k.</p>
<p>The good news is that finally we are seeing the light at the end of the<br>
tunnel. Most of them have been fixed. For sine other tests, we introduced the<br>
concept of "py3k-skipping": some optimizations and modules are indeed failing,<br>
but right now we are concentrating on completing the core language and so we<br>
are not interested in those.  When the core language will be done, we will be<br>
able to easily find and work on the py3k-skipped tests.  In particular, for<br>
now we disabled the <tt class="docutils literal">Int</tt> and <tt class="docutils literal">String</tt> dict strategies, which are broken<br>
because of the usual int/long unification and str vs bytes.  As for modules,<br>
for now <tt class="docutils literal">_continuation</tt> (needed for stackless) and <tt class="docutils literal">_multiprocessing</tt> do<br>
not work yet.</p>
<p>Another non-trivial feature we implemented is the proper cleaning of exception<br>
variables when we exit <tt class="docutils literal">except</tt> blocks.  This is a feature which touches<br>
lots of levels of PyPy, starting from <tt class="docutils literal">astcompiler</tt>, down to the bytecode<br>
interpreter. It tooks two days of headache, but at the end we made it :-).</p>
<p>Additionally, Amaury did a lot of improvements to <tt class="docutils literal">cpyext</tt>, which had been<br>
broken since forever on this branch.</p>
<p>As for the next plans, now that things are starting to work and PyPy's own<br>
tests mostly pass, we can finally start to run the compiled PyPy against<br>
CPython's test suite.  It is very likely that we will have tons of failures at<br>
the beginning, but once we start to fix them one by one, a Py3k-compatible<br>
PyPy will be closer and closer.</p>
    </div>
    </article><div class="comment-level comment-level-1">
      <div class="comment comment-4758641022269967240">
        <div class="comment-header">
          <a name="comment-4758641022269967240"></a>
            <span class="author">Connelly Barnes</span> wrote on <span class="date">2012-06-27 18:28</span>:
        </div>
        <div class="comment-content">
          <p>Does anyone actually use Python 3? That whole project of Guido's reminds me of "things you should never do: rewrites."<br><br>https://www.neilgunton.com/doc/?o=1&amp;doc_id=8583</p>
        </div>
      </div>
      <div class="comment comment-5004976816292194024">
        <div class="comment-header">
          <a name="comment-5004976816292194024"></a>
            <span class="author">Unknown</span> wrote on <span class="date">2012-06-29 10:55</span>:
        </div>
        <div class="comment-content">
          <p>I cheered at your update when I saw it originally - but did not write this here.<br><br>Since no one else did that, yet, I want to go back to fix the mistake:<br><br>Great work!<br><br>I’m anxious to see my python3 code running under pypy!</p>
        </div>
      </div>
      <div class="comment comment-2197312472249542643">
        <div class="comment-header">
          <a name="comment-2197312472249542643"></a>
            <span class="author">z1r0un</span> wrote on <span class="date">2013-08-06 04:24</span>:
        </div>
        <div class="comment-content">
          <p>@Connelly Barnes:<br>Wat.<br>I use Python3 almost exclusively, mainly because filter, map, and friends return iterators as FSM intended. I haven't done much string work, but that's another major win. And it's not like 2.7's EOL'd.<br>In short, un-bunch your knickers and roll with the times.</p>
        </div>
      </div>
         </div>

    <article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="../posts/2012/05/stm-update-back-to-threads-6622746581767639355.html" class="u-url">STM update: back to threads?</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                <a href="../authors/armin-rigo.html">Armin Rigo</a>
            </span></p>
            <p class="dateline">
            <a href="../posts/2012/05/stm-update-back-to-threads-6622746581767639355.html" rel="bookmark">
            <time class="published dt-published" datetime="2012-05-07T20:58:00Z" itemprop="datePublished" title="2012-05-07 20:58">2012-05-07 20:58</time></a>
            </p>
                <p class="commentline">20 comments</p>

        </div>
    </header><div class="p-summary entry-summary">
    <p>Hi again,<br><br>
Here is another update on the status of Software Transactional Memory on PyPy.<br><br>
Those of you who have been closely following this blog since last year know that, from the <a href="../posts/2011/06/global-interpreter-lock-or-how-to-kill-8270246310848099963.html">very first post about STM</a>, I explored various design ideas about the API that we should get when programming in Python.<br><br>
I went a full circle, and now I am back to where I started (with, important difference, <a href="https://foss.heptapod.net/pypy/pypy/-/tree/branch/stm-thread">a very roughly working implementation</a> of pypy-stm).<br><br>
What I realized is that the "thread" module is not that bad after all --- I mean, yes, it is a horribly low-level interface, but it is general enough to build various interesting things on top of it.  What the "stm-thread" branch of PyPy contains is, basically, the regular "thread" module in which the GIL was replaced with STM.  It gives multicore capabilities to any program based on multiple threads.  (This is so far exactly the idea same than the one being investigated for Hardware Transactional Memory.  It is roughly also what you would get if you managed to convince GCC 4.7 to compile CPython using STM.)<br><br>
Now while this might already be quite interesting to some people, here is how it relates to all I said previously: namely, threads are bad, and some new "transaction" module would be a better idea.<br><br>
There is <i>one</i> new core functionality in the "stm-thread" branch: it is "thread.atomic", a context manager that can be used in a "with" statement (exact name subject to change).  In terms of the GIL, it prevents the GIL from being released in the "with" block.  In terms of STM, it prevents a "transaction break", which means that the whole "with" statement runs in one single transaction.  (From the Python programmer's point of view, the net effect is the same.)<br><br>
So far, no ground-breaking news.  But what I missed previously is that this is enough to give multicore capabilities <i>even to a program that is not using threads so far.</i>  It is possible to rewrite an equivalent of the old <a href="https://foss.heptapod.net/pypy/pypy/-/tree/branch//stm-gc/lib_pypy/transaction.py">transaction</a> module in a few pages of pure Python, using "thread.atomic".  Something along the following lines: start N threads that each reads from a Queue.Queue() the next job to do, and does it in a "with thread.atomic" block.  The STM version of PyPy is then able to run these atomic blocks concurrently.  The key point is that the slightly delicate handling of threads should be nicely hidden inside the new "transaction" module, and from outside the observed behavior would be exactly as if the transactions that we schedule are run serially.<br><br>
The point I kept missing was that, yes, this sounds like nonsense, because it seems that we create N threads just to serialize their work again in "thread.atomic" sections.  In fact this would be nonsense in any model that would "just" remove the GIL to let multiple threads run concurrently without crashing.  Indeed, you have multiple threads, but their atomic blocks would be again a sort of GIL: only one of them would run at a time.  And this is indeed the simple model of execution that you get <i>even with STM</i> --- but not the model of performance.  The performance with STM scales with the number of cores, as long as there is enough non-conflicting work to do.<br><br>
So in summary the complete circle back to the starting point is that threads might be a good low-level model.  It mends itself naturally to, say, a kind of program in which the main thread polls file descriptors using select() or the Linux epoll(), and the work received is split along N other threads --- which is the kind of program you would naturally write in other languages that don't have a GIL, say Java.  The other threads can then use "thread.atomic" blocks to protect sections of their work.  The traditional Transactional Memory point of view is that you use such blocks to guard the short sections of code that communicate with other threads or modify global state, but nothing prevents you from using much larger sections: you should be able to scale them up to the size of a native "unit of work", so that every unit is naturally atomic.  And then it's only a matter of design: you can tweak an existing module that does the thread pooling to add one "with thread.atomic"; or do it yourself from scratch; or (if the design is compatible enough) just plug in the proposed pure-Python "transaction" module.  Or if you feel like it you can even use threads directly (but keep in mind that using threads too explicitly is not a <a href="https://en.wikipedia.org/wiki/Software_transactional_memory#Composable_operations">composable</a> abstraction, whereas higher-level designs typically are).<br><br>
At the end of the day, you can write or reuse programs whose global structure you are already familiar with, for example with a thread pool (that can be hidden in a library if you prefer), or any other structure with or without explicit threads.  But you can do so without all the mess that comes with threads like locks and deadlocks.  From that angle it is really similar to Garbage Collection: e.g. the Boehm GC (now used by GCC itself) lets you write C code like you are used to, but forgeting all you had to learn about careful explicit memory management.</p>
    </div>
    </article><div class="comment-level comment-level-1">
      <div class="comment comment-949412754465247368">
        <div class="comment-header">
          <a name="comment-949412754465247368"></a>
            <span class="author">Benjamin</span> wrote on <span class="date">2012-05-08 04:38</span>:
        </div>
        <div class="comment-content">
          <p>So I'm not sure if I fully grok STM, but my basic understanding of the workflow for a transaction is this:<br><br>1. Make a copy of whatever it is you're planning to use, ie, 'stuff'.<br>2. Do anything that doesn't have side effects (writing to memory/disk).<br>3. Acquire a lock &amp; compare the state of the parts of 'stuff' you want to change to the current state.<br>4a. If 'stuff to write' is unchanged, write it and release lock.<br>4b. Otherwise, release lock and restart transaction.<br><br>With the context manager, how is 'stuff' determined? Does it record everything in locals()?  That seems like it might be excessive. Would it make sense to expose 'stuff' to the programmer?<br><br>If you were to expose 'stuff' to the programmer, I'd think you'd want a new local context where the only variables available were those explicitly specified as 'stuff' (and builtins, etc) so as to avoid congruency accidents. Something like:<br><br>with atomic(f, x, y, z, q) as f, x, y, z, q:<br>    z += f(x, y)<br>    y = x<br>    x = q.pop()<br><br>This would also help remind folks to keep their transactions small.<br><br>Furthermore, this could easily be transformed into a very useful (function) decorator that uses the function's arguments as the 'stuff'.<br><br>Am I missing something? Are my suggestions reasonable?</p>
        </div>
      </div>
      <div class="comment comment-7627661849074849657">
        <div class="comment-header">
          <a name="comment-7627661849074849657"></a>
            <span class="author">Unknown</span> wrote on <span class="date">2012-05-08 06:09</span>:
        </div>
        <div class="comment-content">
          <a href="https://code.google.com/p/disruptor" rel="nofollow">this</a> might give you some insight into another approach for passing messages (aka information) between threads which might be GIL friendly.
        </div>
      </div>
      <div class="comment comment-1837731522753426562">
        <div class="comment-header">
          <a name="comment-1837731522753426562"></a>
            <span class="author">Frankier</span> wrote on <span class="date">2012-05-08 07:29</span>:
        </div>
        <div class="comment-content">
          <p>@Benjamin:<br><br>My understanding is STM is using these type of transactions: https://en.wikipedia.org/wiki/Optimistic_concurrency_control</p>
        </div>
      </div>
      <div class="comment comment-8714743568967598432">
        <div class="comment-header">
          <a name="comment-8714743568967598432"></a>
            <span class="author">Armin Rigo</span> wrote on <span class="date">2012-05-08 08:17</span>:
        </div>
        <div class="comment-content">
          <p>@Benjamin: no, that's not reasonable at all in the context of large transactions.  "Help remind folks to keep their transactions small" is precisely what I don't want: I want <i>large</i> transactions.  This might be harder to do efficiently, it might be more conflict-prone, etc.; but what I <i>don't</i> want is the classical situation where you have to be very careful about keeping your transactions as small as possible, because that's just as hard and error-prone as using locks.<br><br>What I want is for "the average programmer" to not use the "thread" module at all, including "thread.atomic".  This should be part of a library that does thread pooling and dispatching (large) transactions.</p>
        </div>
      </div>
      <div class="comment comment-4407253057248073828">
        <div class="comment-header">
          <a name="comment-4407253057248073828"></a>
            <span class="author">Kristján Valur</span> wrote on <span class="date">2012-05-08 11:33</span>:
        </div>
        <div class="comment-content">
          <p>You know, of course, that stackless has an "atomic" property, and stacklesslib has an stacklesslib.utils.atomic ctxtmgr.<br><br>I recently modified stackless so that the "atomic" property also inhibited GIL release, so that inter-thread tasklet operations could be made safe.<br><br>On a whim I scoured the python archives and found that such a property had been proposed to cPython but rejected (unwisely imho) in favor of general locking.<br><br>Perhaps we can get them to reconsider?</p>
        </div>
      </div>
      <div class="comment comment-3815561712303808126">
        <div class="comment-header">
          <a name="comment-3815561712303808126"></a>
            <span class="author">Kristján Valur</span> wrote on <span class="date">2012-05-08 11:41</span>:
        </div>
        <div class="comment-content">
          <p>Oh, and btw:<br>an "atomic" property in regular cPython (and stackless) of course only prevents preemptive release of the GIL.  Any blocking IO calls will still cause a "co-operative" GIL release.  For this reason, "atomic" cannot be replace generic locks completely.<br><br>How does this play with longer "transactions" in STM?</p>
        </div>
      </div>
      <div class="comment comment-4052041925794156379">
        <div class="comment-header">
          <a name="comment-4052041925794156379"></a>
            <span class="author">Armin Rigo</span> wrote on <span class="date">2012-05-08 11:54</span>:
        </div>
        <div class="comment-content">
          <p>@Kris: ah, interesting.  You did the same as what I attempted in my hack of CPython at https://bitbucket.org/arigo/cpython-withatomic .  This didn't really work out, though, because the stdlib (including file objects) use regular locks.  A simple "print" in an atomic block could lead to deadlocks: the atomic block can block waiting for the stdout's file lock to be released, but it does so without releasing the GIL.  Now the lock would typically be released by another thread --- if only it could grab the GIL for a short while.<br><br>You can see the workaround I found in the last few commit messages of the above repository, but I'm not satisfied with it...  In general I'm still unsure what the best way is.  For now in pypy-stm I'm going to hack on a case-by-case basis to convert the locks to atomic sections.<br><br>Perhaps it is possible to do it semi-generically, e.g. convert all syntactically nested "with lock:" statements in the user code into "with atomic:" statements (similar to next year's Intel CPUs, which will have "lock elision" to help convert from lock-based to HTM programs).  As far as I know, this idea doesn't work in all situations, e.g. if you acquire a lock in one thread and release it in another thread.<br><br>As far as I can say, this issue is the main blocker preventing any further progress on the CPython side.  It is certainly the reason I stopped pushing for it last year.</p>
        </div>
      </div>
      <div class="comment comment-671309105404345554">
        <div class="comment-header">
          <a name="comment-671309105404345554"></a>
            <span class="author">Armin Rigo</span> wrote on <span class="date">2012-05-08 11:58</span>:
        </div>
        <div class="comment-content">
          <p>@Kris: ah, ok: you have a version of "atomic" that doesn't prevent the GIL from being released around I/O calls.  This is different from the version described in this post, which is also what I assumed in my previous answer.  In a "with atomic" block, the GIL is not released under any circumstance (equivalently, the whole "atomic" block runs as a single transaction), so that the programmer can assume that a "with atomic" block is truly atomic.</p>
        </div>
      </div>
      <div class="comment comment-1318245391259391694">
        <div class="comment-header">
          <a name="comment-1318245391259391694"></a>
            <span class="author">Unknown</span> wrote on <span class="date">2012-05-08 12:59</span>:
        </div>
        <div class="comment-content">
          <p>How would a code example look for thread.atomic?</p>
        </div>
      </div>
      <div class="comment comment-5409418058441905177">
        <div class="comment-header">
          <a name="comment-5409418058441905177"></a>
            <span class="author">Armin Rigo</span> wrote on <span class="date">2012-05-08 13:23</span>:
        </div>
        <div class="comment-content">
          <p>@Arne: here is an example using directly thread.atomic.  In your multithreaded application, at some point, you want to remove an item from list1 and add it to list2, knowing that list1 and list2 are also accessed by other threads.  Then you write:<br><br>with thread.atomic:<br>    x = list1.pop()<br>    list2.append(x)<br><br>This is a classical STM example.  What I'm pushing for is not that, though: it is for not writing multithreaded code in the first place.  With the proper library code you can write code like the first few lines of <a href="https://foss.heptapod.net/pypy/pypy/-/tree/branch//stm-gc/lib_pypy/transaction.py" rel="nofollow">transaction</a>.  The library code would itself use thread.atomic, but not you directly.</p>
        </div>
      </div>
      <div class="comment comment-4714147678465543748">
        <div class="comment-header">
          <a name="comment-4714147678465543748"></a>
            <span class="author">Kristján Valur</span> wrote on <span class="date">2012-05-08 15:02</span>:
        </div>
        <div class="comment-content">
          <p>Yes, sorry for not being clear, Armin.  But an "atomic" flag that inhibits involountary thread switching is useful too, because it is a fast "lock" around all kinds of code:<br><br>with atomic:<br>  foo = foo+1 #multi-threading-safe<br><br>without the overhead of real locks.<br>In our GIL world, real locks only benefit areas that incur thread-blocking operations such as IO.<br><br>Anyway, that is off-topic, I suppose :)</p>
        </div>
      </div>
      <div class="comment comment-8664937597408632986">
        <div class="comment-header">
          <a name="comment-8664937597408632986"></a>
            <span class="author">Kristján Valur</span> wrote on <span class="date">2012-05-08 15:06</span>:
        </div>
        <div class="comment-content">
          <p>Of course, we cannot replace thread._Lock with an "atomic" equivalent, because it is a non-recursive entity, also used for such things as condition variables!.<br><br>Not a very wise move, in retrospect.</p>
        </div>
      </div>
      <div class="comment comment-7774825949489887436">
        <div class="comment-header">
          <a name="comment-7774825949489887436"></a>
            <span class="author">Armin Rigo</span> wrote on <span class="date">2012-05-08 16:38</span>:
        </div>
        <div class="comment-content">
          <p>@Kris: indeed.  I found out a way that should in all cases either work or raise an exception if unsupported (and not unexpectedly deadlock).<br><br>The unsupported situation is: we are in a "with atomic" block trying to acquire a lock, and this lock is acquired already.  In this case, there is nothing the interpreter can do automatically.  It can only complain rather than deadlocking: no other thread is going to run in parallel to release the lock.<br><br>This should let the "common use case" work, which is locks used as scoped mutexes.  Caveat: only as long as you use them either only in "with atomic" blocks --- because they appear to be fully serialized, so the mutex will never block --- or only outside "with atomic" blocks.<br><br>This leaves the case of mixed usage as unsupported, but I don't see how it could reasonably be supported.<br><br>So for now, pypy-stm will raise "oups deadlock" if you try to use "print" statements both inside and outside atomic blocks in parallel...  that's the best I could come up with so far.</p>
        </div>
      </div>
      <div class="comment comment-598859044443630201">
        <div class="comment-header">
          <a name="comment-598859044443630201"></a>
            <span class="author">Anonymous</span> wrote on <span class="date">2012-05-09 00:38</span>:
        </div>
        <div class="comment-content">
          <p>thanks for the article.   might want to reword "This is so far exactly the idea same than the one being investigated for Hardware Transactional Memory.".    :)</p>
        </div>
      </div>
      <div class="comment comment-5790328126053393982">
        <div class="comment-header">
          <a name="comment-5790328126053393982"></a>
            <span class="author">Ole Laursen</span> wrote on <span class="date">2012-05-11 12:20</span>:
        </div>
        <div class="comment-content">
          <p>To expand slightly on what someone else commented, there was <a href="https://www.infoq.com/presentations/LMAX" rel="nofollow">a talk</a> not too long ago by some guys who found out using queues to communicate between threads can be pretty hefty bottleneck. They were using the JVM.<br><br>The talk is interesting because they actually measured the stuff they do and compared it with how it affects the CPU pipelines/caches. The queue discussion is around 32 minutes into the talk.<br><br>It's perhaps not relevant for pypy-stm at the moment, but it's definitely relevant for anyone interested in high-performance multithreaded code.</p>
        </div>
      </div>
      <div class="comment comment-9048605839194282305">
        <div class="comment-header">
          <a name="comment-9048605839194282305"></a>
            <span class="author">Dima Q</span> wrote on <span class="date">2012-05-18 10:03</span>:
        </div>
        <div class="comment-content">
          <p>Good job, Armin!<br><br>This is exactly what Python needs, and if turns out hard rather than insanely hard, all the better!</p>
        </div>
      </div>
      <div class="comment comment-9214945209291164064">
        <div class="comment-header">
          <a name="comment-9214945209291164064"></a>
            <span class="author">Jonas W.</span> wrote on <span class="date">2012-05-21 17:51</span>:
        </div>
        <div class="comment-content">
          <p>I am not entirely sure about the concept which is being implemented in PyPy-stm or better, which is planned for a parallel PyPy in the future.<br><br>I think am a pretty conservative programmer, and I actually dislike the idea of running code twice because of conflicts which could have been foreseen at development time ;). I still see the advantages STM brings regarding development time.<br><br>So I'm wondering about a point which was not entirely clear in your post. You're saying you don't want people to (be forced to?) write short transactions. However, I could still in a project which is both CPU and memory intensive try to keep the thread.atomic sections as small as possible to avoid unneccessary overheads but still get effective logs?</p>
        </div>
      </div>
      <div class="comment comment-8986531617131272077">
        <div class="comment-header">
          <a name="comment-8986531617131272077"></a>
            <span class="author">Armin Rigo</span> wrote on <span class="date">2012-05-21 22:42</span>:
        </div>
        <div class="comment-content">
          <p>@Jonas: it is not always obvious at development time -- to say the least -- how to avoid all conflicts.  Think about how hard it is to add automatic GC to C++ in a large project: it's messy but you might get pretty far with just reference counting -- until some point when you loose because of cyclic references.  If instead you had used a proper GC-managed language, the problem would just not exist.  It's the same about Transactional Memory and conflicts: you can either think harder and harder about using locks correctly, until your programs becomes really messy; then you give up and use TM, solving the issue instantly and letting you think again about your original problem.<br><br>Regarding the transaction size: with a good implementation, big transactions should not be slower than small transactions.  The only potential drawback of having big transactions is that the risks of conflicts might increase (depending on your program).<br><br>Note that this question has a different answer for Python than for C, where code outside transactions runs faster than code within transactions.  It is not so in Python.  The reason is that transactions are always needed in Python: either explicitly, or implicitly in order to protect the interpreter structures (in replacement of the famous GIL).</p>
        </div>
      </div>
      <div class="comment comment-2628648278989185335">
        <div class="comment-header">
          <a name="comment-2628648278989185335"></a>
            <span class="author">Connelly Barnes</span> wrote on <span class="date">2012-05-30 05:53</span>:
        </div>
        <div class="comment-content">
          <p>Is there any plan to add type declarations as some optional mode in PyPy, like Cython allows? Because PyPy can sometimes give some speed up, but when it doesn't it seems the alternative for the user is to go back to CPython + Cython.</p>
        </div>
      </div>
      <div class="comment comment-4620530333605154730">
        <div class="comment-header">
          <a name="comment-4620530333605154730"></a>
            <span class="author">Unknown</span> wrote on <span class="date">2012-06-05 12:26</span>:
        </div>
        <div class="comment-content">
          <p>@Armin: Looks nice!<br><br>But you’re right: The explicit transaction still looks nicer.<br><br>I think though, that both can nicely complement each other: <br><br>(1) The transaction is efficient for pushing out parts of the code from the main run to get it multithreaded (think “#pragma omp parallel for” from OpenMP).<br><br>(2) The thread.atomic is efficient for protecting stuff inside a threaded application. Also I like that I don’t have to explicitely state which variables I want to protect. And I like that it is not full locking: If I don’t actually get a conflict, other code still runs in parallel.<br><br>The first actually looks more interesting though, because it might be possible to make every for-loop run like this, as long as later runs are not dependent on the result of previous runs. This would require quite heavy runtime analysis, though.</p>
        </div>
      </div>
         </div>

    <article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="../posts/2012/04/stm-update-and-thanks-everybody-6071745734932940294.html" class="u-url">STM update (and thanks everybody)</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                <a href="../authors/armin-rigo.html">Armin Rigo</a>
            </span></p>
            <p class="dateline">
            <a href="../posts/2012/04/stm-update-and-thanks-everybody-6071745734932940294.html" rel="bookmark">
            <time class="published dt-published" datetime="2012-04-27T17:22:00Z" itemprop="datePublished" title="2012-04-27 17:22">2012-04-27 17:22</time></a>
            </p>
                <p class="commentline">11 comments</p>

        </div>
    </header><div class="p-summary entry-summary">
    <p>A short update on the Software Transactional Memory (STM) side.  Let me remind you that the work is to add STM internally into PyPy, with the goal of letting the user's programs run on multiple cores after a minor adaptation.  (The goal is not to expose STM to the user's program.)  I will soon write some official documentation that explains in more details exactly what you get.  For now you can read the previous <a class="reference" href="../posts/2012/03/call-for-donations-for-software-8853699867109654713.html">blog</a> <a class="reference" href="../posts/2012/01/transactional-memory-ii-7225309560970774590.html">posts</a>, and you can also find technical details in the <a class="reference" href="https://pypy.org/tmdonate.html">call for donation</a> itself; or directly look at how I adapted the examples linked to later in this post.</p>
<p>I have now reached the point where the basics seem to work.  There is no integration with the JIT so far; moreover the integration with the Garbage Collection subsystem is not finished right now, but at least it is "not crashing in my simple tests and not leaking memory too quickly". (It means that it is never calling <tt class="docutils literal"><span class="pre">__del__</span></tt> so far, although it releases memory; and when entering transactional mode or when going to the next transaction, all live objects become immortal.  This should still let most not-too-long-running programs work.)</p>
<p>If you want to play with it, you can download <a class="reference" href="https://wyvern.cs.uni-duesseldorf.de/~arigo/pypy-stm-22fccf3c9b5e.tar.bz2">this binary</a> (you need to put it in a place with the paths <tt class="docutils literal"><span class="pre">lib-python</span></tt> and <tt class="docutils literal"><span class="pre">lib_pypy</span></tt>, for example inside the main directory from a regular <a class="reference" href="https://buildbot.pypy.org/nightly/trunk/">nightly tarball</a> or from a full checkout). This version was compiled for Linux x86 32-bit from the <a class="reference" href="https://foss.heptapod.net/pypy/pypy/-/tree/branch/stm-gc">stm-gc</a> branch on the 25th of April.  It runs e.g. the modified version of <a class="reference" href="https://foss.heptapod.net/pypy/pypy/-/tree/branch//stm-gc/pypy/translator/stm/test/richards.py">richards</a>. This branch could also be translated for Linux x86-64, but not for other OSes nor other CPUs for now.</p>
<p>The resulting <tt class="docutils literal"><span class="pre">pypy-stm</span></tt> exposes the same interface as the pure Python <a class="reference" href="https://foss.heptapod.net/pypy/pypy/-/tree/branch//stm-gc/lib_pypy/transaction.py">transaction</a> module, which is an emulator (running on CPython or any version of PyPy) which can be used to play around and prepare your programs.  See the comments in there.  A difference is that the real <tt class="docutils literal"><span class="pre">pypy-stm</span></tt> doesn't support epoll right now, so it cannot be used yet to play with <a class="reference" href="svn://svn.twistedmatrix.com/svn/Twisted/branches/stm-5526">a branch of Twisted</a> that was already adapted (thanks Jean-Paul Calderone); but that's coming soon.  For now you can use it to get multi-core usage on purely computational programs.</p>
<p>I did for example adapt PyPy's own <tt class="docutils literal"><span class="pre">translate.py</span></tt>: see the tweak <a class="reference" href="https://foss.heptapod.net/pypy/pypy/-/tree/branch/stm-gc/pypy/rpython/rtyper.py#cl-249">in rpython/rtyper.py</a>.  Lines 273-281 are all that I needed to add, and they are mostly a "simplification and parallelization" of the lines above.  There are a few more places in the whole <tt class="docutils literal"><span class="pre">translate.py</span></tt> that could be similarly modified, but overall it is just that: a few places. I did not measure performance, but I checked that it is capable of using multiple cores in the RTyping step of translation, with --- as expected --- some still-reasonable number of conflicts, particularly at the beginning when shared data structures are still being built.</p>
<p>On a few smaller, more regular examples like <a class="reference" href="https://foss.heptapod.net/pypy/pypy/-/tree/branch//stm-gc/pypy/translator/stm/test/richards.py">richards</a>, I did measure the performance.  It is not great, even taking into account that it has no JIT so far.  Running pypy-stm with one thread is roughly 5 times slower than running a regular PyPy with no JIT (it used to be better in previous versions, but they didn't have any GC; nevertheless, I need to investigate).  However, it does seem to scale.  At least, it scales roughly as expected on my 2-real-cores, 4-hyperthreaded-cores laptop (i.e. for N between 1 and 4, the N-threaded pypy-stm performs similarly to N independent pypy-stm's running one thread each).</p>
<p>And finally...</p>
<p>...a big thank you to everyone who contributed some money to support this!  As you see on the <a class="reference" href="https://pypy.org/">PyPy</a> site, we got more than 6700$ so far in only 5 or 6 weeks.  Thanks to that, my contract started last Monday, and I am now paid a small salary via the <a class="reference" href="https://sfconservancy.org/">Software Freedom Conservancy</a> (thanks Bradley M. Kuhn for organizational support from the SFC). Again, thank you everybody!</p>
<p><b>UPDATE:</b> The performance regression was due to disabling an optimization, the <i>method cache,</i> which caused non-deterministic results --- the performance could vary from simple to double.  Today, as a workaround, I made the method cache transaction-local for now; it is only effective for transactions that run for long enough (maybe 0.1ms or 1ms), but at least it is there in this situation.  In the version of richards presented above, the transactions are too short to make a difference (around 0.015ms).<br></p>
    </div>
    </article><div class="comment-level comment-level-1">
      <div class="comment comment-2002727957713897347">
        <div class="comment-header">
          <a name="comment-2002727957713897347"></a>
            <span class="author">Anonymous</span> wrote on <span class="date">2012-04-27 20:37</span>:
        </div>
        <div class="comment-content">
          <p>I don't get it.  It's great that pypy libs and so on will be multithreaded with good performance, but how does that help you to write a multithreaded program with good performance, if you don't expose the tools you used to do that?</p>
        </div>
      </div>
      <div class="comment comment-8586241353216939752">
        <div class="comment-header">
          <a name="comment-8586241353216939752"></a>
            <span class="author">Alexander Sedov</span> wrote on <span class="date">2012-04-27 20:44</span>:
        </div>
        <div class="comment-content">
          <p>Interface is exposed; transaction module it is.</p>
        </div>
      </div>
      <div class="comment comment-1615790623898745402">
        <div class="comment-header">
          <a name="comment-1615790623898745402"></a>
            <span class="author">Texatril</span> wrote on <span class="date">2012-04-27 20:44</span>:
        </div>
        <div class="comment-content">
          <p>I think the idea is that the GIL would be gone since internally the interpreter would use STM, and at the programmer level, you would be free to use the normal threading mechanisms</p>
        </div>
      </div>
      <div class="comment comment-5917140286633509139">
        <div class="comment-header">
          <a name="comment-5917140286633509139"></a>
            <span class="author">Maciej Fijalkowski</span> wrote on <span class="date">2012-04-27 20:49</span>:
        </div>
        <div class="comment-content">
          <p>@Texatril no, the point is you would not have to. You write a normal event-based program with transaction module and boom it works. It's easier than writing correct multithreaded code.</p>
        </div>
      </div>
      <div class="comment comment-6515272861580881101">
        <div class="comment-header">
          <a name="comment-6515272861580881101"></a>
            <span class="author">Anonymous</span> wrote on <span class="date">2012-04-27 20:50</span>:
        </div>
        <div class="comment-content">
          <p>Ah, you kinda contradicted yourself by saying the goal wasn't to expose STM to users' programs, but then saying that it exposed the same API as the transaction module.<br><br>The transaction module is pretty horrible though.  Might I suggest a better syntax than the transaction module?  Something like exceptions would be better:<br><br>begin:<br>    ...<br>    commit<br><br>or:<br><br>transaction:<br>    ...<br>rollback:<br>    retry<br><br>perhaps with an option (in a later  version?) to replace the "retry" with alternate code.</p>
        </div>
      </div>
      <div class="comment comment-9053545101804130362">
        <div class="comment-header">
          <a name="comment-9053545101804130362"></a>
            <span class="author">Maciej Fijalkowski</span> wrote on <span class="date">2012-04-27 20:52</span>:
        </div>
        <div class="comment-content">
          <p>@Anonymous that would be a bad API, because you cannot fail a transaction. It'll be automatically retried until it finishes. That's in-line with correct programs, just multithreaded</p>
        </div>
      </div>
      <div class="comment comment-1696861050575461106">
        <div class="comment-header">
          <a name="comment-1696861050575461106"></a>
            <span class="author">Unknown</span> wrote on <span class="date">2012-04-28 09:37</span>:
        </div>
        <div class="comment-content">
          <p>Anonymous: the user level API is any asynchronous event handling framework that uses the transaction library internally to handle events in parallel.<br><br>So, for example, you take *any* Twisted program and run it on pypy-stm and it will use the available number of cores to process events without losing any of the normal correctness guarantees of event-based programming.</p>
        </div>
      </div>
      <div class="comment comment-3763141318028727041">
        <div class="comment-header">
          <a name="comment-3763141318028727041"></a>
            <span class="author">Armin Rigo</span> wrote on <span class="date">2012-04-29 07:43</span>:
        </div>
        <div class="comment-content">
          <p>The goal is really not to expose STM to the user.  The pure Python transaction module is a working implementation, running on a single core but running.  The fact that pypy-stm provides an alternate implementation, based on STM and giving multi-core usage --- this is the implementation detail.<br><br>That's why it has the kind of API you see, and not some STM syntax like "begin: rollback: commit".  I also dislike custom keywords, because then we can no longer run the program on CPython or non-STM-based PyPys.  But I know I am no language designer myself, so the details are open for discussion.<br><br>Nick: thanks for the precisions.  Note however that the transaction module is also meant to be used directly, e.g. in CPU-intensive computational programs that don't use any event framework, like I did in rpython/rtyper.py.</p>
        </div>
      </div>
      <div class="comment comment-4086595336632138224">
        <div class="comment-header">
          <a name="comment-4086595336632138224"></a>
            <span class="author">Unknown</span> wrote on <span class="date">2012-05-01 06:10</span>:
        </div>
        <div class="comment-content">
          <p>That sounds great!<br><br>From the code I wondered, though, if it’s not actually only 2 lines:<br><br>for block in pending:<br>  transaction.add(self.specialize_block, block)<br>  transaction.run()<br><br>That sounds like map() - for example like the futures module:<br><br>with concurrent.futures.ThreadExecutor() as e:<br>  e.map(...)<br><br>Similarly something like <br><br>with transaction.Runner() as r:<br>  r.map(self.specialize_block, block)<br><br>might be easier.<br><br>Anyway: Your STM project sounds great!</p>
        </div>
      </div>
      <div class="comment comment-4340988579899641699">
        <div class="comment-header">
          <a name="comment-4340988579899641699"></a>
            <span class="author">Armin Rigo</span> wrote on <span class="date">2012-05-01 08:51</span>:
        </div>
        <div class="comment-content">
          <p>@arne: right, maybe.  It points to a similarity, at least.  This simple example corresponds nicely to map(), but in other examples (like richards) we add() more transactions from within transactions.  Nevertheless, using the "with ... as t:" syntax might work, by passing the "t" inside transactions in order to call t.map() or t.add() on it too.<br><br>This would also open the door to naturally nest these constructs.  Right now if you call transaction.run() inside a transaction, you get an error.  Such a case is more work to support in the current implementation, but from the surface it looks like a transaction.Runner() kind of interface should allow us to express what we need.</p>
        </div>
      </div>
      <div class="comment comment-4322764261353229881">
        <div class="comment-header">
          <a name="comment-4322764261353229881"></a>
            <span class="author">Unknown</span> wrote on <span class="date">2012-05-03 19:51</span>:
        </div>
        <div class="comment-content">
          <p>@Armin: Nice! Congrats for the great project!</p>
        </div>
      </div>
         </div>

    <article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="../posts/2012/04/numpy-on-pypy-progress-report-6048076549081013253.html" class="u-url">NumPy on PyPy progress report</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                <a href="../authors/maciej-fijalkowski.html">Maciej Fijalkowski</a>
            </span></p>
            <p class="dateline">
            <a href="../posts/2012/04/numpy-on-pypy-progress-report-6048076549081013253.html" rel="bookmark">
            <time class="published dt-published" datetime="2012-04-17T17:52:00Z" itemprop="datePublished" title="2012-04-17 17:52">2012-04-17 17:52</time></a>
            </p>
                <p class="commentline">17 comments</p>

        </div>
    </header><div class="p-summary entry-summary">
    <p>Hello.</p>
<p>A lot of things happened in March, like <a class="reference external" href="https://us.pycon.org">pycon</a>. I was also busy doing other
things (pictured), so apologies for the late numpy status update.</p>
<p>However, a lot of things have happened and numpy continues to be one of the
main points of entry for hacking on PyPy. Apologies to all the people whose
patches I don't review in timely manner, but seriously, you do <strong>a lot</strong> of
work.</p>
<p>This list of changes is definitely not exhaustive, and I might be forgetting
important contributions. In a loose order:</p>
<ul>
<li>
<p class="first">Matti Picus made <tt class="docutils literal">out</tt> parameter work for a lot of (but not all)
functions.</p>
</li>
<li>
<p class="first">We merged record dtypes support. The only missing dtypes left are complex
(important), datetime (less important) and object (which will probably
never be implemented because it makes very little sense and is a mess with moving GCs).</p>
</li>
<li>
<p class="first">Taavi Burns and others implemented lots of details, including lots of ufuncs.
On the completely unscientific measure of "implemented functions" on
<a class="reference external" href="https://buildbot.pypy.org/numpy-status/latest.html">numpypy status page</a>, we're close to 50% of numpy working. In reality
it might be more or less, but after complex dtypes we're getting very close
to running real programs.</p>
</li>
<li>
<p class="first">Bool indexing of arrays of the same size should work, leaving only
arrays-of-ints indexing as the last missing element of fancy indexing.</p>
</li>
<li>
<p class="first">I did some very early experiments on SSE. This work is <strong>seriously</strong>
preliminary - in fact the only implemented operation is addition of
float single-dimension numpy arrays. However, results are encouraging,
given that our assembler generator is far from ideal:</p>
<table border="1" class="docutils">
<colgroup>
<col width="22%">
<col width="14%">
<col width="14%">
<col width="9%">
<col width="23%">
<col width="17%">
</colgroup>
<tbody valign="top">
<tr>
<td> </td>
<td>
<p class="first last">Numpy</p>
</td>
<td>
<p class="first last">PyPy SSE</p>
</td>
<td>
<p class="first last">PyPy</p>
</td>
<td>
<p class="first last">GCC non-looped</p>
</td>
<td>
<p class="first last">GCC looped</p>
</td>
</tr>
<tr>
<td>
<p class="first last"><tt class="docutils literal">a+b</tt></p>
</td>
<td>
<p class="first last">0.6s</p>
</td>
<td>
<p class="first last">0.3s</p>
</td>
<td>
<p class="first last">0.4s</p>
</td>
<td>
<p class="first last">0.3s</p>
</td>
<td>
<p class="first last">0.25s</p>
</td>
</tr>
<tr>
<td>
<p class="first last"><tt class="docutils literal">a+b+c</tt></p>
</td>
<td>
<p class="first last">1.9s</p>
</td>
<td>
<p class="first last">0.35s</p>
</td>
<td>
<p class="first last">0.5s</p>
</td>
<td>
<p class="first last">0.7s</p>
</td>
<td>
<p class="first last">0.32s</p>
</td>
</tr>
<tr>
<td>
<p class="first last"><tt class="docutils literal">a+b+c+d+e</tt></p>
</td>
<td>
<p class="first last">3.2s</p>
</td>
<td>
<p class="first last">0.36s</p>
</td>
<td>
<p class="first last">0.8s</p>
</td>
<td>
<p class="first last">1.7s</p>
</td>
<td>
<p class="first last">0.51s</p>
</td>
</tr>
</tbody>
</table>
<p>The <a class="reference external" href="https://bitbucket.org/fijal/hack2/src/fa3119d8ade6/bench/numeric">benchmark repo</a> is available. GCC was run with <tt class="docutils literal"><span class="pre">-O3</span></tt>, no further
options specified. PyPy was run with default options, the SSE branch is under
<tt class="docutils literal"><span class="pre">backend-vector-ops</span></tt>, but <strong>it's not working completely</strong> yet.</p>
<p>One might argue that C and Python is not the same code - indeed it is not.
It just shows some possible approach to writing numeric code.</p>
</li>
</ul>
<p>Next step would be to just continue implementing missing features such as</p>
<ul class="simple">
<li>specialised arrays i.e. masked arrays and matrixes</li>
<li>core modules such as <tt class="docutils literal">fft</tt>, <tt class="docutils literal">linalg</tt>, <tt class="docutils literal">random</tt>.</li>
<li>numpy's testing framework</li>
</ul>
<p>The future is hard to predict, but we're not far off!</p>
<p>Cheers,<br>fijal</p>

<p><b>UPDATE:</b>Indeed, string and unicode dtypes are not supported yet. They're as important as complex dtype</p>
    </div>
    </article><div class="comment-level comment-level-1">
      <div class="comment comment-3073859409540047828">
        <div class="comment-header">
          <a name="comment-3073859409540047828"></a>
            <span class="author">Jeff Terrace</span> wrote on <span class="date">2012-04-17 18:53</span>:
        </div>
        <div class="comment-content">
          <p>I think the string dtype is missing too?</p>
        </div>
      </div>
      <div class="comment comment-9212986645433735699">
        <div class="comment-header">
          <a name="comment-9212986645433735699"></a>
            <span class="author">Anonymous</span> wrote on <span class="date">2012-04-17 19:57</span>:
        </div>
        <div class="comment-content">
          <p>Hello,<br><br>May you get a bit more precise on the GCC test ?<br><br>For instance, is the GCC code using SSE too ? Is it written in a single loop (x[i] = a[i] + b[i] + c[i]) or in several consecutive loops first a+b then (a+b) + c ?<br><br>Just to know :-)</p>
        </div>
      </div>
      <div class="comment comment-3794349908863683763">
        <div class="comment-header">
          <a name="comment-3794349908863683763"></a>
            <span class="author">Winston Ewert</span> wrote on <span class="date">2012-04-17 20:03</span>:
        </div>
        <div class="comment-content">
          <p>One thing I'll note is that I do from time to time use the object dtype. Occasionally, I've got multidimensional arrays of objects, and the array operations from numpy are useful. I don't really get a speed advantage there, but the interface from numpy is useful. But its not super necessary and certainly not a priority.</p>
        </div>
      </div>
      <div class="comment comment-1475098217748418721">
        <div class="comment-header">
          <a name="comment-1475098217748418721"></a>
            <span class="author">Anonymous</span> wrote on <span class="date">2012-04-17 20:04</span>:
        </div>
        <div class="comment-content">
          <p>Sorry, didn't RTFA completely. I just had a look at the C code.<br><br>Still, a question: is PyPy doing the optimization of combining operations in one step ?<br><br>A "good" Fortran compiler should be able to do those optimizations, for instance.</p>
        </div>
      </div>
      <div class="comment comment-8144034095267301743">
        <div class="comment-header">
          <a name="comment-8144034095267301743"></a>
            <span class="author">Gaël</span> wrote on <span class="date">2012-04-17 21:17</span>:
        </div>
        <div class="comment-content">
          <p>You should compare to numpy with a JIT, such as numexpr, it would be interesting to see whether PyPy is able to beat the numexpr JIT.</p>
        </div>
      </div>
      <div class="comment comment-558565961870943947">
        <div class="comment-header">
          <a name="comment-558565961870943947"></a>
            <span class="author">x</span> wrote on <span class="date">2012-04-17 22:55</span>:
        </div>
        <div class="comment-content">
          <p>Very cool!</p>
        </div>
      </div>
      <div class="comment comment-5523713996652875361">
        <div class="comment-header">
          <a name="comment-5523713996652875361"></a>
            <span class="author">Armin Rigo</span> wrote on <span class="date">2012-04-18 10:07</span>:
        </div>
        <div class="comment-content">
          <p>"busy doing other things (pictured)".  Pictured where? :-)</p>
        </div>
      </div>
      <div class="comment comment-4263250331155652779">
        <div class="comment-header">
          <a name="comment-4263250331155652779"></a>
            <span class="author">Ralf Gommers</span> wrote on <span class="date">2012-04-18 20:45</span>:
        </div>
        <div class="comment-content">
          <p>Hi, Numpy masked arrays, matrices and the testing framework are pure Python, so why do you need to implement them?</p>
        </div>
      </div>
      <div class="comment comment-6732107377708523751">
        <div class="comment-header">
          <a name="comment-6732107377708523751"></a>
            <span class="author">Alex</span> wrote on <span class="date">2012-04-18 22:20</span>:
        </div>
        <div class="comment-content">
          <p>Ralf, we don't have to implement the pure-python stuff, so much as we need to make sure the features of NumPy's core that they depend on are implemented.</p>
        </div>
      </div>
      <div class="comment comment-1805833778565543988">
        <div class="comment-header">
          <a name="comment-1805833778565543988"></a>
            <span class="author">EOL (Eric O LEBIGOT)</span> wrote on <span class="date">2012-04-19 10:17</span>:
        </div>
        <div class="comment-content">
          <p>Support for objects is actually quite useful: please reconsider adding it.<br><br>Here is a very useful case: the manipulation of arrays of numbers with uncertainties (special uncertainties.UFloat objects). Numbers with uncertainties behave very much like regular numbers: it is very useful to be able to use the regular NumPy syntax for array operations, for calculating matrix inverses when the matrices contain number with uncertainties, etc. I know many people use these features.<br><br>It would be *great* (read: irreplaceable :) to have support for the object NumPy dtype.</p>
        </div>
      </div>
      <div class="comment comment-7446751840380114413">
        <div class="comment-header">
          <a name="comment-7446751840380114413"></a>
            <span class="author">Unknown</span> wrote on <span class="date">2012-04-19 13:47</span>:
        </div>
        <div class="comment-content">
          <p>This sounds really cool!<br><br>And it would be awesome if you’d manage to coordinate with numpy, so the projects merge to a single python codebase with two separate backends: One C-Extension based for CPython and one Pure-Python based for pypy.</p>
        </div>
      </div>
      <div class="comment comment-5328275691930000907">
        <div class="comment-header">
          <a name="comment-5328275691930000907"></a>
            <span class="author">Anonymous</span> wrote on <span class="date">2012-04-19 17:19</span>:
        </div>
        <div class="comment-content">
          <p>Any chance comparing with Fortran? There are assumptions about pointers and alignment that Fortran compiler can make.</p>
        </div>
      </div>
      <div class="comment comment-2855233754711967879">
        <div class="comment-header">
          <a name="comment-2855233754711967879"></a>
            <span class="author">Unknown</span> wrote on <span class="date">2012-04-20 15:26</span>:
        </div>
        <div class="comment-content">
          <p>Nice...but what is the next step?<br>Numpy alone is not that useful.<br><br>"We" need at least scipy and matplotlib.<br><br>Are you going to port all these modules? I don't think so.<br><br>One way forward could be to have numpy in pypy and at least scipy and matplotlib working with the pypy C api at a decent speed.<br><br>What do you think?</p>
        </div>
      </div>
      <div class="comment comment-8133362336255297955">
        <div class="comment-header">
          <a name="comment-8133362336255297955"></a>
            <span class="author">Anonymous</span> wrote on <span class="date">2012-04-22 20:07</span>:
        </div>
        <div class="comment-content">
          <p>What about pickling? I'd love to experiment with hybrid CPython/PyPy execution using some magic from the multiprocessing module or a similar parallel computation framework.</p>
        </div>
      </div>
      <div class="comment comment-1755431587771992012">
        <div class="comment-header">
          <a name="comment-1755431587771992012"></a>
            <span class="author">Anonymous</span> wrote on <span class="date">2012-07-30 21:02</span>:
        </div>
        <div class="comment-content">
          <p>Hello,<br><br>This is a very promising result, thank you for sharing it.<br>Could you give a few more details about the differences wrt to numpy?<br><br>What would people have to do to use numpypy with scipy?</p>
        </div>
      </div>
      <div class="comment comment-1216389594999511994">
        <div class="comment-header">
          <a name="comment-1216389594999511994"></a>
            <span class="author">Raul Durand</span> wrote on <span class="date">2012-08-06 16:52</span>:
        </div>
        <div class="comment-content">
          <p>I think the numpy.linalg module is pretty important.<br>How to move efforts into this?</p>
        </div>
      </div>
      <div class="comment comment-8863930018685865034">
        <div class="comment-header">
          <a name="comment-8863930018685865034"></a>
            <span class="author">Raul Durand</span> wrote on <span class="date">2012-08-06 16:53</span>:
        </div>
        <div class="comment-content">
          <p>I think the numpy.linalg module is pretty important.<br>How to move efforts into this?</p>
        </div>
      </div>
         </div>

    <article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="../posts/2012/04/pycon-2012-wrap-up-559575896040055505.html" class="u-url">PyCon 2012 wrap up</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                <a href="../authors/maciej-fijalkowski.html">Maciej Fijalkowski</a>
            </span></p>
            <p class="dateline">
            <a href="../posts/2012/04/pycon-2012-wrap-up-559575896040055505.html" rel="bookmark">
            <time class="published dt-published" datetime="2012-04-13T17:36:00Z" itemprop="datePublished" title="2012-04-13 17:36">2012-04-13 17:36</time></a>
            </p>
                <p class="commentline">2 comments</p>

        </div>
    </header><div class="p-summary entry-summary">
    <p>So, PyCon happened. This was the biggest PyCon ever and probably the biggest
gathering of Python hackers ever.</p>
<p>From the PyPy perspective, a lot at PyCon was about PyPy. Listing things:</p>
<ul class="simple">
<li>David Beazley presented an excellent keynote describing his experience
diving head-first into PyPy and at least partly failing. He, however, did
not fail to explain bits and pieces about PyPy's architecture.
<a class="reference external" href="https://pyvideo.org/video/659/keynote-david-beazley">Video</a> is available.</li>
<li>We gave tons of talks, including the <a class="reference external" href="https://pyvideo.org/video/612/how-to-get-the-most-out-of-your-pypy">tutorial</a>, <a class="reference external" href="https://pyvideo.org/video/661/why-pypy-by-example">why pypy by example</a>
and <a class="reference external" href="https://pyvideo.org/video/662/how-the-pypy-jit-works">pypy's JIT architecture</a>
</li>
<li>We had a giant influx of new commiters, easily doubling the amount of pull
requests ever created for PyPy. The main topics for newcomers were numpy and
py3k, disproving what David said about PyPy being too hard to dive into ;)</li>
<li>Guido argued in his keynote that Python is not too slow. In the meantime,
we're trying to <a class="reference external" href="https://mrjoes.github.com/2011/12/15/sockjs-bench.html">prove him correct</a> :-)</li>
</ul>
<p>We would like to thank everyone who talked to us, shared ideas and especially
those who participated in sprints - we're always happy to welcome newcomers!</p>
<p>I'm sure there are tons of things I forgot, but thank you all!</p>
<p>Cheers,
fijal</p>
    </div>
    </article><div class="comment-level comment-level-1">
      <div class="comment comment-7647610238146158643">
        <div class="comment-header">
          <a name="comment-7647610238146158643"></a>
            <span class="author">Dave Beazley</span> wrote on <span class="date">2012-04-14 00:16</span>:
        </div>
        <div class="comment-content">
          <p>I'm so happy to be proven wrong!</p>
        </div>
      </div>
      <div class="comment comment-6864093723227597514">
        <div class="comment-header">
          <a name="comment-6864093723227597514"></a>
            <span class="author">Maciej Fijalkowski</span> wrote on <span class="date">2012-04-14 09:36</span>:
        </div>
        <div class="comment-content">
          <p>I think "proven" is a bit strong word, we're trying though :)</p>
        </div>
      </div>
         </div>

    <article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="../posts/2012/04/py3k-status-update-3-6975588144646689872.html" class="u-url">Py3k status update #3</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                <a href="../authors/antonio-cuni.html">Antonio Cuni</a>
            </span></p>
            <p class="dateline">
            <a href="../posts/2012/04/py3k-status-update-3-6975588144646689872.html" rel="bookmark">
            <time class="published dt-published" datetime="2012-04-06T20:06:00Z" itemprop="datePublished" title="2012-04-06 20:06">2012-04-06 20:06</time></a>
            </p>
                <p class="commentline">4 comments</p>

        </div>
    </header><div class="p-summary entry-summary">
    <div class="document" id="py3k-status-update-3">This is the third status update about my work on the <a class="reference external" href="https://foss.heptapod.net/pypy/pypy/-/tree/branch/py3k">py3k branch</a>, which I can work on thanks to all of the people who <a class="reference external" href="../posts/2012/01/py3k-and-numpy-first-stage-thanks-to-3008917396290059758.html">donated</a> to the <a class="reference external" href="https://pypy.org/py3donate.html">py3k proposal</a>.<br><br>
A lot of work has been done during the last month: as usual, the list of changes is too big to be reported in a detalied way, so this is just a summary of what happened.<br><br>
One of the most active areas was killing old and deprecated features. In particular, we killed support for the <tt class="docutils literal">__cmp__</tt> special method and its counsins, the <tt class="docutils literal">cmp</tt> builtin function and keyword argument for <tt class="docutils literal">list.sort()</tt> and <tt class="docutils literal">sorted()</tt>.  Killing is easy, but then you have to fix all the places which breaks because of this, including all the types which relied on <tt class="docutils literal">__cmp__</tt> to be comparable,, fixing all the tests which tried to order objects which are no longer ordeable now, or implementing new behavior like forbidding calling <tt class="docutils literal">hash()</tt> on objects which implement <tt class="docutils literal">__eq__</tt> but not <tt class="docutils literal">__hash__</tt>.<br><br>
Among the other features, we killed lots of now-gone functions in the <tt class="docutils literal">operator</tt> module, the builtins <tt class="docutils literal">apply()</tt>, <tt class="docutils literal">reduce()</tt> and <tt class="docutils literal">buffer</tt>, and the <tt class="docutils literal">os.*</tt> functions to deal with temporary files, which has been deprecated in favour of the new <tt class="docutils literal">tempfile</tt> module.<br><br>
The other topic which can't miss in a py3k status update is, as usual, string-vs-unicode. At this round, we fixed bugs in string formatting (in particular to teach <tt class="docutils literal">format()</tt> to always use unicode strings) and various corner cases about when calling the (possibly overridden) <tt class="docutils literal">__str__</tt> method on subclasses of <tt class="docutils literal">str</tt>. Believe me, you don't want to know the precise rules :-).<br><br>
Other features which we worked on and fixed tests include, but are not limited to, <tt class="docutils literal">marshal</tt>, <tt class="docutils literal">hashlib</tt>, <tt class="docutils literal">zipimport</tt>, <tt class="docutils literal">_socket</tt> and <tt class="docutils literal">itertools</tt>, plus the habitual endless lists of tests which fail for shallow reasons such as the syntactic differences, <tt class="docutils literal">int</tt> vs <tt class="docutils literal">long</tt>, <tt class="docutils literal">range()</tt> vs <tt class="docutils literal"><span class="pre">list(range())</span></tt> etc. As a result, the number of failing tests <a class="reference external" href="https://buildbot.pypy.org/summary?category=linux32&amp;branch=py3k&amp;recentrev=53956:3c8ac35c653a">dropped</a> from 650 to 235: we are beginning to see the light at the end of the tunnel :-)<br><br>
Benjamin finished implementing Python 3 syntax. Most of it was small cleanups and tweaks to be compatible with CPython such as making <tt class="docutils literal">True</tt> and <tt class="docutils literal">False</tt> keywords and preventing <tt class="docutils literal">. . .</tt> (note spaces between dots) from being parsed as <tt class="docutils literal">Ellipsis</tt>. Larger syntax additions included keyword only arguments and function annotations.<br><br>
Finally, we did some RPython fixes, so that it is possible again to translate PyPy in the py3k branch. However, the resuling binary is a strange beast which mixes python 2 and python 3 semantics, so it is unusable for anything but <a class="reference external" href="https://paste.pocoo.org/show/577006/">showing friends how cool it is</a>.<br><br>
I would like to underline that I was not alone in doing all this work. In particular, a lot of people joined the PyPy sprint at Pycon and worked on the branch, as you can clearly see in this activity graph. I would like to thank all who helped!<br><div class="separator" style="clear: both; text-align: center;"><a href="https://1.bp.blogspot.com/-XIrydp78nVs/T38-WyUX0PI/AAAAAAAAAQE/bLvx330NcAs/s1600/py3k-activity-march.png" style="margin-left: 1em; margin-right: 1em;"><img border="0" height="150" src="https://1.bp.blogspot.com/-XIrydp78nVs/T38-WyUX0PI/AAAAAAAAAQE/bLvx330NcAs/s400/py3k-activity-march.png" width="400"></a></div>
<br>
cheers,<br>
Antonio and Benjamin</div>
    </div>
    </article><div class="comment-level comment-level-1">
      <div class="comment comment-2426151895685073139">
        <div class="comment-header">
          <a name="comment-2426151895685073139"></a>
            <span class="author">Unknown</span> wrote on <span class="date">2012-04-11 11:19</span>:
        </div>
        <div class="comment-content">
          <p>Very cool work!<br><br>Thanks for the update! I‘ll need to see if I can already let it hit my own python3 project (I had to convert that to python2.x to make it run with pypy, being able to get rid of that step would be really cool!)<br><br>Do you already have prebuilt binaries of pypy3?</p>
        </div>
      </div>
      <div class="comment comment-2572897923108713748">
        <div class="comment-header">
          <a name="comment-2572897923108713748"></a>
            <span class="author">Antonio Cuni</span> wrote on <span class="date">2012-04-14 11:21</span>:
        </div>
        <div class="comment-content">
          <p>I don't think that there is any chance that a python3 project will run as of now, there are still tons of features missing. So far my job as mostly been to fix all the failing tests in the PyPy testsuite. When I'll have finished, I'll be able to start with new features.<br><br>And, for the same reason: no prebuilt binaries yet, sorry.</p>
        </div>
      </div>
      <div class="comment comment-4039565102332535128">
        <div class="comment-header">
          <a name="comment-4039565102332535128"></a>
            <span class="author">Unknown</span> wrote on <span class="date">2012-04-19 13:41</span>:
        </div>
        <div class="comment-content">
          <p>OK, thanks for the info!<br><br>I’m anxious to test it, once you give it a chance to run simple unicode-using code!</p>
        </div>
      </div>
      <div class="comment comment-582609035431682696">
        <div class="comment-header">
          <a name="comment-582609035431682696"></a>
            <span class="author">Anonymous</span> wrote on <span class="date">2012-05-30 20:01</span>:
        </div>
        <div class="comment-content">
          <p>Pocoo's pastebin has unfortunately permanently shut down.  Any chance you could repaste how cool it is somewhere else?</p>
        </div>
      </div>
         </div>

    <article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="../posts/2012/04/pypy-sprint-in-leipzig-june-22-27-6450601012927549960.html" class="u-url">PyPy sprint in Leipzig, Germany (June 22-27)</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                <a href="../authors/armin-rigo.html">Armin Rigo</a>
            </span></p>
            <p class="dateline">
            <a href="../posts/2012/04/pypy-sprint-in-leipzig-june-22-27-6450601012927549960.html" rel="bookmark">
            <time class="published dt-published" datetime="2012-04-05T10:13:00Z" itemprop="datePublished" title="2012-04-05 10:13">2012-04-05 10:13</time></a>
            </p>
            
        </div>
    </header><div class="p-summary entry-summary">
    <p>The next PyPy sprint will be held --- for the first time in a while ---
in a place where we haven't been so far: Leipzig, Germany, at the
<a class="reference" href="https://www.python-academy.com/">Python Academy</a>'s Teaching Center.  It will take place from the 22nd
to the 27th of June 2012, before EuroPython.  Thanks to Mike Müller for
organizing it!</p>
<p>This is a fully public sprint, everyone is welcome to join us.  All days are
full sprint days, so it is recommended to arrive the 21st and leave the 28th.</p>
<h3>Topics and goals</h3>
<p>Open.  Here are some goals:</p>
<ul class="simple">
<li>numpy: progress towards completing the <tt class="docutils literal"><span class="pre">numpypy</span></tt> module; try to
use it in real code</li>
<li>stm: progress on Transactional Memory; try out the <tt class="docutils literal"><a href="https://foss.heptapod.net/pypy/pypy/-/tree/branch/stm-gc/lib_pypy/transaction.py"><span class="pre">transaction</span></a></tt> module on real code.</li>
<li>jit optimizations: there are a number of optimizations we can still
try out or refactor.</li>
<li>work on various, more efficient data structures for Python language.
A good example would be lazy string slicing/concatenation or more efficient
objects.</li>
<li>any other PyPy-related topic is fine too.</li>
</ul>
<h3>Grants</h3>
<p>For students, we have the possibility to support some costs via PyPy
funds.  Additionally, we can support you applying for grants from the
PSF and other sources.</p>
<h3>Registration</h3>
<p>If you'd like to come, please <em>sign up</em> either by announcing yourself on
<a class="reference" href="https://mail.python.org/mailman/listinfo/pypy-dev">pypy-dev</a>, or by directly adding yourself to the <a class="reference" href="https://foss.heptapod.net/pypy/extradoc/-/blob/branch/default/extradoc/sprintinfo/leipzig2012/people.txt">list of people</a>.
(We need to have a head count for the organization.)  If you are new to
the project please drop a note about your interests and post any
questions.</p>
<h3>More...</h3>
<p>For more information, please see the <a href="https://wyvern.cs.uni-duesseldorf.de/~arigo/leipzig2012.html">sprint announcement.</a></p>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="../posts/2012/03/call-for-donations-for-software-8853699867109654713.html" class="u-url">Call for donations for Software Transactional Memory</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                <a href="../authors/armin-rigo.html">Armin Rigo</a>
            </span></p>
            <p class="dateline">
            <a href="../posts/2012/03/call-for-donations-for-software-8853699867109654713.html" rel="bookmark">
            <time class="published dt-published" datetime="2012-03-08T18:07:00Z" itemprop="datePublished" title="2012-03-08 18:07">2012-03-08 18:07</time></a>
            </p>
                <p class="commentline">10 comments</p>

        </div>
    </header><div class="p-summary entry-summary">
    <p><i>Hi all,</i></p>

<p><i>The <a href="https://pypy.org/tmdonate.html">Software Transactional Memory
call for donations</a> is up.  From the proposal:</i></p>

<table><tr>
<td width="4%"></td>
<td>
Previous attempts on Hardware Transactional Memory focused on parallelizing existing programs written using the <code>thread</code> or <code>threading</code> modules. However, as argued <a href="https://mail.python.org/pipermail/pypy-dev/2012-January/009044.html">here</a>, this may not be the most practical way to achieve real multithreading; it seems that better alternatives would offer good scalability too. Notably, Transactional Memory could benefit any event-based system that is written to dispatch events serially (Twisted-based, most GUI toolkit, Stackless, gevent, and so on). The events would internally be processed in parallel, while maintaining the illusion of serial execution, with all the corresponding benefits of safety. This should be possible with minimal changes to the event dispatchers. This approach has been described by the Automatic Mutual Exclusion work at Microsoft Research, but not been implemented anywhere (to the best of our knowledge).
<br><br>
Note that, yes, this gives you both sides of the coin: you keep using your non-thread-based program (without worrying about locks and their drawbacks like deadlocks, races, and friends), and your programs benefit from all your cores.
<br><br>
In more details, a low-level built-in module will provide the basics to start transactions in parallel; but this module will be only used internally in a tweaked version of, say, a Twisted reactor. Using this reactor will be enough for your existing Twisted-based programs to actually run on multiple cores. You, as a developer of the Twisted-based program, have only to care about improving the parallelizability of your program (e.g. by splitting time-consuming transactions into several parts; the exact rules will be published in detail once they are known).
</td>
<td width="4%"></td>
</tr></table>
<p><i>The point is that your program is always <i>correct</i>, and can be tweaked to improve performance.  This is the opposite from what explicit threads and locks give you, which is a performant program which you need to tweak to remove bugs.  Arguably, this approach is the reason for why you use Python in the first place :-)</i></p>

<p><i>Armin</i></p>
    </div>
    </article><div class="comment-level comment-level-1">
      <div class="comment comment-2048072898193933227">
        <div class="comment-header">
          <a name="comment-2048072898193933227"></a>
            <span class="author">Konstantine Rybnikov</span> wrote on <span class="date">2012-03-08 21:13</span>:
        </div>
        <div class="comment-content">
          <p>Great news, really looking into experimenting with that, good luck!<br><br>My question is: will it map to os thread being created on each event dispatch or can it potentially be somehow optimized? I mean, you can potentially end up with code that has tons of small events, and creating os thread on each event would slow down your program.</p>
        </div>
      </div>
      <div class="comment comment-2803441516229718784">
        <div class="comment-header">
          <a name="comment-2803441516229718784"></a>
            <span class="author">Anonymous</span> wrote on <span class="date">2012-03-08 23:22</span>:
        </div>
        <div class="comment-content">
          <p>@k_bx it's not like that at all. There are links in the proposal that may enlighten, depending on what you already know.</p>
        </div>
      </div>
      <div class="comment comment-7895526174732297401">
        <div class="comment-header">
          <a name="comment-7895526174732297401"></a>
            <span class="author">Armin Rigo</span> wrote on <span class="date">2012-03-09 01:49</span>:
        </div>
        <div class="comment-content">
          <p>Indeed, it is creating a pool of N threads and reusing them, where N is configurable.  Ideally it should default to the number of cores you have, detected in some (sadly non-portable) way.</p>
        </div>
      </div>
      <div class="comment comment-8669130059244413455">
        <div class="comment-header">
          <a name="comment-8669130059244413455"></a>
            <span class="author">Anonymous</span> wrote on <span class="date">2012-03-09 09:06</span>:
        </div>
        <div class="comment-content">
          <p>Are any of you affiliated with a university? Since this is research, maybe you can get a grant for a post-doc or a PhD position.</p>
        </div>
      </div>
      <div class="comment comment-6334632753942852622">
        <div class="comment-header">
          <a name="comment-6334632753942852622"></a>
            <span class="author">Anonymous</span> wrote on <span class="date">2012-03-09 10:03</span>:
        </div>
        <div class="comment-content">
          <p>Trivial comment - on the donation page in the "What is Transactional Memory?" section, I think a (TM) has been turned into a superscript TM (as in trademark).</p>
        </div>
      </div>
      <div class="comment comment-6321939394852410496">
        <div class="comment-header">
          <a name="comment-6321939394852410496"></a>
            <span class="author">Steve Phillips</span> wrote on <span class="date">2012-03-10 00:50</span>:
        </div>
        <div class="comment-content">
          <p>This sounds exciting for the kinds of Python programs that would benefit from TM, but can anyone give a ballpark estimate of what percentage of programs that might be?<br><br>Personally, I write various (non-evented) Python scripts (replacements for Bash scripts, IRC bot, etc) and do a lot of Django web dev.  It's not clear that I or similar people would benefit from Transactional Memory.<br><br>Is that correct?</p>
        </div>
      </div>
      <div class="comment comment-3660931603651307277">
        <div class="comment-header">
          <a name="comment-3660931603651307277"></a>
            <span class="author">Anonymous</span> wrote on <span class="date">2012-03-10 01:23</span>:
        </div>
        <div class="comment-content">
          <p>Could u update the donation page? It doesn't seem to be tallying the amounts.<br><br>I am really excited to see this work even if it is pure research (I donated $200). It would be awesome if<br><br>stm:<br>....pre:<br>........# init transaction state<br>....trans:<br>........# parallel stuff<br><br>So it would be easy to retry failed transactions or be able to reorder them for contention or perf.</p>
        </div>
      </div>
      <div class="comment comment-1248553685063980247">
        <div class="comment-header">
          <a name="comment-1248553685063980247"></a>
            <span class="author">kurdakov</span> wrote on <span class="date">2012-03-17 17:07</span>:
        </div>
        <div class="comment-content">
          <p>offtopic:<br><br>there is a project to help bring C# and C++ together<br><br>https://github.com/mono/cxxi<br>and fork https://github.com/kthompson/cxxi <br><br>in essence: there is a generation step which allows then to easily use C++ objects in C# and vice versa.<br><br>considering that ctypes are very much like p/invoke, it looks like pypy might have something similar for python/C++ environments , this might allow much easier to port, for example, Blender to use pypy as scripting language.</p>
        </div>
      </div>
      <div class="comment comment-3658413981857277481">
        <div class="comment-header">
          <a name="comment-3658413981857277481"></a>
            <span class="author">Arne Babenhauserheide</span> wrote on <span class="date">2012-03-22 14:08</span>:
        </div>
        <div class="comment-content">
          <p>Could you post an example snippet of code which would benefit from that? <br><br>I ask because I have trouble really imagining example code.<br><br>Something minimal with the least possible amount of extension modules which I could just throw into the pypy and pypy-tm interpreter and see the difference.</p>
        </div>
      </div>
      <div class="comment comment-3281850216528291407">
        <div class="comment-header">
          <a name="comment-3281850216528291407"></a>
            <span class="author">Armin Rigo</span> wrote on <span class="date">2012-04-02 15:12</span>:
        </div>
        <div class="comment-content">
          <p>I wrote a minimal example here:<br><br>https://foss.heptapod.net/pypy/pypy/-/tree/branch//stm-gc/lib_pypy/transaction.py</p>
        </div>
      </div>
         </div>

</div>
</div>
<div class="sidebar">
<div>
  <h2>
    The PyPy blogposts
  </h2>
  <div>
    Create a guest post via a PR to the <a href="https://github.com/pypy/pypy.org">source repo</a>
  </div>
</div>
    <div id="global-recent-posts">
    <h2>
      Recent Posts
    </h2>
    <ul class="post-list">
      <li>
        <a href="/posts/2025/12/toy-load-store.html" class="listtitle">Load and store forwarding in the Toy Optimizer</a>
      </li>
      <li>
        <a href="/posts/2025/07/pypy-v7320-release.html" class="listtitle">PyPy v7.3.20 release</a>
      </li>
      <li>
        <a href="/posts/2025/06/rpython-gc-allocation-speed.html" class="listtitle">How fast can the RPython GC allocate?</a>
      </li>
      <li>
        <a href="/posts/2025/04/prospero-in-rpython.html" class="listtitle">Doing the Prospero-Challenge in RPython</a>
      </li>
      <li>
        <a href="/posts/2025/02/pypy-v7319-release.html" class="listtitle">PyPy v7.3.19 release</a>
      </li>
      <li>
        <a href="/posts/2025/02/pypy-gc-sampling.html" class="listtitle">Low Overhead Allocation Sampling with VMProf in PyPy's GC</a>
      </li>
      <li>
        <a href="/posts/2025/02/pypy-v7318-release.html" class="listtitle">PyPy v7.3.18 release</a>
      </li>
      <li>
        <a href="/posts/2025/01/musings-tracing.html" class="listtitle">Musings on Tracing in PyPy</a>
      </li>
      <li>
        <a href="/posts/2025/01/towards-pypy311-an-update.html" class="listtitle">Towards PyPy3.11 - an update</a>
      </li>
      <li>
        <a href="/posts/2024/11/guest-post-final-encoding-in-rpython.html" class="listtitle">Guest Post: Final Encoding in RPython Interpreters</a>
      </li>
    </ul>
  </div>

          <div id="global-archive-list">
          <h2>
            Archives
          </h2>
          <ul class="archive-level archive-level-1">
            <li><a class="reference" href="/2007/">2007</a> (19)
            </li>
            <li><a class="reference" href="/2008/">2008</a> (62)
            </li>
            <li><a class="reference" href="/2009/">2009</a> (38)
            </li>
            <li><a class="reference" href="/2010/">2010</a> (44)
            </li>
            <li><a class="reference" href="/2011/">2011</a> (43)
            </li>
            <li><a class="reference" href="/2012/">2012</a> (44)
            </li>
            <li><a class="reference" href="/2013/">2013</a> (46)
            </li>
            <li><a class="reference" href="/2014/">2014</a> (22)
            </li>
            <li><a class="reference" href="/2015/">2015</a> (20)
            </li>
            <li><a class="reference" href="/2016/">2016</a> (20)
            </li>
            <li><a class="reference" href="/2017/">2017</a> (13)
            </li>
            <li><a class="reference" href="/2018/">2018</a> (12)
            </li>
            <li><a class="reference" href="/2019/">2019</a> (12)
            </li>
            <li><a class="reference" href="/2020/">2020</a> (9)
            </li>
            <li><a class="reference" href="/2021/">2021</a> (10)
            </li>
            <li><a class="reference" href="/2022/">2022</a> (13)
            </li>
            <li><a class="reference" href="/2023/">2023</a> (6)
            </li>
            <li><a class="reference" href="/2024/">2024</a> (13)
            </li>
            <li><a class="reference" href="/2025/">2025</a> (9)
            </li>
          </ul>
        </div>


          <div id="global-tag-list">
          <h2>
            Tags
          </h2>
          <ul>
            <li><a class="reference" href="/categories/arm.html">arm</a> (2)</li>
            <li><a class="reference" href="/categories/benchmarking.html">benchmarking</a> (1)</li>
            <li><a class="reference" href="/categories/casestudy.html">casestudy</a> (3)</li>
            <li><a class="reference" href="/categories/cli.html">cli</a> (1)</li>
            <li><a class="reference" href="/categories/compiler.html">compiler</a> (1)</li>
            <li><a class="reference" href="/categories/conda-forge.html">conda-forge</a> (1)</li>
            <li><a class="reference" href="/categories/cpyext.html">cpyext</a> (4)</li>
            <li><a class="reference" href="/categories/cpython.html">CPython</a> (3)</li>
            <li><a class="reference" href="/categories/ep2008.html">ep2008</a> (1)</li>
            <li><a class="reference" href="/categories/extension-modules.html">extension modules</a> (3)</li>
            <li><a class="reference" href="/categories/gc.html">gc</a> (3)</li>
            <li><a class="reference" href="/categories/guestpost.html">guestpost</a> (3)</li>
            <li><a class="reference" href="/categories/graalpython.html">GraalPython</a> (1)</li>
            <li><a class="reference" href="/categories/hpy.html">hpy</a> (1)</li>
            <li><a class="reference" href="/categories/heptapod.html">Heptapod</a> (1)</li>
            <li><a class="reference" href="/categories/jit.html">jit</a> (23)</li>
            <li><a class="reference" href="/categories/jython.html">jython</a> (1)</li>
            <li><a class="reference" href="/categories/kcachegrind.html">kcachegrind</a> (1)</li>
            <li><a class="reference" href="/categories/meta.html">meta</a> (1)</li>
            <li><a class="reference" href="/categories/numpy.html">numpy</a> (24)</li>
            <li><a class="reference" href="/categories/parser.html">parser</a> (1)</li>
            <li><a class="reference" href="/categories/performance.html">performance</a> (2)</li>
            <li><a class="reference" href="/categories/profiling.html">profiling</a> (7)</li>
            <li><a class="reference" href="/categories/pypy.html">pypy</a> (6)</li>
            <li><a class="reference" href="/categories/pypy3.html">pypy3</a> (16)</li>
            <li><a class="reference" href="/categories/pyqt4.html">PyQt4</a> (1)</li>
            <li><a class="reference" href="/categories/release.html">release</a> (66)</li>
            <li><a class="reference" href="/categories/releasecffi.html">releasecffi</a> (3)</li>
            <li><a class="reference" href="/categories/releaserevdb.html">releaserevdb</a> (1)</li>
            <li><a class="reference" href="/categories/releasestm.html">releasestm</a> (1)</li>
            <li><a class="reference" href="/categories/revdb.html">revdb</a> (1)</li>
            <li><a class="reference" href="/categories/roadmap.html">roadmap</a> (2)</li>
            <li><a class="reference" href="/categories/rpython.html">rpython</a> (1)</li>
            <li><a class="reference" href="/categories/rpyc.html">RPyC</a> (1)</li>
            <li><a class="reference" href="/categories/speed.html">speed</a> (6)</li>
            <li><a class="reference" href="/categories/sponsors.html">sponsors</a> (7)</li>
            <li><a class="reference" href="/categories/sprint.html">sprint</a> (3)</li>
            <li><a class="reference" href="/categories/sprints.html">sprints</a> (1)</li>
            <li><a class="reference" href="/categories/stm.html">stm</a> (14)</li>
            <li><a class="reference" href="/categories/sun.html">sun</a> (1)</li>
            <li><a class="reference" href="/categories/smalltalk.html">Smalltalk</a> (1)</li>
            <li><a class="reference" href="/categories/squeak.html">Squeak</a> (1)</li>
            <li><a class="reference" href="/categories/testing.html">testing</a> (1)</li>
            <li><a class="reference" href="/categories/toy-optimizer.html">toy-optimizer</a> (6)</li>
            <li><a class="reference" href="/categories/unicode.html">unicode</a> (1)</li>
            <li><a class="reference" href="/categories/valgrind.html">valgrind</a> (1)</li>
            <li><a class="reference" href="/categories/vmprof.html">vmprof</a> (3)</li>
            <li><a class="reference" href="/categories/z3.html">z3</a> (5)</li>
          </ul>
        </div></div>
</main>
</div>
<div style="clear: both; width: 75%; margin: 1em auto;">
        <nav class="postindexpager"><ul class="pager">
<li class="previous">
                <a href="index-24.html" rel="prev">Newer posts</a>
            </li>
            <li class="next">
                <a href="index-22.html" rel="next">Older posts</a>
            </li>
        </ul></nav>
</div>
         
                 <footer id="footer"><p>
</p>
<div class="myfooter">
  <div class="logotext">
    © 2026 <a href="mailto:pypy-dev@pypy.org">The PyPy Team</a>
     
    Built with <a href="https://getnikola.com" rel="nofollow">Nikola</a>
     
    Last built 2026-01-17T00:22
  </div>
  <div style="margin-left: auto">
  <a href="../rss.xml">RSS feed</a>
</div>

            
        

    </div>
            <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.1.3/jquery.min.js" crossorigin="anonymous"></script><script src="../assets/js/styles.js"></script></footer>
</body>
</html>