<!DOCTYPE html>
<html \ prefix="
        og: http://ogp.me/ns# article: http://ogp.me/ns/article#
    " vocab="http://ogp.me/ns" lang="en">
<head>
<meta charset="utf-8">
<meta name="description" content="A Faster Python">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>PyPy (old posts, page 39) | PyPy</title>
<link href="../assets/css/rst_base.css" rel="stylesheet" type="text/css">
<link href="../assets/css/nikola_rst.css" rel="stylesheet" type="text/css">
<link href="../assets/css/code.css" rel="stylesheet" type="text/css">
<link href="../assets/css/theme.css" rel="stylesheet" type="text/css">
<link href="../assets/css/styles.css" rel="stylesheet" type="text/css">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="alternate" type="application/rss+xml" title="RSS" hreflang="en" href="../rss.xml">
<link rel="canonical" href="https://www.pypy.org/blog/index-39.html">
<link rel="icon" href="../favicon2.ico" sizes="16x16">
<link rel="icon" href="../favicon32x32.ico" sizes="32x32">
<link rel="prev" href="index-40.html" type="text/html">
<link rel="next" href="index-38.html" type="text/html">
<!--[if lt IE 9]><script src="../assets/js/html5shiv-printshiv.min.js"></script><![endif]--><link href="https://fonts.googleapis.com/css?family=Roboto" rel="stylesheet">
<link rel="stylesheet" type="text/css" href="../assets/css/tipuesearch.css">
</head>
<body>
    <a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>
    <div id="container">
             <header id="header"><!-- Adapted from https://www.taniarascia.com/responsive-dropdown-navigation-bar --><section class="navigation"><div class="nav-container">
            <div class="brand">
                <a href="../index.html">
                    <image id="toplogo" src="../images/pypy-logo.svg" width="75px;" alt="PyPy/"></image></a>
            </div>
            <nav><ul class="nav-list">
<li> 
                <a href="#!">Features</a>
                <ul class="nav-dropdown">
<li> <a href="../features.html">What is PyPy?</a> </li>  
                    <li> <a href="../compat.html">Compatibility</a> </li>  
                    <li> <a href="../performance.html">Performance</a> </li>  
                </ul>
</li>
          <li> <a href="../download.html">Download</a> </li>  
          <li> <a href="http://doc.pypy.org">Dev Docs</a> </li>  
            <li> 
                <a href="#!">Blog</a>
                <ul class="nav-dropdown">
<li> <a href=".">Index</a> </li>  
                    <li> <a href="../categories/">Tags</a> </li>  
                    <li> <a href="../archive.html">Archive by year</a> </li>  
                    <li> <a href="../rss.xml">RSS feed</a> </li>  
                    <li> <a href="https://morepypy.blogspot.com/">Old site</a> </li>  
                </ul>
</li>
            <li> 
                <a href="#!">About</a>
                <ul class="nav-dropdown">
<li> <a href="https://bsky.app/profile/pypyproject.bsky.social">Bluesky</a> </li>  
                    <li> <a href="https://libera.irclog.whitequark.org/pypy">IRC logs</a> </li>  
                    <li> <a href="https://www.youtube.com/playlist?list=PLADqad94yVqDRQXuqxKrPS5QnVqbDLlRt">YouTube</a> </li>  
                    <li> <a href="https://www.twitch.tv/pypyproject">Twitch</a> </li>  
                    <li> <a href="../pypy-sponsors.html">Sponsors</a> </li>  
                    <li> <a href="../howtohelp.html">How To Help?</a> </li>  
                    <li> <a href="../contact.html">Contact</a> </li>  
                </ul>
</li>

                </ul></nav><div class="nav-mobile">
                <a id="nav-toggle" href="#!"> <span></span></a>
            </div>
        </div>
    </section><div class="searchform" role="search">
                
<form class="navbar-form navbar-left" action="../search.html" role="search">
    <div class="form-group">
        <input type="text" class="form-control" id="tipue_search_input" name="q" placeholder="Search…" autocomplete="off">
</div>
    <input type="submit" value="Local Search" style="visibility: hidden;">
</form>

            </div>
    </header><main id="content"><div class="post">
<div class="postindex">
    <article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="../posts/2019/07/pypy-jit-for-aarch64-7161523403247118006.html" class="u-url">PyPy JIT for Aarch64</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                <a href="../authors/maciej-fijalkowski.html">Maciej Fijalkowski</a>
            </span></p>
            <p class="dateline">
            <a href="../posts/2019/07/pypy-jit-for-aarch64-7161523403247118006.html" rel="bookmark">
            <time class="published dt-published" datetime="2019-07-25T14:41:00Z" itemprop="datePublished" title="2019-07-25 14:41">2019-07-25 14:41</time></a>
            </p>
                <p class="commentline">4 comments</p>

        </div>
    </header><div class="p-summary entry-summary">
    <div dir="ltr" style="text-align: left;">

<p>Hello everyone.</p>
<p>We are pleased to announce the availability of the new PyPy for AArch64. This
port brings PyPy's high-performance just-in-time compiler to the AArch64
platform, also known as 64-bit ARM. With the addition of AArch64, PyPy now
supports a total of 6 architectures: x86 (32 &amp; 64bit), ARM (32 &amp; 64bit), PPC64,
and s390x. The AArch64 work was funded by ARM Holdings Ltd. and Crossbar.io.</p>
<p>PyPy has a good record of boosting the performance of Python programs on the
existing platforms. To show how well the new PyPy port performs, we compare the
performance of PyPy against CPython on a set of benchmarks. As a point of
comparison, we include the results of PyPy on x86_64.</p>
<p>Note, however, that the results presented here were measured on a Graviton A1
machine from AWS, which comes with a very serious word of warning: Graviton A1's
are virtual machines, and, as such, they are not suitable for benchmarking. If
someone has access to a beefy enough (16G) ARM64 server and is willing to give
us access to it, we are happy to redo the benchmarks on a real machine. One
major concern is that while a virtual CPU is 1-to-1 with a real CPU, it is not
clear to us how CPU caches are shared across virtual CPUs. Also, note that by no
means is this benchmark suite representative enough to average the results. Read
the numbers individually per benchmark.</p>
<p>The following graph shows the speedups on AArch64 of PyPy (hg id 2417f925ce94) compared to
CPython (2.7.15), as well as the speedups on a x86_64 Linux laptop
comparing the most recent release, PyPy 7.1.1, to CPython 2.7.16.</p>

<div class="separator" style="clear: both; text-align: center;"><a href="https://1.bp.blogspot.com/-zC5JsKK5msM/XTmxQdJawEI/AAAAAAAAJgY/mDR_IbpJOAEImVSkGtVb2V5snEtqZcdnQCLcBGAs/s1600/2019-07-arm64-speedups.png" style="margin-left: 1em; margin-right: 1em;"><img border="0" height="231" src="https://1.bp.blogspot.com/-zC5JsKK5msM/XTmxQdJawEI/AAAAAAAAJgY/mDR_IbpJOAEImVSkGtVb2V5snEtqZcdnQCLcBGAs/s400/2019-07-arm64-speedups.png" width="400"></a></div>

<p>In the majority of benchmarks, the speedups achieved on AArch64 match those
achieved on the x86_64 laptop. Over CPython, PyPy on AArch64 achieves speedups
between 0.6x to 44.9x. These speedups are comparable to x86_64, where the
numbers are between 0.6x and 58.9x.</p>
<p>The next graph compares between the speedups achieved on AArch64 to the speedups
achieved on x86_64, i.e., how great the speedup is on AArch64 vs. the same
benchmark on x86_64. This comparison should give a rough idea about the
quality of the generated code for the new platform.</p>

<div class="separator" style="clear: both; text-align: center;"><a href="https://4.bp.blogspot.com/-29YGxYG1SLU/XTmxbjoz9nI/AAAAAAAAJgc/efNeh3P4guwHtgqKXjyMgfwfUbMFl3eDACLcBGAs/s1600/2019-07-arm64-relative.png" style="margin-left: 1em; margin-right: 1em;"><img border="0" height="133" src="https://4.bp.blogspot.com/-29YGxYG1SLU/XTmxbjoz9nI/AAAAAAAAJgc/efNeh3P4guwHtgqKXjyMgfwfUbMFl3eDACLcBGAs/s400/2019-07-arm64-relative.png" width="400"></a></div>

<p>Note that we see a large variance: There are generally three groups of
benchmarks - those that run at more or less the same speed, those that
run at 2x the speed, and those that run at 0.5x the speed of x86_64.</p>
<p>The variance and disparity are likely related to a variety of issues, mostly due
to differences in architecture. What <em>is</em> however interesting is that, compared
to measurements performed on older ARM boards, the branch predictor on the
Graviton A1 machine appears to have improved. As a result, the speedups achieved
by PyPy over CPython are smaller than on older ARM boards: sufficiently branchy
code, like CPython itself, simply runs a lot faster. Hence, the advantage
of the non-branchy code generated by PyPy's just-in-time compiler is smaller.</p>
<p>One takeaway here is that many possible improvements for PyPy have yet to be
implemented. This is true for both of the above platforms, but probably more so
for AArch64, which comes with a large number of CPU registers. The PyPy backend
was written with x86 (the 32-bit variant) in mind, which has a really low number
of registers. We think that we can improve in the area of emitting more modern
machine code, which may have a higher impact on AArch64 than on x86_64. There is
also a number of missing features in the AArch64 backend. These features are
currently implemented as expensive function calls instead of inlined native
instructions, something we intend to improve.</p>
<p>Best,</p>
<p>Maciej Fijalkowski, Armin Rigo and the PyPy team</p>

<br>
</div>
    </div>
    </article><div class="comment-level comment-level-1">
      <div class="comment comment-1520039492044194092">
        <div class="comment-header">
          <a name="comment-1520039492044194092"></a>
            <span class="author">Unknown</span> wrote on <span class="date">2019-07-25 18:59</span>:
        </div>
        <div class="comment-content">
          <p>Hey - I can provide access to several flavors of beefy bare-metal arm64 hardware as part of the Works on Arm project, for your benchmark efforts.</p>
        </div>
      </div>
      <div class="comment comment-5552774526596018701">
        <div class="comment-header">
          <a name="comment-5552774526596018701"></a>
            <span class="author">Maciej Fijalkowski</span> wrote on <span class="date">2019-07-25 21:22</span>:
        </div>
        <div class="comment-content">
          <p>Awesome! Send me an email - fijall at gmail</p>
        </div>
      </div>
      <div class="comment comment-7352455246142951601">
        <div class="comment-header">
          <a name="comment-7352455246142951601"></a>
            <span class="author">Anonymous</span> wrote on <span class="date">2019-07-29 15:57</span>:
        </div>
        <div class="comment-content">
          <br>Does this work well with pypy3 ?
        </div>
      </div>
      <div class="comment comment-5483209029916866373">
        <div class="comment-header">
          <a name="comment-5483209029916866373"></a>
            <span class="author">Armin Rigo</span> wrote on <span class="date">2019-07-29 20:02</span>:
        </div>
        <div class="comment-content">
          <p>Yes, it works with any RPython-based interpreter (including pypy2 and pypy3).</p>
        </div>
      </div>
         </div>

    <article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="../posts/2019/04/pypy-711-bug-fix-release-6539023630991217367.html" class="u-url">PyPy 7.1.1 Bug Fix Release</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                <a href="../authors/mattip.html">mattip</a>
            </span></p>
            <p class="dateline">
            <a href="../posts/2019/04/pypy-711-bug-fix-release-6539023630991217367.html" rel="bookmark">
            <time class="published dt-published" datetime="2019-04-18T15:24:00Z" itemprop="datePublished" title="2019-04-18 15:24">2019-04-18 15:24</time></a>
            </p>
            
        </div>
    </header><div class="p-summary entry-summary">
    <div dir="ltr" style="text-align: left;">
The PyPy team is proud to release a bug-fix release version 7.1.1 of PyPy, which
includes two different interpreters:<br><ul style="text-align: left;">
<li>PyPy2.7, which is an interpreter supporting the syntax and the features of
Python 2.</li>
<li>PyPy3.6-beta: the second official release of PyPy to support 3.6
features.</li>
</ul>
<blockquote>
<div>
</div>
</blockquote>
The interpreters are based on much the same codebase, thus the double
release.<br><br>
This bugfix fixes bugs related to large lists, dictionaries, and sets, some corner cases with unicode, and <a href="https://www.python.org/dev/peps/pep-3118/">PEP 3118</a> memory views of ctype structures. It also fixes a few issues related to the ARM 32-bit backend. For the complete list see the <a href="https://doc.pypy.org/en/latest/release-v7.1.1.html">changelog.</a><br><br>
You can download the v7.1.1 releases here:<br><blockquote>
<div>
<a class="reference external" href="https://pypy.org/download.html">https://pypy.org/download.html</a>
</div>
</blockquote>
<br>
As always, this release is 100% compatible with the previous one and fixed
several issues and bugs raised by the growing community of PyPy users.
We strongly recommend updating.<br><br>
The PyPy3.6 release is rapidly maturing, but is still considered beta-quality.<br><br>
The PyPy team </div>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="../posts/2019/04/an-rpython-jit-for-lpegs-4779548053359386284.html" class="u-url">An RPython JIT for LPegs</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                <a href="../authors/carl-friedrich-bolz-tereick.html">Carl Friedrich Bolz-Tereick</a>
            </span></p>
            <p class="dateline">
            <a href="../posts/2019/04/an-rpython-jit-for-lpegs-4779548053359386284.html" rel="bookmark">
            <time class="published dt-published" datetime="2019-04-04T21:26:00Z" itemprop="datePublished" title="2019-04-04 21:26">2019-04-04 21:26</time></a>
            </p>
            
        </div>
    </header><div class="p-summary entry-summary">
    <p>The following is a guest post by Stefan Troost, he describes the work he did in his bachelor thesis:</p>

<p>In this project we have used the RPython infrastructure to generate an RPython
JIT for a
less-typical use-case: string pattern matching. The work in this project is
based on <a href="../posts/2019/04/bford.info/pub/lang/peg.pdf">Parsing Expression Grammars</a> and
<a href="../posts/2019/04/www.inf.puc-rio.br/~roberto/docs/peg.pdf">LPeg</a>, an implementation of PEGs
designed to be used in Lua. In this post I will showcase some of the work that
went into this project, explain PEGs in general and LPeg in particular, and
show some benchmarking results.</p>
<h1>
<a id="Parsing_Expression_Grammars_12"></a>Parsing Expression Grammars</h1>
<p>Parsing Expression Grammas (PEGs) are a type of formal grammar similar to
context-free grammars, with the main difference being that they are unambiguous.
This is achieved by redefining the ambiguous choice operator of CFGs (usually
noted as <code>|</code>) as an <em>ordered</em> choice operator. In practice this means that if a
rule in a PEG presents a choice, a PEG parser should prioritize the leftmost
choice. Practical uses include parsing and pattern-searching. In comparison to
regular expressions PEGs stand out as being able to be parsed in linear time,
being strictly more powerful than REs, as well as being arguably more readable.</p>
<h1>
<a id="LPeg_24"></a>LPeg</h1>
<p>LPeg is an implementation of PEGs written in C to be used in the Lua
programming language. A crucial detail of this implementation is that it parses
high level function calls, translating them to bytecode, and interpreting that
bytecode. Therefore, we are able to improve that implementation by replacing
LPegs C-interpreter with an RPython JIT. I use a modified version of LPeg to
parse PEGs and pass the generated Intermediate Representation, the LPeg
bytecode, to my VM.</p>
<h1>
<a id="The_LPeg_Library_35"></a>The LPeg Library</h1>
<p>The LPeg Interpreter executes bytecodes created by parsing a string of commands
using the LPeg library. Our JIT supports a subset of the LPeg library, with
some of the more advanced or obscure features being left out. Note that this
subset is still powerful enough to do things like parse JSON.</p>
<table class="table table-striped table-bordered">
<thead><tr>
<th>Operator</th>
<th>Description</th>
</tr></thead>
<tbody>
<tr>
<td>lpeg.P(string)</td>
<td>Matches string literally</td>
</tr>
<tr>
<td>lpeg.P(n)</td>
<td>Matches exactly n characters</td>
</tr>
<tr>
<td>lpeg.P(-n)</td>
<td>Matches at most n characters</td>
</tr>
<tr>
<td>lpeg.S(string)</td>
<td>Matches any character in string (Set)</td>
</tr>
<tr>
<td>lpeg.R(“xy”)</td>
<td>Matches any character between x and y (Range)</td>
</tr>
<tr>
<td>pattern^n</td>
<td>Matches at least n repetitions of pattern</td>
</tr>
<tr>
<td>pattern^-n</td>
<td>Matches at most n repetitions of pattern</td>
</tr>
<tr>
<td>pattern1 * pattern2</td>
<td>Matches pattern1 followed by pattern2</td>
</tr>
<tr>
<td>pattern1 + pattern2</td>
<td>Matches pattern1 or pattern2 (ordered choice)</td>
</tr>
<tr>
<td>pattern1 - pattern2</td>
<td>Matches pattern1 if pattern2 does not match</td>
</tr>
<tr>
<td>-pattern</td>
<td>Equivalent to ("" - pattern)</td>
</tr>
</tbody>
</table>
<p>As a simple example, the pattern <code>lpeg.P"ab"+lpeg.P"cd"</code> would match either the
string <code>ab</code> or the string <code>cd</code>.</p>
<p>To extract semantic information from a pattern, captures are needed. These are
the following operations supported for capture creation.</p>
<table class="table table-striped table-bordered">
<thead><tr>
<th>Operation</th>
<th>What it produces</th>
</tr></thead>
<tbody>
<tr>
<td>lpeg.C(pattern)</td>
<td>the match for pattern plus all captures made by pattern</td>
</tr>
<tr>
<td>lpeg.Cp()</td>
<td>the current position (matches the empty string)</td>
</tr>
</tbody>
</table>
<p>(tables taken from the <a href="https://www.inf.puc-rio.br/~roberto/lpeg/">LPeg documentation</a>)</p>
<p>These patterns are translated into bytecode by LPeg, at which point we are able
to pass them into our own VM.</p>
<h1>
<a id="The_VM_73"></a>The VM</h1>
<p>The state of the VM at any point is defined by the following variables:</p>
<ul>
<li>
<code>PC</code>: program counter indicating the current instruction</li>
<li>
<code>fail</code>: an indicator that some match failed and the VM must backtrack</li>
<li>
<code>index</code>: counter indicating the current character of the input string</li>
<li>
<code>stackentries</code>: stack of return addresses and choice points</li>
<li>
<code>captures</code>: stack of capture objects</li>
</ul>
<p>The execution of bytecode manipulates the values of these variables in order to
produce some output. How that works and what that output looks like will be
explained now.</p>
<h1>
<a id="The_Bytecode_88"></a>The Bytecode</h1>
<p>For simplicity’s sake I will not go over every individual bytecode, but instead
choose some that exemplify the core concepts of the bytecode set.</p>
<h2>
<a id="generic_character_matching_bytecodes_93"></a>generic character matching bytecodes</h2>
<ul>
<li>
<p><code>any</code>: Checks if there’s any characters left in the inputstring. If it succeeds
it advances the index and PC by 1, if not the bytecode fails.</p>
</li>
<li>
<p><code>char c</code>: Checks if there is another bytecode in the input and if that
character is equal to <code>c</code>. Otherwise the bytecode fails.</p>
</li>
<li>
<p><code>set c1-c2</code>: Checks if there is another bytecode in the input and if that
character is between (including) c1 and c2. Otherwise the bytecode fails.</p>
</li>
</ul>
<p>These bytecodes are the easiest to understand with very little impact on the
VM. What it means for a bytecode to fail will be explained when
we get to control flow bytecodes.</p>
<p>To get back to the example, the first half of the pattern <code>lpeg.P"ab"</code> could be
compiled to the following bytecodes:</p>
<pre><code>char a
char b
</code></pre>
<h2>
<a id="control_flow_bytecodes_117"></a>control flow bytecodes</h2>
<ul>
<li>
<p><code>jmp n</code>: Sets <code>PC</code> to <code>n</code>, effectively jumping to the n’th bytecode. Has no defined
failure case.</p>
</li>
<li>
<p><code>testchar c n</code>: This is a lookahead bytecode. If the current character is equal
to <code>c</code> it advances the <code>PC</code> but not the index. Otherwise it jumps to <code>n</code>.</p>
</li>
<li>
<p><code>call n</code>: Puts a return address (the current <code>PC + 1</code>) on the <code>stackentries</code> stack
and sets the <code>PC</code> to <code>n</code>. Has no defined failure case.</p>
</li>
<li>
<p><code>ret</code>: Opposite of <code>call</code>. Removes the top value of the <code>stackentries</code> stack (if
the string of bytecodes is valid this will always be a return address) and
sets the <code>PC</code> to the removed value. Has no defined failure case.</p>
</li>
<li>
<p><code>choice n</code>: Puts a choice point on the <code>stackentries</code> stack. Has no defined
failure case.</p>
</li>
<li>
<p><code>commit n</code>: Removes the top value of the <code>stackentries</code> stack (if the string of
bytecodes is valid this will always be a choice point) and jumps to <code>n</code>. Has no
defined failure case.</p>
</li>
</ul>
<p>Using <code>testchar</code> we can implement the full pattern <code>lpeg.P"ab"+lpeg.P"cd"</code> with
bytecode as follows:</p>
<pre><code>testchar a -&gt; L1
any
char b
end
any
L1: char c
char d
end
</code></pre>
<p>The <code>any</code> bytecode is needed because <code>testchar</code> does not consume a character
from the input.</p>
<h2>
<a id="Failure_Handling_Backtracking_and_Choice_Points_158"></a>Failure Handling, Backtracking and Choice Points</h2>
<p>A choice point consist of the VM’s current <code>index</code> and <code>capturestack</code> as well as a
<code>PC</code>. This is not the VM’s <code>PC</code> at the time of creating the
choicepoint, but rather the <code>PC</code> where we should continue trying to find
matches when a failure occurs later.</p>
<p>Now that we have talked about choice points, we can talk about how the VM
behaves in the fail state. If the VM is in the fail state, it removed entries
from the stackentries stack until it finds a choice point. Then it backtracks
by restoring the VM to the state defined by the choice point. If no choice
point is found this way, no match was found in the string and the VM halts.</p>
<p>Using choice points we could implement the example <code>lpeg.P"ab" + lpeg.P"cd"</code> in
bytecodes in a different way (LPEG uses the simpler way shown above, but for
more complex patterns it can’t use the lookahead solution using <code>testchar</code>):</p>
<pre><code>choice L1
char a
char b
commit
end
L1: char c
char d
end
</code></pre>
<h2>
<a id="Captures_188"></a>Captures</h2>
<p>Some patterns require the VM to produce more output than just “the pattern
matched” or “the pattern did not match”. Imagine searching a document for an
IPv4 address and all your program responded was “I found one”. In order to
recieve additional information about our inputstring, captures are used.</p>
<h3>
<a id="The_capture_object_195"></a>The capture object</h3>
<p>In my VM, two types of capture objects are supported, one of them being the
position capture. It consists of a single index referencing the point in the
inputstring where the object was created.</p>
<p>The other type of capture object is called simplecapture. It consists of an
index and a size value, which are used to reference a substring of the
inputstring. In addition, simplecaptures have a variable status indicating they
are either open or full. If a simplecapture object is open, that means that its
size is not yet determined, since the pattern we are capturing is of variable
length.</p>
<p>Capture objects are created using the following bytecodes:</p>
<ul>
<li>
<p><code>Fullcapture Position</code>: Pushes a positioncapture object with the current index
value to the capture stack.</p>
</li>
<li>
<p><code>Fullcapture Simple n</code>: Pushes a simplecapture object with current index value
and size=n to the capture stack.</p>
</li>
<li>
<p><code>Opencapture Simple</code>: Pushes an open simplecapture object with current index
value and undetermined size to the capture stack.</p>
</li>
<li>
<p><code>closecapture</code>: Sets the top element of the capturestack to full and sets its
size value using the difference between the current index and the index of
the capture object.</p>
</li>
</ul>
<h1>
<a id="The_RPython_Implementation_224"></a>The RPython Implementation</h1>
<p>These, and many more bytecodes were implemented in an RPython-interpreter.
By adding jit hints, we were able to generate an efficient JIT.
We will now take a closer look at some implementations of bytecodes.</p>
<pre><code class="language-python">...
        <span class="hljs-keyword">elif</span> instruction.name == <span class="hljs-string">"any"</span>:
            <span class="hljs-keyword">if</span> index &gt;= len(inputstring):
                fail = <span class="hljs-keyword">True</span>
            <span class="hljs-keyword">else</span>:
                pc += <span class="hljs-number">1</span>
                index += <span class="hljs-number">1</span>

...
</code></pre>
<p>The code for the <code>any</code>-bytecode is relatively straight-forward. It either
advances the <code>pc</code> and <code>index</code> or sets the VM into the fail state,
depending on whether the end of the inputstring has been reached or not.</p>
<pre><code class="language-python">...
        <span class="hljs-keyword">if</span> instruction.name == <span class="hljs-string">"char"</span>:
            <span class="hljs-keyword">if</span> index &gt;= len(inputstring):
                fail = <span class="hljs-keyword">True</span>
            <span class="hljs-keyword">elif</span> instruction.character == inputstring[index]:
                pc += <span class="hljs-number">1</span>
                index += <span class="hljs-number">1</span>
            <span class="hljs-keyword">else</span>:
                fail = <span class="hljs-keyword">True</span>
...
</code></pre>
<p>The <code>char</code>-bytecode also looks as one would expect. If the VM’s string index is
out of range or the character comparison fails, the VM is put into the
fail state, otherwise the <code>pc</code> and <code>index</code> are advanced by 1. As you can see, the
character we’re comparing the current inputstring to is stored in the
instruction object (note that this code-example has been simplified for
clarity, since the actual implementation includes a jit-optimization that
allows the VM to execute multiple successive char-bytecodes at once).</p>
<pre><code class="language-python">...
        <span class="hljs-keyword">elif</span> instruction.name == <span class="hljs-string">"jmp"</span>:
            pc = instruction.goto
...
</code></pre>
<p>The <code>jmp</code>-bytecode comes with a <code>goto</code> value which is a <code>pc</code> that we want
execution to continue at.</p>
<pre><code class="language-python">...
        <span class="hljs-keyword">elif</span> instruction.name == <span class="hljs-string">"choice"</span>:
            pc += <span class="hljs-number">1</span>
            choice_points = choice_points.push_choice_point(
                instruction.goto, index, captures)
...
</code></pre>
<p>As we can see here, the <code>choice</code>-bytecode puts a choice point onto the stack that
may be backtracked to if the VM is in the fail-state. This choice point
consists of a pc to jump to which is determined by the bytecode.
But it also includes the current <code>index</code> and <code>captures</code> values at the time the choice
point was created. An ongoing topic of jit optimization is which data structure
is best suited to store choice points and return addresses. Besides naive
implementations of stacks and single-linked lists, more case-specific
structures are also being tested for performance.</p>
<h1>
<a id="Benchmarking_Result_299"></a>Benchmarking Result</h1>
<p>In order to find out how much it helps to JIT LPeg patterns we ran a small
number of benchmarks. We used an otherwise idle Intel Core i5-2430M CPU with
3072 KiB of cache and 8 GiB of RAM, running with 2.40GHz. The machine was
running Ubuntu 14.04 LTS, Lua 5.2.3 and we used GNU grep 2.16 as a point of
comparison for one of the benchmarks. The benchmarks were run 100 times in
a new process each. We measured the full runtime of the called process,
including starting the process.</p>
<p>Now we will take a look at some plots generated by measuring the runtime of
different iterations of my JIT compared to lua and using bootstrapping to
generate a sampling distribution of mean values. The plots contain a few different
variants of pypeg, only the one called "fullops" is important for this blog post, however.</p>

<div class="separator" style="clear: both; text-align: center;"><a href="https://1.bp.blogspot.com/-Qv3aZapdMOk/XKXMDhTGujI/AAAAAAAAsNo/b7QShypeeV8mvePwTjPgmDSzUVB6EsiaACLcBGAs/s1600/rawplot_100_kb_urlinput.png" style="margin-left: 1em; margin-right: 1em;"><img border="0" height="300" src="https://1.bp.blogspot.com/-Qv3aZapdMOk/XKXMDhTGujI/AAAAAAAAsNo/b7QShypeeV8mvePwTjPgmDSzUVB6EsiaACLcBGAs/s400/rawplot_100_kb_urlinput.png" width="400"></a></div>

<p>This is the plot for a search pattern that searches a text file for valid URLs.
As we can see, if the input file is as small as 100 kb, the benefits of JIT
optimizations do not outweigh the time required to generate the
machine code. As a result, all of our attempts perform significantly slower
than LPeg.</p>

<div class="separator" style="clear: both; text-align: center;"><a href="https://2.bp.blogspot.com/-mTry3w1vSFA/XKXMNoaeHOI/AAAAAAAAsNs/YhdGWoGmyjU3yxqFgcePBklGv-qw13wXgCLcBGAs/s1600/rawplot_500_kb_urlinput.png" style="margin-left: 1em; margin-right: 1em;"><img border="0" height="300" src="https://2.bp.blogspot.com/-mTry3w1vSFA/XKXMNoaeHOI/AAAAAAAAsNs/YhdGWoGmyjU3yxqFgcePBklGv-qw13wXgCLcBGAs/s400/rawplot_500_kb_urlinput.png" width="400"></a></div>

<p>This is the plot for the same search pattern on a larger input file. As we can
see, for input files as small as 500 kb our VM already outperforms LPeg’s. An
ongoing goal of continued development is to get this lower boundary as small as
possible.</p>

<div class="separator" style="clear: both; text-align: center;"><a href="https://2.bp.blogspot.com/-Cr4BE9Cejg8/XKXMUXamP3I/AAAAAAAAsN0/t5PTo0Q4vPMLwL12bdQ93Q4bAMIjJTEVACLcBGAs/s1600/rawplot_5_mb_urlinput.png" style="margin-left: 1em; margin-right: 1em;"><img border="0" height="300" src="https://2.bp.blogspot.com/-Cr4BE9Cejg8/XKXMUXamP3I/AAAAAAAAsN0/t5PTo0Q4vPMLwL12bdQ93Q4bAMIjJTEVACLcBGAs/s400/rawplot_5_mb_urlinput.png" width="400"></a></div>

<p>The benefits of a JIT compared to an Interpreter become more and more relevant
for larger input files. Searching a file as large as 5 MB makes this fairly
obvious and is exactly the behavior we expect.</p>

<div class="separator" style="clear: both; text-align: center;"><a href="https://2.bp.blogspot.com/-uIoguDb7ApE/XKXMngYEnSI/AAAAAAAAsOA/zdv2WAfdRwwruS1yOdX7jFz0nB_PPQqRACLcBGAs/s1600/rawplot_50_kb_jsoninput.png" style="margin-left: 1em; margin-right: 1em;"><img border="0" height="300" src="https://2.bp.blogspot.com/-uIoguDb7ApE/XKXMngYEnSI/AAAAAAAAsOA/zdv2WAfdRwwruS1yOdX7jFz0nB_PPQqRACLcBGAs/s400/rawplot_50_kb_jsoninput.png" width="400"></a></div>

<p>This time we are looking at a different more complicated pattern, one that parses JSON used on a
50 kb input file. As expected, LPeg outperforms us, however, something
unexpected happens as we increase the filesize.</p>

<div class="separator" style="clear: both; text-align: center;"><a href="https://3.bp.blogspot.com/-r1-Aq39Oe9I/XKXMuQlcB6I/AAAAAAAAsOE/Eqmj7i3JKz0zdTK6Cd1ai11aZCf-EZkVwCLcBGAs/s1600/rawplot_100_kb_jsoninput.png" style="margin-left: 1em; margin-right: 1em;"><img border="0" height="300" src="https://3.bp.blogspot.com/-r1-Aq39Oe9I/XKXMuQlcB6I/AAAAAAAAsOE/Eqmj7i3JKz0zdTK6Cd1ai11aZCf-EZkVwCLcBGAs/s400/rawplot_100_kb_jsoninput.png" width="400"></a></div>

<p>Since LPeg has a defined maximum depth of 400 for the choicepoints and
returnaddresses Stack, LPeg by default refuses to parse files as small as
100kb. This raises the question if LPeg was intended to be used for parsing.
Until a way to increase LPeg’s maximum stack depth is found, no comparisons to
LPeg can be performed at this scale. This has been a low priority in the past
but may be addressed in the future.</p>
<p>To conclude, we see that at sufficiently high filesizes, our JIT outperforms
the native LPeg-interpreter. This lower boundary is currently as low as 100kb
in filesize.</p>
<h1>
<a id="Conclusion_353"></a>Conclusion</h1>
<p>Writing a JIT for PEG’s has proven itself to be a challenge worth pursuing, as
the expected benefits of a JIT compared to an Interpreter have been achieved.
Future goals include getting LPeg to be able to use parsing patterns on larger
files, further increasing the performance of our JIT and comparing it to other
well-known programs serving a similar purpose, like grep.</p>
<p>The prototype implementation that I described in this post can be found
<a href="https://github.com/sktroost/PyPeg/tree/master/pypeg">on Github</a>
(it's a bit of a hack in some places, though).</p>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="../posts/2019/03/pypy-v71-released-now-uses-utf-8-451324088028792912.html" class="u-url">PyPy v7.1 released; now uses utf-8 internally for unicode strings</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                <a href="../authors/mattip.html">mattip</a>
            </span></p>
            <p class="dateline">
            <a href="../posts/2019/03/pypy-v71-released-now-uses-utf-8-451324088028792912.html" rel="bookmark">
            <time class="published dt-published" datetime="2019-03-24T19:14:00Z" itemprop="datePublished" title="2019-03-24 19:14">2019-03-24 19:14</time></a>
            </p>
                <p class="commentline">9 comments</p>

        </div>
    </header><div class="p-summary entry-summary">
    <div dir="ltr" style="text-align: left;">
The PyPy team is proud to release version 7.1.0 of PyPy, which includes
two different interpreters:<br><blockquote>
<div>
<ul class="simple">
<li>PyPy2.7, which is an interpreter supporting the syntax and the features of
Python 2.7</li>
<li>PyPy3.6-beta: this is the second official release of PyPy to support 3.6
features, although it is still considered beta quality.</li>
</ul>
</div>
</blockquote>
The interpreters are based on much the same codebase, thus the double
release.<br><br>
This release, coming fast on the heels of 7.0 in February, finally merges the
internal refactoring of unicode representation as UTF-8. Removing the
conversions from strings to unicode internally lead to a nice speed bump. We merged the utf-8 changes to the py3.5 branch (Python3.5.3) but will concentrate on 3.6 going forward.<br><br>
We also improved the ability to use the buffer protocol with ctype structures
and arrays.<br><br>
The <a class="reference external" href="https://cffi.readthedocs.io/">CFFI</a> backend has been updated to version 1.12.2. We recommend using CFFI
rather than c-extensions to interact with C, and <a class="reference external" href="https://cppyy.readthedocs.io/">cppyy</a> for interacting with
C++ code.<br>
 You can download the v7.1 releases here:<br><blockquote>
<div>
<a class="reference external" href="https://pypy.org/download.html">https://pypy.org/download.html</a>
</div>
</blockquote>
We would like to thank our donors for the continued support of the PyPy
project. If PyPy is not quite good enough for your needs, we are available for
direct consulting work.<br><br>
We would also like to thank our contributors and encourage new people to join
the project. PyPy has many layers and we need help with all of them: <a class="reference external" href="https://doc.pypy.org/en/latest/index.html">PyPy</a>
and <a class="reference external" href="https://rpython.readthedocs.org/">RPython</a> documentation improvements, tweaking popular modules to run
on pypy, or general <a class="reference external" href="https://doc.pypy.org/en/latest/project-ideas.html">help</a> with making RPython’s JIT even better.<br><div class="section" id="what-is-pypy">
<h2 style="text-align: center;">
<span style="font-size: x-large;">What is PyPy?</span>
</h2>
PyPy is a very compliant Python interpreter, almost a drop-in replacement for
CPython 2.7, 3.6. It’s fast (<a class="reference external" href="https://speed.pypy.org/">PyPy and CPython 2.7.x</a> performance
comparison) due to its integrated tracing JIT compiler.<br><br>
We also welcome developers of other <a class="reference external" href="https://rpython.readthedocs.io/en/latest/examples.html">dynamic languages</a> to see what RPython
can do for them.<br>

This PyPy release supports:<br><strong> </strong>
</div>
<div class="section" id="what-is-pypy">
<ul class="simple">
<li>
<strong>x86</strong> machines on most common operating systems
(Linux 32/64 bits, Mac OS X 64 bits, Windows 32 bits, OpenBSD, FreeBSD)</li>
<li>big- and little-endian variants of <strong>PPC64</strong> running Linux</li>
<li> <b>ARM32 </b>although we do not supply downloadable binaries at this time</li>
<li>
<strong>s390x</strong> running Linux</li>
</ul>
<div class="section" id="changelog">
<h2 style="text-align: center;">
<span style="font-size: x-large;">What else is new?</span>
</h2>
PyPy 7.0 was released in February, 2019.
There are many incremental improvements to RPython and PyPy, for more information see the <a class="reference external" href="https://doc.pypy.org/en/latest/release-v7.1.0.html#changelog">changelog</a>.<br><br>
Please update, and continue to help us make PyPy better.<br><br><br>
Cheers, The PyPy team
</div>
<br>
</div>
</div>
    </div>
    </article><div class="comment-level comment-level-1">
      <div class="comment comment-2892465627547709055">
        <div class="comment-header">
          <a name="comment-2892465627547709055"></a>
            <span class="author">Anonymous</span> wrote on <span class="date">2019-03-28 09:52</span>:
        </div>
        <div class="comment-content">
          <p>Hi,<br><br>I get this error when trying to run my app with the new PyPy release (pypy 2.7 syntax on Windows):<br><br>'C:\pypy2\lib_pypy\_sqlite3_cffi.pypy-41.pyd': The specified module could not be found<br><br><br>The file specified in the error message (\lib_pypy\_sqlite3_cffi.pypy-41.pyd) is in the folder so whatever is missing is not quite so obvious.</p>
        </div>
      </div>
      <div class="comment comment-1009946760597900994">
        <div class="comment-header">
          <a name="comment-1009946760597900994"></a>
            <span class="author">Noah F. San Tsorvutz</span> wrote on <span class="date">2019-03-29 14:27</span>:
        </div>
        <div class="comment-content">
          <p>One question about using utf8 text encoding, internally. <br><br>Is text handling code much different now, in PyPy, vs. cPython?<br><br>If handling characters ( code points ) within the ASCII range <br>is more like Python v.2.x, that would be very good news to <br>at least one old fart who is having trouble even treating <br>print as a function ...<br><br>Thanks!<br></p>
        </div>
      </div>
      <div class="comment comment-2992256973717075345">
        <div class="comment-header">
          <a name="comment-2992256973717075345"></a>
            <span class="author">Armin Rigo</span> wrote on <span class="date">2019-03-31 08:00</span>:
        </div>
        <div class="comment-content">
          <p>@Noah The answer is complicated because CPython changed its internals more than once.  The current CPython 3.x stores unicode strings as an array of same-sized characters; if your string contains even one character over 0xffff then it's an array of 4 bytes for all the characters.  Sometimes CPython *also* caches the UTF8 string, but doesn't use it much.  The new PyPy is very different: it uses the UTF8 string *only*, and it works for both PyPy 2.7 or 3.x.</p>
        </div>
      </div>
      <div class="comment comment-71276575228454634">
        <div class="comment-header">
          <a name="comment-71276575228454634"></a>
            <span class="author">Armin Rigo</span> wrote on <span class="date">2019-03-31 08:04</span>:
        </div>
        <div class="comment-content">
          <p>@Anonymous It works for me.  Please open a bug report on https://bugs.pypy.org and give more details...</p>
        </div>
      </div>
      <div class="comment comment-1757100720789328317">
        <div class="comment-header">
          <a name="comment-1757100720789328317"></a>
            <span class="author">Anonymous</span> wrote on <span class="date">2019-03-31 12:09</span>:
        </div>
        <div class="comment-content">
          <p>Hi Armin,<br><br>I can't log in to bugs.pypy.org but the problem is very easy to replicate, you only need to test this and it fails (v6.0.0 works fine but both v7.0.0 and 7.1.0 fail):<br><br>try:<br>    import sqlite3<br>except Exception as e:<br>    print str(e)<br><br>The error is:<br>'C:\pypy27v710\lib_pypy\_sqlite3_cffi.pypy-41.pyd': The specified module could not be found<br><br>I've tested it on two different Win10 PCs (32bit PyPy on 64bit Win10) and both exhibit the same behaviour.<br></p>
        </div>
      </div>
      <div class="comment comment-9186629026282543935">
        <div class="comment-header">
          <a name="comment-9186629026282543935"></a>
            <span class="author">Armin Rigo</span> wrote on <span class="date">2019-03-31 16:29</span>:
        </div>
        <div class="comment-content">
          <p>It is not so easy, because it works fine for me (win10 too). Please file a regular bug report. If you can't then we have another problem to solve first...</p>
        </div>
      </div>
      <div class="comment comment-1438451039904895078">
        <div class="comment-header">
          <a name="comment-1438451039904895078"></a>
            <span class="author">Anonymous</span> wrote on <span class="date">2019-03-31 18:06</span>:
        </div>
        <div class="comment-content">
          <p>Hi Armin,<br><br>I've got the answer: With PyPy version &gt;= 7.0.0 you have to add PyPy's root folder to PATH in Environment Variables, that wasn't required with versions &lt;= 6.0.0</p>
        </div>
      </div>
      <div class="comment comment-3304130718023464526">
        <div class="comment-header">
          <a name="comment-3304130718023464526"></a>
            <span class="author">Armin Rigo</span> wrote on <span class="date">2019-04-01 08:15</span>:
        </div>
        <div class="comment-content">
          <p>https://foss.heptapod.net/pypy/pypy/-/issues/2988/windows-cant-find-_sqlite3_cffipypy-41pyd</p>
        </div>
      </div>
      <div class="comment comment-4421260900536150875">
        <div class="comment-header">
          <a name="comment-4421260900536150875"></a>
            <span class="author">Anonymous</span> wrote on <span class="date">2019-04-02 19:10</span>:
        </div>
        <div class="comment-content">
          <p>Hi Armin,<br><br>Moving the dlls to lib_pypy is a nice easy workaround, thank you.<br><br>And thanks to everybody in the PyPy team for their excellent work.</p>
        </div>
      </div>
         </div>

    <article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="../posts/2019/02/pypy-v700-triple-release-of-27-35-and-606875333356156076.html" class="u-url">PyPy v7.0.0: triple release of 2.7, 3.5 and 3.6-alpha</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                <a href="../authors/antonio-cuni.html">Antonio Cuni</a>
            </span></p>
            <p class="dateline">
            <a href="../posts/2019/02/pypy-v700-triple-release-of-27-35-and-606875333356156076.html" rel="bookmark">
            <time class="published dt-published" datetime="2019-02-11T10:55:00Z" itemprop="datePublished" title="2019-02-11 10:55">2019-02-11 10:55</time></a>
            </p>
                <p class="commentline">4 comments</p>

        </div>
    </header><div class="p-summary entry-summary">
    <br><div class="document" id="pypy-v7-0-0-triple-release-of-2-7-3-5-and-3-6-alpha">
The PyPy team is proud to release the version 7.0.0 of PyPy, which includes
three different interpreters:<br><blockquote>
<ul class="simple">
<li>PyPy2.7, which is an interpreter supporting the syntax and the features of
Python 2.7</li>
<li>PyPy3.5, which supports Python 3.5</li>
<li>PyPy3.6-alpha: this is the first official release of PyPy to support 3.6
features, although it is still considered alpha quality.</li>
</ul>
</blockquote>
All the interpreters are based on much the same codebase, thus the triple
release.<br>
Until we can work with downstream providers to distribute builds with PyPy, we
have made packages for some common packages <a class="reference external" href="https://github.com/antocuni/pypy-wheels">available as wheels</a>.<br>
The <a class="reference external" href="https://doc.pypy.org/en/latest/gc_info.html#semi-manual-gc-management">GC hooks</a> , which can be used to gain more insights into its
performance, has been improved and it is now possible to manually manage the
GC by using a combination of <tt class="docutils literal">gc.disable</tt> and <tt class="docutils literal">gc.collect_step</tt>. See the
<a class="reference external" href="../posts/2019/01/pypy-for-low-latency-systems-613165393301401965.html">GC blog post</a>.<br>
We updated the <a class="reference external" href="https://cffi.readthedocs.io/">cffi</a> module included in PyPy to version 1.12, and the
<a class="reference external" href="https://cppyy.readthedocs.io/">cppyy</a> backend to 1.4. Please use these to wrap your C and C++ code,
respectively, for a JIT friendly experience.<br>
As always, this release is 100% compatible with the previous one and fixed
several issues and bugs raised by the growing community of PyPy users.
We strongly recommend updating.<br>
The PyPy3.6 release and the Windows PyPy3.5 release are still not production
quality so your mileage may vary. There are open issues with incomplete
compatibility and c-extension support.<br>
The utf8 branch that changes internal representation of unicode to utf8 did not
make it into the release, so there is still more goodness coming.
You can download the v7.0 releases here:<br><blockquote>
<a class="reference external" href="https://pypy.org/download.html">https://pypy.org/download.html</a>
</blockquote>
We would like to thank our donors for the continued support of the PyPy
project. If PyPy is not quite good enough for your needs, we are available for
direct consulting work.<br>
We would also like to thank our contributors and encourage new people to join
the project. PyPy has many layers and we need help with all of them: <a class="reference external" href="https://www.blogger.com/index.html">PyPy</a>
and <a class="reference external" href="https://rpython.readthedocs.org/">RPython</a> documentation improvements, tweaking popular modules to run
on pypy, or general <a class="reference external" href="https://www.blogger.com/project-ideas.html">help</a> with making RPython's JIT even better.<br><div class="section" id="what-is-pypy">
<h1>
What is PyPy?</h1>
PyPy is a very compliant Python interpreter, almost a drop-in replacement for
CPython 2.7, 3.5 and 3.6. It's fast (<a class="reference external" href="https://speed.pypy.org/">PyPy and CPython 2.7.x</a> performance
comparison) due to its integrated tracing JIT compiler.<br>
We also welcome developers of other <a class="reference external" href="https://rpython.readthedocs.io/en/latest/examples.html">dynamic languages</a> to see what RPython
can do for them.<br>
The PyPy release supports:<br><blockquote>
<ul class="simple">
<li>
<strong>x86</strong> machines on most common operating systems
(Linux 32/64 bits, Mac OS X 64 bits, Windows 32 bits, OpenBSD, FreeBSD)</li>
<li>big- and little-endian variants of <strong>PPC64</strong> running Linux,</li>
<li>
<strong>s390x</strong> running Linux</li>
</ul>
</blockquote>
Unfortunately at the moment of writing our ARM buildbots are out of service,
so for now we are <strong>not</strong> releasing any binary for the ARM architecture.</div>
<div class="section" id="changelog">
<h1>
What else is new?</h1>
PyPy 6.0 was released in April, 2018.
There are many incremental improvements to RPython and PyPy, the complete listing is <a class="reference external" href="https://doc.pypy.org/en/latest/release-v7.0.0.html">here</a>.<br><br>
Please update, and continue to help us make PyPy better.<br><br><br>
Cheers, The PyPy team
</div>
</div>
    </div>
    </article><div class="comment-level comment-level-1">
      <div class="comment comment-2441192182262727610">
        <div class="comment-header">
          <a name="comment-2441192182262727610"></a>
            <span class="author">Anonymous</span> wrote on <span class="date">2019-02-11 20:18</span>:
        </div>
        <div class="comment-content">
          <br>I would be very happy, if at some point request-html would work. Thank you for your great work.<br><br><br>cheers<br>Rob
        </div>
      </div>
      <div class="comment comment-6167289590300589613">
        <div class="comment-header">
          <a name="comment-6167289590300589613"></a>
            <span class="author">Carl Friedrich Bolz-Tereick</span> wrote on <span class="date">2019-02-11 22:06</span>:
        </div>
        <div class="comment-content">
          <p>@Rob can you please file an issue with how we can reproduce the problem?</p>
        </div>
      </div>
      <div class="comment comment-1515310572290536744">
        <div class="comment-header">
          <a name="comment-1515310572290536744"></a>
            <span class="author">Anonymous</span> wrote on <span class="date">2019-02-15 13:54</span>:
        </div>
        <div class="comment-content">
          <p>requests-html seems to work with pypy 3.6 -v7.0, but the normal requests not.<br><br><br>This Code works with cpython <br><br>from requests_html import HTMLSession<br>import requests<br><br>def get_url():<br>    session = HTMLSession()<br>    #r = session.get('https://www.kernel.org/', verify='kernel.org.crt')<br>    r = session.get('https://www.kernel.org/')<br>    url = r.html.xpath('//*[@id="latest_link"]/a/@href')<br>    return url[0]<br><br>def download():<br>    with open('last_stable_kernel.txt', 'rt') as last_kernel:<br>        last_kernel = last_kernel.read() <br>    url = get_url()<br>    if url != last_kernel:<br>        print('New kernel found !!!\n')<br>        print('Downloading from this url: \n' + url )<br>        res = requests.get(url, stream = True)<br>        if res.status_code == requests.codes.ok: # Check the download<br>            print('Download complete\n')<br>        print('Writing file to disk.')<br>        kernel = open('latest_kernel.tar.xz', 'wb')<br>        for file in res.iter_content(1024):<br>            kernel.write(file)<br>        kernel.close()<br>        with open('last_stable_kernel.txt','wt') as last_kernel:<br>            last_kernel.write(url)<br>        return True<br><br>    else:<br>        print('I have allready the newest kernel !')<br>        return False<br><br>if __name__ == "__main__":<br>    download()</p>
        </div>
      </div>
      <div class="comment comment-2436216832378604917">
        <div class="comment-header">
          <a name="comment-2436216832378604917"></a>
            <span class="author">Anonymous</span> wrote on <span class="date">2019-02-15 14:01</span>:
        </div>
        <div class="comment-content">
          <p>The pybench2.0 looks good. (except string mapping)<br><br><br>Test                             minimum  average  operation  overhead<br>-------------------------------------------------------------------------------<br>          BuiltinFunctionCalls:      0ms      5ms    0.01us    0.005ms<br>           BuiltinMethodLookup:      0ms      1ms    0.00us    0.006ms<br>                 CompareFloats:      0ms      1ms    0.00us    0.005ms<br>         CompareFloatsIntegers:      0ms      1ms    0.00us    0.003ms<br>               CompareIntegers:      0ms      1ms    0.00us    0.007ms<br>        CompareInternedStrings:      0ms      1ms    0.00us    0.023ms<br>                  CompareLongs:      0ms      1ms    0.00us    0.004ms<br>                CompareStrings:      0ms      0ms    0.00us    0.016ms<br>    ComplexPythonFunctionCalls:     12ms     14ms    0.07us    0.007ms<br>                 ConcatStrings:      0ms      1ms    0.00us    0.017ms<br>               CreateInstances:      8ms     12ms    0.11us    0.013ms<br>            CreateNewInstances:      8ms     13ms    0.16us    0.012ms<br>       CreateStringsWithConcat:      0ms      1ms    0.00us    0.014ms<br>                  DictCreation:     11ms     13ms    0.03us    0.005ms<br>             DictWithFloatKeys:     48ms     50ms    0.06us    0.010ms<br>           DictWithIntegerKeys:     10ms     11ms    0.01us    0.016ms<br>            DictWithStringKeys:     11ms     13ms    0.01us    0.016ms<br>                      ForLoops:      3ms      7ms    0.28us    0.003ms<br>                    IfThenElse:      0ms      1ms    0.00us    0.012ms<br>                   ListSlicing:     22ms     24ms    1.69us    0.004ms<br>                NestedForLoops:      9ms     10ms    0.01us    0.002ms<br>      NestedListComprehensions:      8ms     11ms    0.92us    0.002ms<br>          NormalClassAttribute:      5ms      6ms    0.01us    0.011ms<br>       NormalInstanceAttribute:      4ms      5ms    0.00us    0.022ms<br>           PythonFunctionCalls:      0ms      2ms    0.01us    0.007ms<br>             PythonMethodCalls:     59ms     66ms    0.29us    0.012ms<br>                     Recursion:      6ms      7ms    0.15us    0.009ms<br>                  SecondImport:     65ms     74ms    0.74us    0.003ms<br>           SecondPackageImport:     67ms     70ms    0.70us    0.003ms<br>         SecondSubmoduleImport:     89ms     92ms    0.92us    0.004ms<br>       SimpleComplexArithmetic:      0ms      1ms    0.00us    0.007ms<br>        SimpleDictManipulation:     12ms     16ms    0.01us    0.008ms<br>         SimpleFloatArithmetic:      0ms      1ms    0.00us    0.010ms<br>      SimpleIntFloatArithmetic:      0ms      1ms    0.00us    0.010ms<br>       SimpleIntegerArithmetic:      0ms      1ms    0.00us    0.010ms<br>      SimpleListComprehensions:      6ms      9ms    0.72us    0.003ms<br>        SimpleListManipulation:      3ms      5ms    0.00us    0.011ms<br>          SimpleLongArithmetic:      0ms      1ms    0.00us    0.007ms<br>                    SmallLists:      3ms      4ms    0.01us    0.007ms<br>                   SmallTuples:      0ms      1ms    0.00us    0.007ms<br>         SpecialClassAttribute:      5ms      6ms    0.01us    0.011ms<br>      SpecialInstanceAttribute:      4ms      5ms    0.00us    0.022ms<br>                StringMappings:    838ms    846ms    3.36us    0.017ms<br>              StringPredicates:      5ms      6ms    0.01us    0.144ms<br>                 StringSlicing:      0ms      1ms    0.00us    0.019ms<br>                     TryExcept:      0ms      0ms    0.00us    0.012ms<br>                    TryFinally:      0ms      2ms    0.01us    0.007ms<br>                TryRaiseExcept:      0ms      1ms    0.01us    0.009ms<br>                  TupleSlicing:     36ms     38ms    0.15us    0.003ms<br>                   WithFinally:      0ms      2ms    0.01us    0.007ms<br>               WithRaiseExcept:      0ms      1ms    0.02us    0.013ms<br>-------------------------------------------------------------------------------<br>Totals:                           1359ms   1461ms<br><br><br><br>Best regards <br>Rob</p>
        </div>
      </div>
         </div>

    <article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="../posts/2019/02/dusseldorf-sprint-report-2019-6107623654916313905.html" class="u-url">Düsseldorf Sprint Report 2019</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                <a href="../authors/carl-friedrich-bolz-tereick.html">Carl Friedrich Bolz-Tereick</a>
            </span></p>
            <p class="dateline">
            <a href="../posts/2019/02/dusseldorf-sprint-report-2019-6107623654916313905.html" rel="bookmark">
            <time class="published dt-published" datetime="2019-02-09T16:13:00Z" itemprop="datePublished" title="2019-02-09 16:13">2019-02-09 16:13</time></a>
            </p>
                <p class="commentline">4 comments</p>

        </div>
    </header><div class="p-summary entry-summary">
    <p>Hello everyone!</p>
<p>We are happy to report a successful and well attended sprint that is wrapping up
in Düsseldorf, Germany. In the last week we had eighteen people sprinting
at the Heinrich-Heine-Universität Düsseldorf on various topics.</p>
<div class="separator" style="clear: both; text-align: center;">
<a href="https://1.bp.blogspot.com/-ZSjAODMWBmc/XF77I34X4TI/AAAAAAAAqgw/lc1uNqH5a30efONmAGKH8-wikbX0R47NwCLcBGAs/s1600/DypAt1VXcAA3HwD.jpeg" style="margin-left: 1em; margin-right: 1em;"><img border="0" height="300" src="https://1.bp.blogspot.com/-ZSjAODMWBmc/XF77I34X4TI/AAAAAAAAqgw/lc1uNqH5a30efONmAGKH8-wikbX0R47NwCLcBGAs/s400/DypAt1VXcAA3HwD.jpeg" width="400"></a><p><em>Totally serious work going on here constantly.</em></p>
</div>
<p>A big
chunk of the sprint was dedicated to various discussions, since we did not
manage to gather the core developers in one room in quite a while.
Discussion topics included:</p>
<ul class="simple">
<li>Funding and general sustainability of open source.</li>
<li>Catching up with CPython 3.7/3.8 – we are planning to release 3.6 some time
in the next few months and we will continue working on 3.7/3.8.</li>
<li>What to do with VMprof</li>
<li>How can we support Cython inside PyPy in a way that will be understood
by the JIT, hence fast.</li>
<li>The future of supporting the numeric stack on pypy – we have made significant
progress in the past few years and most of the numeric stack works out of the box,
but deployment and performance remain problems. Improving on those problems
remains a very important focus for PyPy as a project.</li>
<li>Using the presence of a CPython developer (Łukasz Langa) and a Graal Python developer
(Tim Felgentreff) we discussed ways to collaborate in order to improve Python
ecosystem across implementations.</li>
<li>Pierre-Yves David and Georges Racinet from octobus gave us an exciting demo
on <a class="reference external" href="https://heptapod.net">Heptapod</a>, which adds mercurial support to gitlab.</li>
<li>Maciej and Armin gave demos of their current (non-PyPy-related) project <a href="https://vrsketch.eu/">VRSketch</a>.</li>
</ul>
<div class="separator" style="clear: both; text-align: center;">
<a href="https://2.bp.blogspot.com/-v0NI3qhGGo8/XF77mi713yI/AAAAAAAAqg4/pFvMbwjYn3MzUrnlazn_NyHdJv3cIpoDgCLcBGAs/s1600/DSC06342.JPG" style="margin-left: 1em; margin-right: 1em;"><img border="0" height="267" src="https://2.bp.blogspot.com/-v0NI3qhGGo8/XF77mi713yI/AAAAAAAAqg4/pFvMbwjYn3MzUrnlazn_NyHdJv3cIpoDgCLcBGAs/s400/DSC06342.JPG" width="400"></a>
<p><em>Visiting the <a href="https://en.wikipedia.org/wiki/Landschaftspark_Duisburg-Nord">Landschaftspark Duisburg Nord</a> on the break day</em></p>
</div>

<p>Some highlights of the coding tasks worked on:</p>
<ul class="simple">
<li>Aarch64 (ARM64) JIT backend work has been started, we are able to run the first
test! Tobias Oberstein from Crossbar GmbH and Rodolph Perfetta from ARM joined the
sprint to help kickstart the project.</li>
<li>The long running math-improvements branch that was started by Stian Andreassen got merged
after bugfixes done by Alexander Schremmer. It should improve operations on large integers.</li>
<li>The arcane art of necromancy was used to revive long dormant regalloc branch started
and nearly finished by Carl Friedrich Bolz-Tereick. The branch got merged and gives
some modest speedups across the board.</li>
<li>Andrew Lawrence worked on MSI installer for PyPy on windows.</li>
<li>Łukasz worked on improving failing tests on the PyPy 3.6 branch. He knows very obscure
details of CPython (e.g. how pickling works), hence we managed to progress very quickly.</li>
<li>Matti Picus set up a new benchmarking server for PyPy 3 branches.</li>
<li>The Utf8 branch, which changes the internal representation of unicode might be finally
merged at some point very soon. We discussed and improved upon the last few
blockers. It gives significant speedups in a lot of cases handling strings.</li>
<li>Zlib was missing couple methods, which were added by Ronan Lamy and Julian Berman.</li>
<li>Manuel Jacob fixed RevDB failures.</li>
<li>Antonio Cuni and Matti Picus worked on 7.0 release which should happen in a few days.</li>
</ul>
<p>Now we are all quite exhausted, and are looking forward to catching up on sleep.</p>
<p>Best regards,
Maciej Fijałkowski, Carl Friedrich Bolz-Tereick and the whole PyPy team.</p>
    </div>
    </article><div class="comment-level comment-level-1">
      <div class="comment comment-2603780063658152492">
        <div class="comment-header">
          <a name="comment-2603780063658152492"></a>
            <span class="author">Juan Luis Cano</span> wrote on <span class="date">2019-02-09 18:19</span>:
        </div>
        <div class="comment-content">
          <p>Congratulations for the sprint, folks! Any plans to leverage the manylinux2010 infrastructure and about producing PyPy compatible wheels soon?</p>
        </div>
      </div>
      <div class="comment comment-5643334801476242027">
        <div class="comment-header">
          <a name="comment-5643334801476242027"></a>
            <span class="author">Anonymous</span> wrote on <span class="date">2019-02-10 15:29</span>:
        </div>
        <div class="comment-content">
          <p>Nice work, looking forward to Python 3.6 and beyond! Is there anywhere to view the Python 3 benchmarks like there is for PyPy2?</p>
        </div>
      </div>
      <div class="comment comment-6634268466803908473">
        <div class="comment-header">
          <a name="comment-6634268466803908473"></a>
            <span class="author">Carl Friedrich Bolz-Tereick</span> wrote on <span class="date">2019-02-11 08:22</span>:
        </div>
        <div class="comment-content">
          <p>Hi Juan! Yes, we are going to work on manylinux2010 support to have PyPy wheels soon.</p>
        </div>
      </div>
      <div class="comment comment-6033392601354537757">
        <div class="comment-header">
          <a name="comment-6033392601354537757"></a>
            <span class="author">Carl Friedrich Bolz-Tereick</span> wrote on <span class="date">2019-02-11 08:24</span>:
        </div>
        <div class="comment-content">
          <p>@Anonymous yes, being able to view PyPy3 benchmarking results is the goal of the new benchmarking server, will still take a bit of work to hook everything up.</p>
        </div>
      </div>
         </div>

    <article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="../posts/2019/01/pypy-for-low-latency-systems-613165393301401965.html" class="u-url">PyPy for low-latency systems</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                <a href="../authors/antonio-cuni.html">Antonio Cuni</a>
            </span></p>
            <p class="dateline">
            <a href="../posts/2019/01/pypy-for-low-latency-systems-613165393301401965.html" rel="bookmark">
            <time class="published dt-published" datetime="2019-01-03T14:21:00Z" itemprop="datePublished" title="2019-01-03 14:21">2019-01-03 14:21</time></a>
            </p>
                <p class="commentline">3 comments</p>

        </div>
    </header><div class="p-summary entry-summary">
    <h1 class="title">
PyPy for low-latency systems</h1>
Recently I have merged the gc-disable branch, introducing a couple of features
which are useful when you need to respond to certain events with the lowest
possible latency.  This work has been kindly sponsored by <a class="reference external" href="https://www.gambitresearch.com/">Gambit Research</a>
(which, by the way, is a very cool and geeky place where to <a class="reference external" href="https://www.gambitresearch.com/jobs.html">work</a>, in case you
are interested).  Note also that this is a very specialized use case, so these
features might not be useful for the average PyPy user, unless you have the
same problems as described here.<br><br>
The PyPy VM manages memory using a generational, moving Garbage Collector.
Periodically, the GC scans the whole heap to find unreachable objects and
frees the corresponding memory.  Although at a first look this strategy might
sound expensive, in practice the total cost of memory management is far less
than e.g. on CPython, which is based on reference counting.  While maybe
counter-intuitive, the main advantage of a non-refcount strategy is
that allocation is very fast (especially compared to malloc-based allocators),
and deallocation of objects which die young is basically for free. More
information about the PyPy GC is available <a class="reference external" href="https://pypy.readthedocs.io/en/latest/gc_info.html#incminimark">here</a>.<br><br>
As we said, the total cost of memory managment is less on PyPy than on
CPython, and it's one of the reasons why PyPy is so fast.  However, one big
disadvantage is that while on CPython the cost of memory management is spread
all over the execution of the program, on PyPy it is concentrated into GC
runs, causing observable pauses which interrupt the execution of the user
program.<br>
To avoid excessively long pauses, the PyPy GC has been using an <a class="reference external" href="../posts/2013/10/incremental-garbage-collector-in-pypy-8956893523842234676.html">incremental
strategy</a> since 2013. The GC runs as a series of "steps", letting the user
program to progress between each step.<br><br>
The following chart shows the behavior of a real-world, long-running process:<br><div class="separator" style="clear: both; text-align: center;">
<a href="https://3.bp.blogspot.com/-44yKwUVK3BE/XC4X9XL4BII/AAAAAAAABbE/XdTCIoyA-eYxvxIgJhFHaKnzxjhoWStHQCEwYBhgL/s1600/gc-timing.png" style="margin-right: 1em;"><img border="0" height="246" src="https://3.bp.blogspot.com/-44yKwUVK3BE/XC4X9XL4BII/AAAAAAAABbE/XdTCIoyA-eYxvxIgJhFHaKnzxjhoWStHQCEwYBhgL/s640/gc-timing.png" width="640"></a>
</div>
<br><br>
The orange line shows the total memory used by the program, which
increases linearly while the program progresses. Every ~5 minutes, the GC
kicks in and the memory usage drops from ~5.2GB to ~2.8GB (this ratio is controlled
by the <a class="reference external" href="https://pypy.readthedocs.io/en/latest/gc_info.html#environment-variables">PYPY_GC_MAJOR_COLLECT</a> env variable).<br>
The purple line shows aggregated data about the GC timing: the whole
collection takes ~1400 individual steps over the course of ~1 minute: each
point represent the <strong>maximum</strong> time a single step took during the past 10
seconds. Most steps take ~10-20 ms, although we see a horrible peak of ~100 ms
towards the end. We have not investigated yet what it is caused by, but we
suspect it is related to the deallocation of raw objects.<br><br>
These multi-millesecond pauses are a problem for systems where it is important
to respond to certain events with a latency which is both low and consistent.
If the GC kicks in at the wrong time, it might causes unacceptable pauses during
the collection cycle.<br><br>
Let's look again at our real-world example. This is a system which
continuously monitors an external stream; when a certain event occurs, we want
to take an action. The following chart shows the maximum time it takes to
complete one of such actions, aggregated every minute:<br><br><div class="separator" style="clear: both; text-align: center;">
<a href="https://4.bp.blogspot.com/-FO9uFHSqZzU/XC4YC8LZUpI/AAAAAAAABa8/B8ZOrEgbVJUHoO65wxvCMVpvciO_d_0TwCLcBGAs/s1600/normal-max.png" style="margin-right: 1em;"><img border="0" height="240" src="https://4.bp.blogspot.com/-FO9uFHSqZzU/XC4YC8LZUpI/AAAAAAAABa8/B8ZOrEgbVJUHoO65wxvCMVpvciO_d_0TwCLcBGAs/s640/normal-max.png" width="640"></a>
</div>
<br>
You can clearly see that the baseline response time is around ~20-30
ms. However, we can also see periodic spikes around ~50-100 ms, with peaks up
to ~350-450 ms! After a bit of investigation, we concluded that most (although
not all) of the spikes were caused by the GC kicking in at the wrong time.<br><br>
The work I did in the <tt class="docutils literal"><span class="pre">gc-disable</span></tt> branch aims to fix this problem by
introducing <a class="reference external" href="https://pypy.readthedocs.io/en/latest/gc_info.html#semi-manual-gc-management">two new features</a> to the <tt class="docutils literal">gc</tt> module:<br><blockquote>
<ul class="simple">
<li>
<tt class="docutils literal">gc.disable()</tt>, which previously only inhibited the execution of
finalizers without actually touching the GC, now disables the GC major
collections. After a call to it, you will see the memory usage grow
indefinitely.</li>
<li>
<tt class="docutils literal">gc.collect_step()</tt> is a new function which you can use to manually
execute a single incremental GC collection step.</li>
</ul>
</blockquote>
It is worth to specify that <tt class="docutils literal">gc.disable()</tt> disables <strong>only</strong> the major
collections, while minor collections still runs.  Moreover, thanks to the
JIT's virtuals, many objects with a short and predictable lifetime are not
allocated at all. The end result is that most objects with short lifetime are
still collected as usual, so the impact of <tt class="docutils literal">gc.disable()</tt> on memory growth
is not as bad as it could sound.<br><br>
Combining these two functions, it is possible to take control of the GC to
make sure it runs only when it is acceptable to do so.  For an example of
usage, you can look at the implementation of a <a class="reference external" href="https://github.com/antocuni/pypytools/blob/master/pypytools/gc/custom.py">custom GC</a> inside <a class="reference external" href="https://pypi.org/project/pypytools/">pypytools</a>.
The peculiarity is that it also defines a "<tt class="docutils literal">with <span class="pre">nogc():"</span></tt> context manager
which you can use to mark performance-critical sections where the GC is not
allowed to run.<br><br>
The following chart compares the behavior of the default PyPy GC and the new
custom GC, after a careful placing of <tt class="docutils literal">nogc()</tt> sections:<br><br><div class="separator" style="clear: both; text-align: center;">
<a href="https://1.bp.blogspot.com/-bGqs0WrOEBk/XC4YJN0uZfI/AAAAAAAABbA/4EXOASvy830IKBoTFtrnmY22Vyd_api-ACLcBGAs/s1600/nogc-max.png" style="margin-right: 1em;"><img border="0" height="242" src="https://1.bp.blogspot.com/-bGqs0WrOEBk/XC4YJN0uZfI/AAAAAAAABbA/4EXOASvy830IKBoTFtrnmY22Vyd_api-ACLcBGAs/s640/nogc-max.png" width="640"></a>
</div>
<br>
The yellow line is the same as before, while the purple line shows the new
system: almost all spikes have gone, and the baseline performance is about 10%
better. There is still one spike towards the end, but after some investigation
we concluded that it was <strong>not</strong> caused by the GC.<br><br>
Note that this does <strong>not</strong> mean that the whole program became magically
faster: we simply moved the GC pauses in some other place which is <strong>not</strong>
shown in the graph: in this specific use case this technique was useful
because it allowed us to shift the GC work in places where pauses are more
acceptable.<br><br>
All in all, a pretty big success, I think.  These functionalities are already
available in the nightly builds of PyPy, and will be included in the next
release: take this as a New Year present :)<br><br>
Antonio Cuni and the PyPy team
    </div>
    </article><div class="comment-level comment-level-1">
      <div class="comment comment-1369370065844385286">
        <div class="comment-header">
          <a name="comment-1369370065844385286"></a>
            <span class="author">stuaxo</span> wrote on <span class="date">2019-01-08 18:47</span>:
        </div>
        <div class="comment-content">
          <p>Could see this being handy for python game libraries too.</p>
        </div>
      </div>
      <div class="comment comment-1469077008041346478">
        <div class="comment-header">
          <a name="comment-1469077008041346478"></a>
            <span class="author">samantha</span> wrote on <span class="date">2019-01-08 22:40</span>:
        </div>
        <div class="comment-content">
          <p>I am a bit surprised as these functions have been available for a long time in python gc module.  So I suppose the news is a better performing one in pypy?</p>
        </div>
      </div>
      <div class="comment comment-2155090110778580732">
        <div class="comment-header">
          <a name="comment-2155090110778580732"></a>
            <span class="author">Armin Rigo</span> wrote on <span class="date">2019-01-09 02:46</span>:
        </div>
        <div class="comment-content">
          <p>@samantha: ``gc.collect_step()`` is new.</p>
        </div>
      </div>
         </div>

    <article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="../posts/2018/12/pypy-winter-sprint-feb-4-9-in-dusseldorf-7199110498451574074.html" class="u-url">PyPy Winter Sprint Feb 4-9 in Düsseldorf</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                <a href="../authors/mattip.html">mattip</a>
            </span></p>
            <p class="dateline">
            <a href="../posts/2018/12/pypy-winter-sprint-feb-4-9-in-dusseldorf-7199110498451574074.html" rel="bookmark">
            <time class="published dt-published" datetime="2018-12-17T11:40:00Z" itemprop="datePublished" title="2018-12-17 11:40">2018-12-17 11:40</time></a>
            </p>
                <p class="commentline">2 comments</p>

        </div>
    </header><div class="p-summary entry-summary">
    <div dir="ltr" style="text-align: left;">
<div style="text-align: left;">
</div>
<h2 style="text-align: center;">
 PyPy Sprint February 4th-9th 2019 in Düsseldorf</h2>
<div style="text-align: left;">
<br>
The next PyPy sprint will be held in the Computer Science department of<b> </b>Heinrich-Heine Universität Düsseldorf from the 4th to the 9st of February 2019 (nine years after the <a href="../posts/2010/10/dusseldorf-sprint-report-2010-371223200425847723.html">last sprint there).</a> This is a fully public sprint, everyone is welcome to join us.</div>
<h3 style="text-align: center;">
Topics and goals</h3>
<div style="text-align: left;">
</div>
<ul style="text-align: left;">
<li>improve Python 3.6 support</li>
<li>discuss benchmarking situation</li>
<li>progress on utf-8 branches</li>
<li>cpyext performance and completeness</li>
<li>packaging: are we ready to upload to PyPI?</li>
<ul>
<li>
<a href="https://foss.heptapod.net/pypy/pypy/-/issues/2617">issue 2617</a>  - we expose too many functions from lib-pypy.so</li>
<li>
<a href="https://github.com/pypa/manylinux/issues/179">manylinux2010</a> - will it solve our build issues?</li>
<li>formulate an ABI name and upgrade policy</li>
</ul>
</ul>
<ul style="text-align: left;">
<li>
<a href="https://foss.heptapod.net/pypy/pypy/-/issues/2930">memoryview(ctypes.Structure)</a> does not create the correct format string</li>
<li>discussing the state and future of PyPy and the wider Python ecosystem</li>
</ul>
<div style="text-align: left;">
</div>
<h3 style="text-align: center;">
Location</h3>
<div style="text-align: left;">
The sprint will take place in seminar room 25.12.02.55 of the computer science department.  It is in the building 25.12 of the university campus, second floor. <a href="https://www.cs.hhu.de/en/research-groups/software-engineering-and-programming-languages/service-pages/contact/location-and-how-to-get-here.html">Travel instructions</a><br>
</div>
<h3 style="text-align: center;">
Exact times</h3>
<div style="text-align: left;">
Work days: starting February 4th (10:00), ending February 9th (~afternoon). The break day will probably be Thursday.</div>
<h3 style="text-align: center;">
Registration</h3>
<div style="text-align: left;">
<br>
Please register by Mercurial::<br>
https://bitbucket.org/pypy/extradoc/</div>
<div style="text-align: left;">
<a href="https://foss.heptapod.net/pypy/extradoc/-/blob/branch/default/extradoc/sprintinfo/ddorf2019/people.txt">https://foss.heptapod.net/pypy/extradoc/-/blob/branch/default/extradoc/sprintinfo/ddorf2019/people.txt</a><br><br>
or on the pypy-dev mailing list if you do not yet have check-in rights:<br>
</div>
<div style="text-align: left;">
<a href="https://mail.python.org/mailman/listinfo/pypy-dev">https://mail.python.org/mailman/listinfo/pypy-dev</a>
</div>
<div style="text-align: left;">
<br>
</div>
<div style="text-align: left;">
Looking forward to seeing everyone there!</div>
</div>
    </div>
    </article><div class="comment-level comment-level-1">
      <div class="comment comment-6406838439074632636">
        <div class="comment-header">
          <a name="comment-6406838439074632636"></a>
            <span class="author">Anonymous</span> wrote on <span class="date">2018-12-27 13:00</span>:
        </div>
        <div class="comment-content">
          <p>The travel instructions link is a redirect to a 404 page.</p>
        </div>
      </div>
      <div class="comment comment-872000399167361679">
        <div class="comment-header">
          <a name="comment-872000399167361679"></a>
            <span class="author">Armin Rigo</span> wrote on <span class="date">2018-12-27 13:33</span>:
        </div>
        <div class="comment-content">
          <p>Thanks!  Fixed.</p>
        </div>
      </div>
         </div>

    <article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="../posts/2018/11/hello-everyone-at-pypy-we-are-trying-to-5336557946798583063.html" class="u-url">Funding for 64-bit Armv8-a support in PyPy</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                <a href="../authors/maciej-fijalkowski.html">Maciej Fijalkowski</a>
            </span></p>
            <p class="dateline">
            <a href="../posts/2018/11/hello-everyone-at-pypy-we-are-trying-to-5336557946798583063.html" rel="bookmark">
            <time class="published dt-published" datetime="2018-11-29T12:09:00Z" itemprop="datePublished" title="2018-11-29 12:09">2018-11-29 12:09</time></a>
            </p>
                <p class="commentline">2 comments</p>

        </div>
    </header><div class="p-summary entry-summary">
    <div dir="ltr" style="text-align: left;">

<p>Hello everyone</p>

<p>At PyPy we are trying to support a relatively wide range of platforms. We have PyPy working on OS X, Windows and various flavors of linux (and unofficially various flavors of BSD) on the software side, with hardware side having x86, x86_64, PPC, 32-bit Arm (v7) and even zarch. This is harder than for other projects, since PyPy emits assembler on the fly from the just in time compiler and it requires significant amount of work to port it to a new platform.</p>

<p>We are pleased to inform that <a href="https://www.arm.com/">Arm Limited</a>, together with <a href="https://crossbario.com/">Crossbar.io GmbH</a>, are sponsoring the development of 64-bit Armv8-a architecture support through <a href="https://baroquesoftware.com">Baroque Software OU</a>, which would allow PyPy to run on a new variety of low-power, high-density servers with that architecture. We believe this will be beneficial for the funders, for the PyPy project as well as to the wider community.</p>

<p>The work will commence soon and will be done some time early next year with expected speedups either comparable to x86 speedups or, if our <a href="../posts/2013/05/pypy-20-alpha-for-arm-2318299473927531503.html">current experience with ARM holds</a>, more significant than x86 speedups.</p>

<p>Best,<br>
Maciej Fijalkowski and the PyPy team</p>
<br>
</div>
    </div>
    </article><div class="comment-level comment-level-1">
      <div class="comment comment-3511458181890368141">
        <div class="comment-header">
          <a name="comment-3511458181890368141"></a>
            <span class="author">GG boy</span> wrote on <span class="date">2018-12-01 13:59</span>:
        </div>
        <div class="comment-content">
          <p>Good job</p>
        </div>
      </div>
      <div class="comment comment-9164758857218309824">
        <div class="comment-header">
          <a name="comment-9164758857218309824"></a>
            <span class="author">Mahmoud Hashemi</span> wrote on <span class="date">2018-12-09 19:44</span>:
        </div>
        <div class="comment-content">
          <p>Nice! Congrats!</p>
        </div>
      </div>
         </div>

    <article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="../posts/2018/11/guest-post-implementing-calculator-repl-6271483514675006846.html" class="u-url">Guest Post: Implementing a Calculator REPL in RPython</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                <a href="../authors/carl-friedrich-bolz-tereick.html">Carl Friedrich Bolz-Tereick</a>
            </span></p>
            <p class="dateline">
            <a href="../posts/2018/11/guest-post-implementing-calculator-repl-6271483514675006846.html" rel="bookmark">
            <time class="published dt-published" datetime="2018-11-15T08:06:00Z" itemprop="datePublished" title="2018-11-15 08:06">2018-11-15 08:06</time></a>
            </p>
            
        </div>
    </header><div class="p-summary entry-summary">
    <p>This is a tutorial style post that walks through using the RPython translation
toolchain to create a REPL that executes basic math expressions. </p>

<p>We will do that by scanning the user's input into tokens, compiling those 
tokens into bytecode and running that bytecode in our own virtual machine. Don't
worry if that sounds horribly complicated, we are going to explain it step by
step. </p>

<p>This post is a bit of a diversion while on my journey to create a compliant 
<a href="https://www.craftinginterpreters.com/the-lox-language.html">lox</a> implementation
using the <a href="https://rpython.readthedocs.io">RPython translation toolchain</a>. The 
majority of this work is a direct RPython translation of the low level C 
guide from Bob Nystrom (<a href="https://twitter.com/munificentbob">@munificentbob</a>) in the
excellent book <a href="https://www.craftinginterpreters.com">craftinginterpreters.com</a>
specifically the chapters 14 – 17.</p>

<h2 id="theroadahead">The road ahead</h2>

<p>As this post is rather long I'll break it into a few major sections. In each section we will
have something that translates with RPython, and at the end it all comes together. </p>

<ul>
<li><a href="../posts/2018/11/guest-post-implementing-calculator-repl-6271483514675006846.html#arepl">REPL</a></li>

<li><a href="../posts/2018/11/guest-post-implementing-calculator-repl-6271483514675006846.html#avirtualmachine">Virtual Machine</a></li>

<li><a href="../posts/2018/11/guest-post-implementing-calculator-repl-6271483514675006846.html#scanningthesource">Scanning the source</a></li>

<li><a href="../posts/2018/11/guest-post-implementing-calculator-repl-6271483514675006846.html#compilingexpressions">Compiling Expressions</a></li>

<li><a href="../posts/2018/11/guest-post-implementing-calculator-repl-6271483514675006846.html#endtoend">End to end</a></li>
</ul>
<h2 id="arepl">A REPL</h2>

<p>So if you're a Python programmer you might be thinking this is pretty trivial right?</p>

<p>I mean if we ignore input errors, injection attacks etc couldn't we just do something
like this:</p>

<pre><code class="python">"""
A pure python REPL that can parse simple math expressions
"""
while True:
    print(eval(raw_input("&gt; ")))
</code></pre>

<p>Well it does appear to do the trick:</p>

<pre><code class="nohighlight">$ python2 section-1-repl/main.py
&gt; 3 + 4 * ((1.0/(2 * 3 * 4)) + (1.0/(4 * 5 * 6)) - (1.0/(6 * 7 * 8)))
3.1880952381
</code></pre>

<p>So can we just ask RPython to translate this into a binary that runs magically
faster?</p>

<p>Let's see what happens. We need to add two functions for RPython to
get its bearings (<code>entry_point</code> and <code>target</code>) and call the file <code>targetXXX</code>:</p>

<p><a href="https://github.com/hardbyte/rpython-post/blob/master/section-1-repl/targetrepl1.py"><code>targetrepl1.py</code></a></p>

<pre><code class="python language-python">def repl():
    while True:
        print eval(raw_input('&gt; '))


def entry_point(argv):
    repl()
    return 0


def target(driver, *args):
    return entry_point, None
</code></pre>

<p>Which at translation time gives us this admonishment that accurately tells us
we are trying to call a Python built-in <code>raw_input</code> that is unfortunately not 
valid RPython.</p>

<pre><code class="nohighlight">$ rpython ./section-1-repl/targetrepl1.py
...SNIP...
[translation:ERROR] AnnotatorError: 

object with a __call__ is not RPython: &lt;built-in function raw_input&gt;
Processing block:
 block@18 is a &lt;class 'rpython.flowspace.flowcontext.SpamBlock'&gt; 
 in (target1:2)repl 
 containing the following operations: 
       v0 = simple_call((builtin_function raw_input), ('&gt; ')) 
       v1 = simple_call((builtin_function eval), v0) 
       v2 = str(v1) 
       v3 = simple_call((function rpython_print_item), v2) 
       v4 = simple_call((function rpython_print_newline)) 
</code></pre>

<p>Ok so we can't use <code>raw_input</code> or <code>eval</code> but that doesn't faze us. Let's get 
the input from a stdin stream and just print it out (no evaluation).</p>

<p><a href="https://github.com/hardbyte/rpython-post/blob/master/section-1-repl/targetrepl2.py"><code>targetrepl2.py</code></a></p>

<pre><code class="python language-python">from rpython.rlib import rfile

LINE_BUFFER_LENGTH = 1024


def repl(stdin):
    while True:
        print "&gt; ",
        line = stdin.readline(LINE_BUFFER_LENGTH)
        print line


def entry_point(argv):
    stdin, stdout, stderr = rfile.create_stdio()
    try:
        repl(stdin)
    except:
        return 0


def target(driver, *args):
    return entry_point, None
</code></pre>

<p>Translate <code>targetrepl2.py</code> – we can add an optimization level if we
are so inclined:</p>

<pre><code class="nohighlight">$ rpython --opt=2 section-1-repl/targetrepl2.py
...SNIP...
[Timer] Timings:
[Timer] annotate                       ---  1.2 s
[Timer] rtype_lltype                   ---  0.9 s
[Timer] backendopt_lltype              ---  0.6 s
[Timer] stackcheckinsertion_lltype     ---  0.0 s
[Timer] database_c                     --- 15.0 s
[Timer] source_c                       ---  1.6 s
[Timer] compile_c                      ---  1.9 s
[Timer] =========================================
[Timer] Total:                         --- 21.2 s
</code></pre>

<p>No errors!? Let's try it out:</p>

<pre><code class="nohighlight">$ ./target2-c 
1 + 2
&gt;  1 + 2

^C
</code></pre>

<p>Ahh our first success – let's quickly deal with the flushing fail by using the 
stdout stream directly as well. Let's print out the input in quotes:</p>

<pre><code class="python language-python">from rpython.rlib import rfile

LINE_BUFFER_LENGTH = 1024


def repl(stdin, stdout):
    while True:
        stdout.write("&gt; ")
        line = stdin.readline(LINE_BUFFER_LENGTH)
        print '"%s"' % line.strip()


def entry_point(argv):
    stdin, stdout, stderr = rfile.create_stdio()
    try:
        repl(stdin, stdout)
    except:
        pass
    return 0


def target(driver, *args):
    return entry_point, None
</code></pre>

<p>Translation works, and the test run too:</p>

<pre><code class="nohighlight">$ ./target3-c 
&gt; hello this seems better
"hello this seems better"
&gt; ^C
</code></pre>

<p>So we are in a good place with taking user input and printing output... What about
the whole math evaluation thing we were promised? For that we are can probably leave
our RPython REPL behind for a while and connect it up at the end.</p>

<h2 id="avirtualmachine">A virtual machine</h2>

<p>A virtual machine is the execution engine of our basic math interpreter. It will be very simple,
only able to do simple tasks like addition. I won't go into any depth to describe why we want
a virtual machine, but it is worth noting that many languages including Java and Python make 
this decision to compile to an intermediate bytecode representation and then execute that with
a virtual machine. Alternatives are compiling directly to native machine code like (earlier versions of) the V8
JavaScript engine, or at the other end of the spectrum executing an abstract syntax tree – 
which is what the <a href="https://blog.plan99.net/graal-truffle-134d8f28fb69">Truffle approach to building VMs</a> is based on. </p>

<p>We are going to keep things very simple. We will have a stack where we can push and pop values,
we will only support floats, and our VM will only implement a few very basic operations.</p>

<h3 id="opcodes">OpCodes</h3>

<p>In fact our entire instruction set is:</p>

<pre><code class="nohighlight">OP_CONSTANT
OP_RETURN
OP_NEGATE
OP_ADD
OP_SUBTRACT
OP_MULTIPLY
OP_DIVIDE
</code></pre>

<p>Since we are targeting RPython we can't use the nice <code>enum</code> module from the Python standard
library, so instead we just define a simple class with class attributes.</p>

<p>We should start to get organized, so we will create a new file 
<a href="https://github.com/hardbyte/rpython-post/blob/master/section-2-vm/opcodes.py"><code>opcodes.py</code></a> and add this:</p>

<pre><code class="python language-python">class OpCode:
    OP_CONSTANT = 0
    OP_RETURN = 1
    OP_NEGATE = 2
    OP_ADD = 3
    OP_SUBTRACT = 4
    OP_MULTIPLY = 5
    OP_DIVIDE = 6
</code></pre>

<h3 id="chunks">Chunks</h3>

<p>To start with we need to get some infrastructure in place before we write the VM engine.</p>

<p>Following <a href="https://www.craftinginterpreters.com/chunks-of-bytecode.html">craftinginterpreters.com</a>
we start with a <code>Chunk</code> object which will represent our bytecode. In RPython we have access 
to Python-esq lists so our <code>code</code> object will just be a list of <code>OpCode</code> values – which are 
just integers. A list of ints, couldn't get much simpler.</p>

<p><code>section-2-vm/chunk.py</code></p>

<pre><code class="python language-python">class Chunk:
    code = None

    def __init__(self):
        self.code = []

    def write_chunk(self, byte):
        self.code.append(byte)

    def disassemble(self, name):
        print "== %s ==\n" % name
        i = 0
        while i &lt; len(self.code):
            i = disassemble_instruction(self, i)
</code></pre>

<p><em>From here on I'll only present minimal snippets of code instead of the whole lot, but 
I'll link to the repository with the complete example code. For example the 
various debugging including <code>disassemble_instruction</code> isn't particularly interesting
to include verbatim. See the <a href="https://github.com/hardbyte/rpython-post/">github repo</a> for full details</em></p>

<p>We need to check that we can create a chunk and disassemble it. The quickest way to do this
is to use Python during development and debugging then every so often try to translate it.</p>

<p>Getting the disassemble part through the RPython translator was a hurdle for me as I
quickly found that many <code>str</code> methods such as <code>format</code> are not supported, and only very basic
<code>%</code> based formatting is supported. I ended up creating helper functions for string manipulation
such as:</p>

<pre><code class="python language-python">def leftpad_string(string, width, char=" "):
    l = len(string)
    if l &gt; width:
        return string
    return char * (width - l) + string
</code></pre>

<p>Let's write a new <code>entry_point</code> that creates and disassembles a chunk of bytecode. We can
set the target output name to <code>vm1</code> at the same time:</p>

<p><a href="https://github.com/hardbyte/rpython-post/blob/master/section-2-vm/targetvm1.py"><code>targetvm1.py</code></a></p>

<pre><code class="python language-python">def entry_point(argv):
    bytecode = Chunk()
    bytecode.write_chunk(OpCode.OP_ADD)
    bytecode.write_chunk(OpCode.OP_RETURN)
    bytecode.disassemble("hello world")
    return 0

def target(driver, *args):
    driver.exe_name = "vm1"
    return entry_point, None
</code></pre>

<p>Running this isn't going to be terribly interesting, but it is always nice to
know that it is doing what you expect:</p>

<pre><code class="nohighlight">$ ./vm1 
== hello world ==

0000 OP_ADD       
0001 OP_RETURN    
</code></pre>

<h3 id="chunksofdata">Chunks of data</h3>

<p>Ref: https://www.craftinginterpreters.com/chunks-of-bytecode.html#constants</p>

<p>So our bytecode is missing a very crucial element – the values to operate on!</p>

<p>As with the bytecode we can store these constant values as part of the chunk
directly in a list. Each chunk will therefore have a constant data component,
and a code component. </p>

<p>Edit the <code>chunk.py</code> file and add the new instance attribute <code>constants</code> as an
empty list, and a new method <code>add_constant</code>.</p>

<pre><code class="python language-python">    def add_constant(self, value):
        self.constants.append(value)
        return len(self.constants) - 1
</code></pre>

<p>Now to use this new capability we can modify our example chunk
to write in some constants before the <code>OP_ADD</code>:</p>

<pre><code class="python language-python">    bytecode = Chunk()
    constant = bytecode.add_constant(1.0)
    bytecode.write_chunk(OpCode.OP_CONSTANT)
    bytecode.write_chunk(constant)

    constant = bytecode.add_constant(2.0)
    bytecode.write_chunk(OpCode.OP_CONSTANT)
    bytecode.write_chunk(constant)

    bytecode.write_chunk(OpCode.OP_ADD)
    bytecode.write_chunk(OpCode.OP_RETURN)

    bytecode.disassemble("adding constants")
</code></pre>

<p>Which still translates with RPython and when run gives us the following disassembled
bytecode:</p>

<pre><code class="$ ./vm2 language-$ ./vm2">== adding constants ==

0000 OP_CONSTANT  (00)        '1'
0002 OP_CONSTANT  (01)        '2'
0004 OP_ADD       
0005 OP_RETURN
</code></pre>

<p>We won't go down the route of serializing the bytecode to disk, but this bytecode chunk
(including the constant data) could be saved and executed on our VM later – like a Java
<code>.class</code> file. Instead we will pass the bytecode directly to our VM after we've created
it during the compilation process. </p>

<h3 id="emulation">Emulation</h3>

<p>So those four instructions of bytecode combined with the constant value mapping
<code>00 -&gt; 1.0</code> and <code>01 -&gt; 2.0</code> describes individual steps for our virtual machine
to execute. One major point in favor of defining our own bytecode is we can 
design it to be really simple to execute – this makes the VM really easy to implement.</p>

<p>As I mentioned earlier this virtual machine will have a stack, so let's begin with that.
Now the stack is going to be a busy little beast – as our VM takes instructions like 
<code>OP_ADD</code> it will pop off the top two values from the stack, and push the result of adding 
them together back onto the stack. Although dynamically resizing Python lists 
are marvelous, they can be a little slow. RPython can take advantage of a constant sized
list which doesn't make our code much more complicated.</p>

<p>To do this we will define a constant sized list and track the <code>stack_top</code> directly. Note
how we can give the RPython translator hints by adding assertions about the state that
the <code>stack_top</code> will be in.</p>

<pre><code class="python language-python">class VM(object):
    STACK_MAX_SIZE = 256
    stack = None
    stack_top = 0

    def __init__(self):
        self._reset_stack()

    def _reset_stack(self):
        self.stack = [0] * self.STACK_MAX_SIZE
        self.stack_top = 0

    def _stack_push(self, value):
        assert self.stack_top &lt; self.STACK_MAX_SIZE
        self.stack[self.stack_top] = value
        self.stack_top += 1

    def _stack_pop(self):
        assert self.stack_top &gt;= 0
        self.stack_top -= 1
        return self.stack[self.stack_top]

    def _print_stack(self):
        print "         ",
        if self.stack_top &lt;= 0:
            print "[]",
        else:
            for i in range(self.stack_top):
                print "[ %s ]" % self.stack[i],
        print
</code></pre>

<p>Now we get to the main event, the hot loop, the VM engine. Hope I haven't built it up to
much, it is actually really simple! We loop until the instructions tell us to stop 
(<code>OP_RETURN</code>), and dispatch to other simple methods based on the instruction.</p>

<pre><code class="python language-python">    def _run(self):
        while True:
            instruction = self._read_byte()

            if instruction == OpCode.OP_RETURN:
                print "%s" % self._stack_pop()
                return InterpretResultCode.INTERPRET_OK
            elif instruction == OpCode.OP_CONSTANT:
                constant = self._read_constant()
                self._stack_push(constant)
            elif instruction == OpCode.OP_ADD:
                self._binary_op(self._stack_add)    
</code></pre>

<p>Now the <code>_read_byte</code> method will have to keep track of which instruction we are up 
to. So add an instruction pointer (<code>ip</code>) to the VM with an initial value of <code>0</code>.
Then <code>_read_byte</code> is simply getting the next bytecode (int) from the chunk's <code>code</code>:</p>

<pre><code class="python language-python">    def _read_byte(self):
        instruction = self.chunk.code[self.ip]
        self.ip += 1
        return instruction
</code></pre>

<p></p>

<p>If the instruction is <code>OP_CONSTANT</code> we take the constant's address from the next byte
of the chunk's <code>code</code>, retrieve that constant value and add it to the VM's stack.</p>

<pre><code class="python language-python">    def _read_constant(self):
        constant_index = self._read_byte()
        return self.chunk.constants[constant_index]
</code></pre>

<p>Finally our first arithmetic operation <code>OP_ADD</code>, what it has to achieve doesn't 
require much explanation: pop two values from the stack, add them together, push 
the result. But since a few operations all have the same template we introduce a
layer of indirection – or abstraction – by introducing a reusable <code>_binary_op</code> 
helper method.</p>

<pre><code class="python language-python">    @specialize.arg(1)
    def _binary_op(self, operator):
        op2 = self._stack_pop()
        op1 = self._stack_pop()
        result = operator(op1, op2)
        self._stack_push(result)

    @staticmethod
    def _stack_add(op1, op2):
        return op1 + op2
</code></pre>

<p></p>

<p>Note we tell RPython to specialize <code>_binary_op</code> on the first argument. This causes
RPython to make a copy of <code>_binary_op</code> for every value of the first argument passed,
which means that each copy contains a call to a particular operator, which can then be
inlined.</p>

<p>To be able to run our bytecode the only thing left to do is to pass in the chunk 
and call <code>_run()</code>:</p>

<pre><code class="python language-python">    def interpret_chunk(self, chunk):
        if self.debug_trace:
            print "== VM TRACE =="
        self.chunk = chunk
        self.ip = 0
        try:
            result = self._run()
            return result
        except:
            return InterpretResultCode.INTERPRET_RUNTIME_ERROR
</code></pre>

<p><a href="https://github.com/hardbyte/rpython-post/blob/master/section-2-vm/targetvm3.py"><code>targetvm3.py</code></a> connects the pieces:</p>

<pre><code class="python language-python">def entry_point(argv):
    bytecode = Chunk()
    constant = bytecode.add_constant(1)
    bytecode.write_chunk(OpCode.OP_CONSTANT)
    bytecode.write_chunk(constant)
    constant = bytecode.add_constant(2)
    bytecode.write_chunk(OpCode.OP_CONSTANT)
    bytecode.write_chunk(constant)
    bytecode.write_chunk(OpCode.OP_ADD)
    bytecode.write_chunk(OpCode.OP_RETURN)

    vm = VM()
    vm.interpret_chunk(bytecode)

    return 0
</code></pre>

<p>I've added some trace debugging so we can see what the VM and stack is doing.</p>

<p>The whole thing translates with RPython, and when run gives us:</p>

<pre><code class="nohighlight">./vm3
== VM TRACE ==
          []
0000 OP_CONSTANT  (00)        '1'
          [ 1 ]
0002 OP_CONSTANT  (01)        '2'
          [ 1 ] [ 2 ]
0004 OP_ADD       
          [ 3 ]
0005 OP_RETURN    
3
</code></pre>

<p>Yes we just computed the result of <code>1+2</code>. Pat yourself on the back. </p>

<p>At this point it is probably valid to check that the translated executable is actually
faster than running our program directly in Python. For this trivial example under 
<code>Python2</code>/<code>pypy</code> this <code>targetvm3.py</code> file runs in the 20ms – 90ms region, and the 
compiled <code>vm3</code> runs in &lt;5ms. Something useful must be happening during the translation.</p>

<p>I won't go through the code adding support for our other instructions as they are
very similar and straightforward. Our VM is ready to execute our chunks of bytecode,
but we haven't yet worked out how to take the entered expression and turn that into
this simple bytecode. This is broken into two steps, scanning and compiling.</p>

<h2 id="scanningthesource">Scanning the source</h2>

<p><em>All the source for this section can be found in 
<a href="https://github.com/hardbyte/rpython-post/blob/master/section-3-scanning">section-3-scanning</a>.</em></p>

<p>The job of the scanner is to take the raw expression string and transform it into
a sequence of tokens. This scanning step will strip out whitespace and comments, 
catch errors with invalid token and tokenize the string. For example the input 
<code>"( 1 + 2 )</code> would get tokenized into <code>LEFT_PAREN, NUMBER(1), PLUS, NUMBER(2), RIGHT_PAREN</code>.</p>

<p>As with our <code>OpCodes</code> we will just define a simple Python class to define an <code>int</code>
for each type of token:</p>

<pre><code class="python language-python">class TokenTypes:
    ERROR = 0
    EOF = 1
    LEFT_PAREN = 2
    RIGHT_PAREN = 3
    MINUS = 4
    PLUS = 5
    SLASH = 6
    STAR = 7
    NUMBER = 8
</code></pre>

<p>A token has to keep some other information as well – keeping track of the <code>location</code> and 
<code>length</code> of the token will be helpful for error reporting. The <code>NUMBER</code> token clearly needs 
some data about the value it is representing: we could include a copy of the source lexeme 
(e.g. the string <code>2.0</code>), or parse the value and store that, or – what we will do in this 
blog – use the <code>location</code> and <code>length</code> information as pointers into the original source 
string. Every token type (except perhaps <code>ERROR</code>) will use this simple data structure: </p>

<pre><code class="python language-python">class Token(object):

    def __init__(self, start, length, token_type):
        self.start = start
        self.length = length
        self.type = token_type
</code></pre>

<p>Our soon to be created scanner will create these <code>Token</code> objects which refer back to 
addresses in some source. If the scanner sees the source <code>"( 1 + 2.0 )"</code> it would emit
the following tokens:</p>

<pre><code class="python language-python">Token(0, 1, TokenTypes.LEFT_PAREN)
Token(2, 1, TokenTypes.NUMBER)
Token(4, 1, TokenTypes.PLUS)
Token(6, 3, TokenTypes.NUMBER)
Token(10, 1, TokenTypes.RIGHT_PAREN)
</code></pre>

<h3 id="scanner">Scanner</h3>

<p>Let's walk through the scanner <a href="https://github.com/hardbyte/rpython-post/blob/master/section-3-scanning/scanner.py">implementation</a> method
by method. The scanner will take the source and pass through it once, creating tokens
as it goes.</p>

<pre><code class="python language-python">class Scanner(object):

    def __init__(self, source):
        self.source = source
        self.start = 0
        self.current = 0
</code></pre>

<p>The <code>start</code> and <code>current</code> variables are character indices in the source string that point to 
the current substring being considered as a token. </p>

<p>For example in the string <code>"(51.05+2)"</code> while we are tokenizing the number <code>51.05</code>
we will have <code>start</code> pointing at the <code>5</code>, and advance <code>current</code> character by character
until the character is no longer part of a number. Midway through scanning the number 
the <code>start</code> and <code>current</code> values might point to <code>1</code> and <code>4</code> respectively:</p>

<table border="1" style="border-collapse: collapse;">
<thead><tr>
<th>0</th>
<th>1</th>
<th>2</th>
<th>3</th>
<th>4</th>
<th>5</th>
<th>6</th>
<th>7</th>
<th>8</th>
</tr></thead>
<tbody>
<tr>
<td>"("</td>
<td>"5"</td>
<td>"1"</td>
<td>"."</td>
<td>"0"</td>
<td>"5"</td>
<td>"+"</td>
<td>"2"</td>
<td>")"</td>
</tr>
<tr>
<td></td>
<td> ^</td>
<td></td>
<td></td>
<td> ^</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>From <code>current=4</code> the scanner peeks ahead and sees that the next character (<code>5</code>) is
a digit, so will continue to advance.</p>

<table border="1" style="border-collapse: collapse;">
<thead><tr>
<th>0</th>
<th>1</th>
<th>2</th>
<th>3</th>
<th>4</th>
<th>5</th>
<th>6</th>
<th>7</th>
<th>8</th>
</tr></thead>
<tbody>
<tr>
<td>"("</td>
<td>"5"</td>
<td>"1"</td>
<td>"."</td>
<td>"0"</td>
<td>"5"</td>
<td>"+"</td>
<td>"2"</td>
<td>")"</td>
</tr>
<tr>
<td></td>
<td> ^</td>
<td></td>
<td></td>
<td></td>
<td> ^</td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>When the scanner peeks ahead and sees the <code>"+"</code> it will create the number
token and emit it. The method that carry's out this tokenizing is <code>_number</code>:</p>

<pre><code class="python language-python">    def _number(self):
        while self._peek().isdigit():
            self.advance()

        # Look for decimal point
        if self._peek() == '.' and self._peek_next().isdigit():
            self.advance()
            while self._peek().isdigit():
                self.advance()

        return self._make_token(TokenTypes.NUMBER)
</code></pre>

<p>It relies on a few helpers to look ahead at the upcoming characters:</p>

<pre><code class="python language-python">    def _peek(self):
        if self._is_at_end():
            return '\0'
        return self.source[self.current]

    def _peek_next(self):
        if self._is_at_end():
            return '\0'
        return self.source[self.current+1]

    def _is_at_end(self):
        return len(self.source) == self.current
</code></pre>

<p>If the character at <code>current</code> is still part of the number we want to call <code>advance</code>
to move on by one character.</p>

<pre><code class="python language-python">    def advance(self):
        self.current += 1
        return self.source[self.current - 1]
</code></pre>

<p>Once the <code>isdigit()</code> check fails in <code>_number()</code> we call <code>_make_token()</code> to emit the
token with the <code>NUMBER</code> type.</p>

<pre><code class="python language-python">    def _make_token(self, token_type):
        return Token(
            start=self.start,
            length=(self.current - self.start),
            token_type=token_type
        )
</code></pre>

<p>Note again that the token is linked to an index address in the source, rather than 
including the string value.</p>

<p>Our scanner is pull based, a token will be requested via <code>scan_token</code>. First we skip 
past whitespace and depending on the characters emit the correct token:</p>

<pre><code class="python language-python">    def scan_token(self):
        # skip any whitespace
        while True:
            char = self._peek()
            if char in ' \r\t\n':
                self.advance()
            break

        self.start = self.current

        if self._is_at_end():
            return self._make_token(TokenTypes.EOF)

        char = self.advance()

        if char.isdigit():
            return self._number()

        if char == '(':
            return self._make_token(TokenTypes.LEFT_PAREN)
        if char == ')':
            return self._make_token(TokenTypes.RIGHT_PAREN)
        if char == '-':
            return self._make_token(TokenTypes.MINUS)
        if char == '+':
            return self._make_token(TokenTypes.PLUS)
        if char == '/':
            return self._make_token(TokenTypes.SLASH)
        if char == '*':
            return self._make_token(TokenTypes.STAR)

        return ErrorToken("Unexpected character", self.current)
</code></pre>

<p></p>

<p>If this was a real programming language we were scanning, this would be the point where we 
add support for different types of literals and any language identifiers/reserved words.</p>

<p>At some point we will need to parse the literal value for our numbers, but we leave that
job for some later component, for now we'll just add a <code>get_token_string</code> helper. To make
sure that RPython is happy to index arbitrary slices of <code>source</code> we add range assertions:</p>

<pre><code class="python language-python">    def get_token_string(self, token):
        if isinstance(token, ErrorToken):
            return token.message
        else:
            end_loc = token.start + token.length
            assert end_loc &lt; len(self.source)
            assert end_loc &gt; 0
            return self.source[token.start:end_loc]
</code></pre>

<p>A simple entry point can be used to test our scanner with a hard coded 
source string:</p>

<p><a href="https://github.com/hardbyte/rpython-post/blob/master/section-3-scanning/targetscanner1.py"><code>targetscanner1.py</code></a></p>

<pre><code class="python language-python">from scanner import Scanner, TokenTypes, TokenTypeToName


def entry_point(argv):

    source = "(   1   + 2.0 )"

    scanner = Scanner(source)
    t = scanner.scan_token()
    while t.type != TokenTypes.EOF and t.type != TokenTypes.ERROR:
        print TokenTypeToName[t.type],
        if t.type == TokenTypes.NUMBER:
            print "(%s)" % scanner.get_token_string(t),
        print
        t = scanner.scan_token()
    return 0
</code></pre>

<p>RPython didn't complain, and lo it works:</p>

<pre><code class="nohighlight">$ ./scanner1 
LEFT_PAREN
NUMBER (1)
PLUS
NUMBER (2.0)
RIGHT_PAREN
</code></pre>

<p>Let's connect our REPL to the scanner.</p>

<p><a href="https://github.com/hardbyte/rpython-post/blob/master/section-3-scanning/targetscanner2.py"><code>targetscanner2.py</code></a></p>

<pre><code class="python language-python">from rpython.rlib import rfile
from scanner import Scanner, TokenTypes, TokenTypeToName

LINE_BUFFER_LENGTH = 1024


def repl(stdin, stdout):
    while True:
        stdout.write("&gt; ")
        source = stdin.readline(LINE_BUFFER_LENGTH)

        scanner = Scanner(source)
        t = scanner.scan_token()
        while t.type != TokenTypes.EOF and t.type != TokenTypes.ERROR:
            print TokenTypeToName[t.type],
            if t.type == TokenTypes.NUMBER:
                print "(%s)" % scanner.get_token_string(t),
            print
            t = scanner.scan_token()


def entry_point(argv):
    stdin, stdout, stderr = rfile.create_stdio()
    try:
        repl(stdin, stdout)
    except:
        pass
    return 0
</code></pre>

<p>With our REPL hooked up we can now scan tokens from arbitrary input:</p>

<pre><code class="nohighlight">$ ./scanner2
&gt; (3 *4) - -3
LEFT_PAREN
NUMBER (3)
STAR
NUMBER (4)
RIGHT_PAREN
MINUS
MINUS
NUMBER (3)
&gt; ^C
</code></pre>

<h2 id="compilingexpressions">Compiling expressions</h2>

<h3 id="references">References</h3>

<ul>
<li>https://www.craftinginterpreters.com/compiling-expressions.html</li>

<li>https://effbot.org/zone/simple-top-down-parsing.htm</li>
</ul>
<p>The final piece is to turn this sequence of tokens into our low level 
bytecode instructions for the virtual machine to execute. Buckle up, 
we are about to write us a compiler.</p>

<p>Our compiler will take a single pass over the tokens using 
<a href="https://en.wikipedia.org/wiki/Vaughan_Pratt">Vaughan Pratt’s</a> 
parsing technique, and output a chunk of bytecode – if we do it
right it will be compatible with our existing virtual machine.</p>

<p>Remember the bytecode we defined above is really simple – by relying 
on our stack we can transform a nested expression into a sequence of
our bytecode operations.</p>

<p>To make this more concrete let's go through by hand translating an
expression into bytecode.</p>

<p>Our source expression:</p>

<pre><code class="nohighlight">(3 + 2) - (7 * 2)
</code></pre>

<p>If we were to make an abstract syntax tree we'd get something 
like this:</p>

<p><a href="https://4.bp.blogspot.com/-9mH1n1YF3rA/W-wxcRXRNPI/AAAAAAAAm5Y/PFqcPlOQ8KcSfIoxdDZHJO3Tby1vKqOKACPcBGAYYCw/s1600/ast.jpg"><img border="0" height="187" src="https://4.bp.blogspot.com/-9mH1n1YF3rA/W-wxcRXRNPI/AAAAAAAAm5Y/PFqcPlOQ8KcSfIoxdDZHJO3Tby1vKqOKACPcBGAYYCw/s400/ast.jpg" width="400"></a></p>

<p>Now if we start at the first sub expression <code>(3+2)</code> we can clearly
note from the first open bracket that we <em>must</em> see a close bracket,
and that the expression inside that bracket <em>must</em> be valid on its 
own. Not only that but regardless of the inside we know that the whole
expression still has to be valid. Let's focus on this first bracketed
expression, let our attention recurse into it so to speak.</p>

<p>This gives us a much easier problem – we just want to get our virtual
machine to compute <code>3 + 2</code>. In this bytecode dialect we would load the 
two constants, and then add them with <code>OP_ADD</code> like so:  </p>

<pre><code class="nohighlight">OP_CONSTANT  (00) '3.000000'
OP_CONSTANT  (01) '2.000000'
OP_ADD
</code></pre>

<p>The effect of our vm executing these three instructions is that sitting
pretty at the top of the stack is the result of the addition. Winning.</p>

<p>Jumping back out from our bracketed expression, our next token is <code>MINUS</code>,
at this point we have a fair idea that it must be used in an infix position. 
In fact whatever token followed the bracketed expression it <strong>must</strong> be a 
valid infix operator, if not the expression is over or had a syntax error. </p>

<p>Assuming the best from our user (naive), we handle <code>MINUS</code> the same way
we handled the first <code>PLUS</code>. We've already got the first operand on the
stack, now we compile the right operand and <strong>then</strong> write out the bytecode
for <code>OP_SUBTRACT</code>.</p>

<p>The right operand is another simple three instructions:</p>

<pre><code class="nohighlight">OP_CONSTANT  (02) '7.000000'
OP_CONSTANT  (03) '2.000000'
OP_MULTIPLY
</code></pre>

<p>Then we finish our top level binary expression and write a <code>OP_RETURN</code> to
return the value at the top of the stack as the execution's result. Our
final hand compiled program is:</p>

<pre><code class="nohighlight">OP_CONSTANT  (00) '3.000000'
OP_CONSTANT  (01) '2.000000'
OP_ADD
OP_CONSTANT  (02) '7.000000'
OP_CONSTANT  (03) '2.000000'
OP_MULTIPLY
OP_SUBTRACT
OP_RETURN
</code></pre>

<p>Ok that wasn't so hard was it? Let's try make our code do that.</p>

<p>We define a parser object which will keep track of where we are, and
whether things have all gone horribly wrong:</p>

<pre><code class="python language-python">class Parser(object):
    def __init__(self):
        self.had_error = False
        self.panic_mode = False
        self.current = None
        self.previous = None
</code></pre>

<p>The compiler will also be a class, we'll need one of our <code>Scanner</code> instances
to pull tokens from, and since the output is a bytecode <code>Chunk</code> let's go ahead
and make one of those in our compiler initializer:</p>

<pre><code class="python language-python">class Compiler(object):

    def __init__(self, source):
        self.parser = Parser()
        self.scanner = Scanner(source)
        self.chunk = Chunk()
</code></pre>

<p>Since we have this (empty) chunk of bytecode we will make a helper method
to add individual bytes. Every instruction will pass from our compiler into
an executable program through this simple .</p>

<pre><code class="python language-python">    def emit_byte(self, byte):
        self.current_chunk().write_chunk(byte)
</code></pre>

<p>To quote from Bob Nystrom on the Pratt parsing technique:</p>

<blockquote>
  <p>the implementation is a deceptively-simple handful of deeply intertwined code</p>
</blockquote>

<p>I don't actually think I can do justice to this section. Instead I suggest 
reading his treatment in 
<a href="https://journal.stuffwithstuff.com/2011/03/19/pratt-parsers-expression-parsing-made-easy/">Pratt Parsers: Expression Parsing Made Easy</a>
which explains the magic behind the parsing component. Our only major difference is 
instead of creating an AST we are going to directly emit bytecode for our VM.</p>

<p>Now that I've absolved myself from taking responsibility in explaining this somewhat
tricky concept, I'll discuss some of the code from 
<a href="https://github.com/hardbyte/rpython-post/blob/master/section-4-compiler/compiler.py"><code>compiler.py</code></a>, and walk through what happens 
for a particular rule.</p>

<p>I'll jump straight to the juicy bit the table of parse rules. We define a <code>ParseRule</code>
for each token, and each rule comprises:</p>

<ul>
<li>an optional handler for when the token is as a <em>prefix</em> (e.g. the minus in <code>(-2)</code>),</li>

<li>an optional handler for whet the token is used <em>infix</em> (e.g. the slash in <code>2/47</code>)</li>

<li>a precedence value (a number that determines what is of higher precedence)</li>
</ul>
<pre><code class="python language-python">rules = [
    ParseRule(None,              None,            Precedence.NONE),   # ERROR
    ParseRule(None,              None,            Precedence.NONE),   # EOF
    ParseRule(Compiler.grouping, None,            Precedence.CALL),   # LEFT_PAREN
    ParseRule(None,              None,            Precedence.NONE),   # RIGHT_PAREN
    ParseRule(Compiler.unary,    Compiler.binary, Precedence.TERM),   # MINUS
    ParseRule(None,              Compiler.binary, Precedence.TERM),   # PLUS
    ParseRule(None,              Compiler.binary, Precedence.FACTOR), # SLASH
    ParseRule(None,              Compiler.binary, Precedence.FACTOR), # STAR
    ParseRule(Compiler.number,   None,            Precedence.NONE),   # NUMBER
]
</code></pre>

<p>These rules really are the magic of our compiler. When we get to a particular
token such as <code>MINUS</code> we see if it is an infix operator and if so we've gone and
got its first operand ready. At all times we rely on the relative precedence; consuming 
everything with higher precedence than the operator we are currently evaluating.</p>

<p>In the expression:</p>

<pre><code class="nohighlight">2 + 3 * 4
</code></pre>

<p>The <code>*</code> has higher precedence than the <code>+</code>, so <code>3 * 4</code> will be parsed together
as the second operand to the first infix operator (the <code>+</code>) which follows
the <a href="https://en.wikipedia.org/wiki/Order_of_operations#Mnemonics">BEDMAS</a> 
order of operations I was taught at high school.</p>

<p>To encode these precedence values we make another Python object moonlighting
as an enum:</p>

<pre><code class="python language-python">class Precedence(object):
    NONE = 0
    DEFAULT = 1
    TERM = 2        # + -
    FACTOR = 3      # * /
    UNARY = 4       # ! - +
    CALL = 5        # ()
    PRIMARY = 6
</code></pre>

<p>What happens in our compiler when turning <code>-2.0</code> into bytecode? Assume we've just 
pulled the token <code>MINUS</code> from the scanner. Every expression <strong>has</strong> to start with some
type of prefix – whether that is:</p>

<ul>
<li>a bracket group <code>(</code>, </li>

<li>a number <code>2</code>, </li>

<li>or a prefix unary operator <code>-</code>. </li>
</ul>
<p>Knowing that, our compiler assumes there is a <code>prefix</code> handler in the rule table – in
this case it points us at the <code>unary</code> handler.</p>

<pre><code class="python language-python">    def parse_precedence(self, precedence):
        # parses any expression of a given precedence level or higher
        self.advance()
        prefix_rule = self._get_rule(self.parser.previous.type).prefix
        prefix_rule(self)
</code></pre>

<p></p>

<p><code>unary</code> is called:</p>

<pre><code class="python language-python">    def unary(self):
        op_type = self.parser.previous.type
        # Compile the operand
        self.parse_precedence(Precedence.UNARY)
        # Emit the operator instruction
        if op_type == TokenTypes.MINUS:
            self.emit_byte(OpCode.OP_NEGATE)
</code></pre>

<p>Here – before writing the <code>OP_NEGATE</code> opcode we recurse back into <code>parse_precedence</code>
to ensure that <em>whatever</em> follows the <code>MINUS</code> token is compiled – provided it has 
higher precedence than <code>unary</code> – e.g. a bracketed group. 
Crucially at run time this recursive call will ensure that the result is left 
on top of our stack. Armed with this knowledge, the <code>unary</code> method just
has to emit a single byte with the <code>OP_NEGATE</code> opcode.</p>

<h3 id="testcompilation">Test compilation</h3>

<p>Now we can test our compiler by outputting disassembled bytecode
of our user entered expressions. Create a new entry_point 
<a href="https://github.com/hardbyte/rpython-post/blob/master/section-4-compiler/targetcompiler1.py"><code>targetcompiler</code></a>:</p>

<pre><code class="python language-python">from rpython.rlib import rfile
from compiler import Compiler

LINE_BUFFER_LENGTH = 1024


def entry_point(argv):
    stdin, stdout, stderr = rfile.create_stdio()

    try:
        while True:
            stdout.write("&gt; ")
            source = stdin.readline(LINE_BUFFER_LENGTH)
            compiler = Compiler(source, debugging=True)
            compiler.compile()
    except:
        pass
    return 0
</code></pre>

<p>Translate it and test it out:</p>

<pre><code class="nohighlight">$ ./compiler1 
&gt; (2/4 + 1/2)
== code ==

0000 OP_CONSTANT  (00) '2.000000'
0002 OP_CONSTANT  (01) '4.000000'
0004 OP_DIVIDE    
0005 OP_CONSTANT  (02) '1.000000'
0007 OP_CONSTANT  (00) '2.000000'
0009 OP_DIVIDE    
0010 OP_ADD       
0011 OP_RETURN
</code></pre>

<p>Now if you've made it this far you'll be eager to finally connect everything
together by executing this bytecode with the virtual machine.</p>

<h2 id="endtoend">End to end</h2>

<p>All the pieces slot together rather easily at this point, create a new 
file <a href="https://github.com/hardbyte/rpython-post/blob/master/section-5-execution/targetcalc.py"><code>targetcalc.py</code></a> and define our 
entry point:</p>

<pre><code class="python language-python">from rpython.rlib import rfile
from compiler import Compiler
from vm import VM

LINE_BUFFER_LENGTH = 4096


def entry_point(argv):
    stdin, stdout, stderr = rfile.create_stdio()
    vm = VM()
    try:
        while True:
            stdout.write("&gt; ")
            source = stdin.readline(LINE_BUFFER_LENGTH)
            if source:
                compiler = Compiler(source, debugging=False)
                compiler.compile()
                vm.interpret_chunk(compiler.chunk)
    except:
        pass
    return 0


def target(driver, *args):
    driver.exe_name = "calc"
    return entry_point, None
</code></pre>

<p></p>

<p>Let's try catch it out with a double negative:</p>

<pre><code class="nohighlight">$ ./calc 
&gt; 2--3
== VM TRACE ==
          []
0000 OP_CONSTANT  (00) '2.000000'
          [ 2.000000 ]
0002 OP_CONSTANT  (01) '3.000000'
          [ 2.000000 ] [ 3.000000 ]
0004 OP_NEGATE    
          [ 2.000000 ] [ -3.000000 ]
0005 OP_SUBTRACT  
          [ 5.000000 ]
0006 OP_RETURN    
5.000000
</code></pre>

<p>Ok well let's evaluate the first 50 terms of the 
<a href="https://en.wikipedia.org/wiki/Pi#Infinite_series">Nilakantha Series</a>:</p>

<pre><code class="nohighlight">$ ./calc
&gt; 3 + 4 * ((1/(2 * 3 * 4)) + (1/(4 * 5 * 6)) - (1/(6 * 7 * 8)) + (1/(8 * 9 * 10)) - (1/(10 * 11 * 12)) + (1/(12 * 13 * 14)) - (1/(14 * 15 * 16)) + (1/(16 * 17 * 18)) - (1/(18 * 19 * 20)) + (1/(20 * 21 * 22)) - (1/(22 * 23 * 24)) + (1/(24 * 25 * 26)) - (1/(26 * 27 * 28)) + (1/(28 * 29 * 30)) - (1/(30 * 31 * 32)) + (1/(32 * 33 * 34)) - (1/(34 * 35 * 36)) + (1/(36 * 37 * 38)) - (1/(38 * 39 * 40)) + (1/(40 * 41 * 42)) - (1/(42 * 43 * 44)) + (1/(44 * 45 * 46)) - (1/(46 * 47 * 48)) + (1/(48 * 49 * 50)) - (1/(50 * 51 * 52)) + (1/(52 * 53 * 54)) - (1/(54 * 55 * 56)) + (1/(56 * 57 * 58)) - (1/(58 * 59 * 60)) + (1/(60 * 61 * 62)) - (1/(62 * 63 * 64)) + (1/(64 * 65 * 66)) - (1/(66 * 67 * 68)) + (1/(68 * 69 * 70)) - (1/(70 * 71 * 72)) + (1/(72 * 73 * 74)) - (1/(74 * 75 * 76)) + (1/(76 * 77 * 78)) - (1/(78 * 79 * 80)) + (1/(80 * 81 * 82)) - (1/(82 * 83 * 84)) + (1/(84 * 85 * 86)) - (1/(86 * 87 * 88)) + (1/(88 * 89 * 90)) - (1/(90 * 91 * 92)) + (1/(92 * 93 * 94)) - (1/(94 * 95 * 96)) + (1/(96 * 97 * 98)) - (1/(98 * 99 * 100)) + (1/(100 * 101 * 102)))

== VM TRACE ==
          []
0000 OP_CONSTANT  (00) '3.000000'
          [ 3.000000 ]
0002 OP_CONSTANT  (01) '4.000000'
...SNIP...
0598 OP_CONSTANT  (101) '102.000000'
          [ 3.000000 ] [ 4.000000 ] [ 0.047935 ] [ 1.000000 ] [ 10100.000000 ] [ 102.000000 ]
0600 OP_MULTIPLY  
          [ 3.000000 ] [ 4.000000 ] [ 0.047935 ] [ 1.000000 ] [ 1030200.000000 ]
0601 OP_DIVIDE    
          [ 3.000000 ] [ 4.000000 ] [ 0.047935 ] [ 0.000001 ]
0602 OP_ADD       
          [ 3.000000 ] [ 4.000000 ] [ 0.047936 ]
0603 OP_MULTIPLY  
          [ 3.000000 ] [ 0.191743 ]
0604 OP_ADD       
          [ 3.191743 ]
0605 OP_RETURN    
3.191743
</code></pre>

<p>We just executed 605 virtual machine instructions to compute pi to 1dp!</p>

<p>This brings us to the end of this tutorial. To recap we've walked through the whole 
compilation process: from the user providing an expression string on the REPL, scanning
the source string into tokens, parsing the tokens while accounting for relative 
precedence via a Pratt parser, generating bytecode, and finally executing the bytecode 
on our own VM. RPython translated what we wrote into C and compiled it, meaning
our resulting <code>calc</code> REPL is really fast.</p>

<blockquote>
  <p>“The world is a thing of utter inordinate complexity and richness and strangeness that is absolutely awesome.”</p>
  
  <p>― Douglas Adams </p>
</blockquote>

<p>Many thanks to Bob Nystrom for writing the book that inspired this post, and thanks to 
Carl Friedrich and Matt Halverson for reviewing.</p>

<p>― Brian (<a href="https://twitter.com/thorneynz">@thorneynzb</a>)</p>
    </div>
    </article>
</div>
</div>
<div class="sidebar">
<div>
  <h2>
    The PyPy blogposts
  </h2>
  <div>
    Create a guest post via a PR to the <a href="https://github.com/pypy/pypy.org">source repo</a>
  </div>
</div>
    <div id="global-recent-posts">
    <h2>
      Recent Posts
    </h2>
    <ul class="post-list">
      <li>
        <a href="/posts/2025/07/pypy-v7320-release.html" class="listtitle">PyPy v7.3.20 release</a>
      </li>
      <li>
        <a href="/posts/2025/06/rpython-gc-allocation-speed.html" class="listtitle">How fast can the RPython GC allocate?</a>
      </li>
      <li>
        <a href="/posts/2025/04/prospero-in-rpython.html" class="listtitle">Doing the Prospero-Challenge in RPython</a>
      </li>
      <li>
        <a href="/posts/2025/02/pypy-v7319-release.html" class="listtitle">PyPy v7.3.19 release</a>
      </li>
      <li>
        <a href="/posts/2025/02/pypy-gc-sampling.html" class="listtitle">Low Overhead Allocation Sampling with VMProf in PyPy's GC</a>
      </li>
      <li>
        <a href="/posts/2025/02/pypy-v7318-release.html" class="listtitle">PyPy v7.3.18 release</a>
      </li>
      <li>
        <a href="/posts/2025/01/musings-tracing.html" class="listtitle">Musings on Tracing in PyPy</a>
      </li>
      <li>
        <a href="/posts/2025/01/towards-pypy311-an-update.html" class="listtitle">Towards PyPy3.11 - an update</a>
      </li>
      <li>
        <a href="/posts/2024/11/guest-post-final-encoding-in-rpython.html" class="listtitle">Guest Post: Final Encoding in RPython Interpreters</a>
      </li>
      <li>
        <a href="/posts/2024/10/jit-peephole-dsl.html" class="listtitle">A DSL for Peephole Transformation Rules of Integer Operations in the PyPy JIT</a>
      </li>
    </ul>
  </div>

          <div id="global-archive-list">
          <h2>
            Archives
          </h2>
          <ul class="archive-level archive-level-1">
            <li><a class="reference" href="/2007/">2007</a> (19)
            </li>
            <li><a class="reference" href="/2008/">2008</a> (62)
            </li>
            <li><a class="reference" href="/2009/">2009</a> (38)
            </li>
            <li><a class="reference" href="/2010/">2010</a> (44)
            </li>
            <li><a class="reference" href="/2011/">2011</a> (43)
            </li>
            <li><a class="reference" href="/2012/">2012</a> (44)
            </li>
            <li><a class="reference" href="/2013/">2013</a> (46)
            </li>
            <li><a class="reference" href="/2014/">2014</a> (22)
            </li>
            <li><a class="reference" href="/2015/">2015</a> (20)
            </li>
            <li><a class="reference" href="/2016/">2016</a> (20)
            </li>
            <li><a class="reference" href="/2017/">2017</a> (13)
            </li>
            <li><a class="reference" href="/2018/">2018</a> (12)
            </li>
            <li><a class="reference" href="/2019/">2019</a> (12)
            </li>
            <li><a class="reference" href="/2020/">2020</a> (9)
            </li>
            <li><a class="reference" href="/2021/">2021</a> (10)
            </li>
            <li><a class="reference" href="/2022/">2022</a> (13)
            </li>
            <li><a class="reference" href="/2023/">2023</a> (6)
            </li>
            <li><a class="reference" href="/2024/">2024</a> (13)
            </li>
            <li><a class="reference" href="/2025/">2025</a> (8)
            </li>
          </ul>
        </div>


          <div id="global-tag-list">
          <h2>
            Tags
          </h2>
          <ul>
            <li><a class="reference" href="/categories/arm.html">arm</a> (2)</li>
            <li><a class="reference" href="/categories/benchmarking.html">benchmarking</a> (1)</li>
            <li><a class="reference" href="/categories/casestudy.html">casestudy</a> (3)</li>
            <li><a class="reference" href="/categories/cli.html">cli</a> (1)</li>
            <li><a class="reference" href="/categories/compiler.html">compiler</a> (1)</li>
            <li><a class="reference" href="/categories/conda-forge.html">conda-forge</a> (1)</li>
            <li><a class="reference" href="/categories/cpyext.html">cpyext</a> (4)</li>
            <li><a class="reference" href="/categories/cpython.html">CPython</a> (3)</li>
            <li><a class="reference" href="/categories/ep2008.html">ep2008</a> (1)</li>
            <li><a class="reference" href="/categories/extension-modules.html">extension modules</a> (3)</li>
            <li><a class="reference" href="/categories/gc.html">gc</a> (3)</li>
            <li><a class="reference" href="/categories/guestpost.html">guestpost</a> (3)</li>
            <li><a class="reference" href="/categories/graalpython.html">GraalPython</a> (1)</li>
            <li><a class="reference" href="/categories/hpy.html">hpy</a> (1)</li>
            <li><a class="reference" href="/categories/heptapod.html">Heptapod</a> (1)</li>
            <li><a class="reference" href="/categories/jit.html">jit</a> (23)</li>
            <li><a class="reference" href="/categories/jython.html">jython</a> (1)</li>
            <li><a class="reference" href="/categories/kcachegrind.html">kcachegrind</a> (1)</li>
            <li><a class="reference" href="/categories/meta.html">meta</a> (1)</li>
            <li><a class="reference" href="/categories/numpy.html">numpy</a> (24)</li>
            <li><a class="reference" href="/categories/parser.html">parser</a> (1)</li>
            <li><a class="reference" href="/categories/performance.html">performance</a> (2)</li>
            <li><a class="reference" href="/categories/profiling.html">profiling</a> (7)</li>
            <li><a class="reference" href="/categories/pypy.html">pypy</a> (6)</li>
            <li><a class="reference" href="/categories/pypy3.html">pypy3</a> (16)</li>
            <li><a class="reference" href="/categories/pyqt4.html">PyQt4</a> (1)</li>
            <li><a class="reference" href="/categories/release.html">release</a> (66)</li>
            <li><a class="reference" href="/categories/releasecffi.html">releasecffi</a> (3)</li>
            <li><a class="reference" href="/categories/releaserevdb.html">releaserevdb</a> (1)</li>
            <li><a class="reference" href="/categories/releasestm.html">releasestm</a> (1)</li>
            <li><a class="reference" href="/categories/revdb.html">revdb</a> (1)</li>
            <li><a class="reference" href="/categories/roadmap.html">roadmap</a> (2)</li>
            <li><a class="reference" href="/categories/rpython.html">rpython</a> (1)</li>
            <li><a class="reference" href="/categories/rpyc.html">RPyC</a> (1)</li>
            <li><a class="reference" href="/categories/speed.html">speed</a> (6)</li>
            <li><a class="reference" href="/categories/sponsors.html">sponsors</a> (7)</li>
            <li><a class="reference" href="/categories/sprint.html">sprint</a> (3)</li>
            <li><a class="reference" href="/categories/sprints.html">sprints</a> (1)</li>
            <li><a class="reference" href="/categories/stm.html">stm</a> (14)</li>
            <li><a class="reference" href="/categories/sun.html">sun</a> (1)</li>
            <li><a class="reference" href="/categories/smalltalk.html">Smalltalk</a> (1)</li>
            <li><a class="reference" href="/categories/squeak.html">Squeak</a> (1)</li>
            <li><a class="reference" href="/categories/testing.html">testing</a> (1)</li>
            <li><a class="reference" href="/categories/toy-optimizer.html">toy-optimizer</a> (5)</li>
            <li><a class="reference" href="/categories/unicode.html">unicode</a> (1)</li>
            <li><a class="reference" href="/categories/valgrind.html">valgrind</a> (1)</li>
            <li><a class="reference" href="/categories/vmprof.html">vmprof</a> (3)</li>
            <li><a class="reference" href="/categories/z3.html">z3</a> (5)</li>
          </ul>
        </div></div>
</main>
</div>
<div style="clear: both; width: 75%; margin: 1em auto;">
        <nav class="postindexpager"><ul class="pager">
<li class="previous">
                <a href="index-40.html" rel="prev">Newer posts</a>
            </li>
            <li class="next">
                <a href="index-38.html" rel="next">Older posts</a>
            </li>
        </ul></nav>
</div>
         
                 <footer id="footer"><p>
</p>
<div class="myfooter">
  <div class="logotext">
    © 2025 <a href="mailto:pypy-dev@pypy.org">The PyPy Team</a>
     
    Built with <a href="https://getnikola.com" rel="nofollow">Nikola</a>
     
    Last built 2025-07-07T11:01
  </div>
  <div style="margin-left: auto">
  <a href="../rss.xml">RSS feed</a>
</div>

            
        

    </div>
            <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.1.3/jquery.min.js" crossorigin="anonymous"></script><script src="../assets/js/styles.js"></script></footer>
</body>
</html>